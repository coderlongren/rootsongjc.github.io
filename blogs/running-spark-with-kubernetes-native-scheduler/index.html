<!DOCTYPE html>
<html class="no-js" lang="en-US" prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb#">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="baidu-site-verification" content="g8IYR9SNLF" />
    <meta name="uyan_auth" content="419f63884b" /> <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="description" content="">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1">


<meta name="keywords" content="kubernetes, spark, big-data, ">

 
<meta property="og:type" content="article"/>
<meta property="og:description" content=""/>
<meta property="og:title" content="运行支持kubernetes原生调度的spark程序-Spark on Kubernetes : jimmysong.io"/>
<meta property="og:site_name" content="rootsongjc is Jimmy Song"/>
<meta property="og:image" content="" />
<meta property="og:image:type" content="image/jpeg" />
<meta property="og:image:width" content="" />
<meta property="og:image:height" content="" />
<meta property="og:url" content="https://jimmysong.io/blogs/running-spark-with-kubernetes-native-scheduler/">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2017-09-14"/>
<meta property="article:modified_time" content="2017-09-14"/>



<meta property="article:tag" content="kubernetes">
<meta property="article:tag" content="spark">
<meta property="article:tag" content="big-data">




<meta name="twitter:card" content="summary">

<meta name="twitter:site" content="@rootsongjc">
<meta name="twitter:title" content="运行支持kubernetes原生调度的spark程序-Spark on Kubernetes : jimmysong.io">
<meta name="twitter:creator" content="@rootsongjc">
<meta name="twitter:description" content="">
<meta name="twitter:image:src" content="">
<meta name="twitter:domain" content="jimmysong.io">

    <base href="https://jimmysong.io/">
    <title> 运行支持kubernetes原生调度的spark程序-Spark on Kubernetes - jimmysong.io focus on Cloud Native & Big Data </title>
    <link rel="canonical" href="https://jimmysong.io/blogs/running-spark-with-kubernetes-native-scheduler/"> <link rel="stylesheet" href="/static/css/style.css">






<link rel="stylesheet" href="/static/css/syntax.css">
<script>
    var _hmt = _hmt || [];
    (function() {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?11f7d254cfa4e0ca44b175c66d379ecc";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>



    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" href="/apple-touch-icon.png" />
</head>


<body lang="en" itemscope itemtype="http://schema.org/Article">
    <header id="header">
    <figure>
      <a href="/" border=0 id="logolink"><div class="icon-octocat" id="logo"> </div></a>
    </figure>
    <div id="byline">by Jimmy Song</div>
    <nav id="nav">
    <ul id="mainnav">
    <li>
        <a href="/blogs/">
            <span class="icon"> <i aria-hidden="true" class="icon-quill"></i></span>
            <span> blogs </span>
        </a>
    </li>
    <li>
        <a href="/projects/">
            <span class="icon"> <i aria-hidden="true" class="icon-console"></i></span>
            <span> projects </span>
        </a>
    </li>
    <li>
        <a href="/talks/">
            <span class="icon"> <i aria-hidden="true" class="icon-stats"></i></span>
            <span> talks </span>
        </a>
    </li>
    <li>
        <a href="http://www.linkedin.com/in/rootsongjc">
            <span class="icon"> <i aria-hidden="true" class="icon-linkedin"></i></span>
            <span> me </span>
        </a>
    </li>
</ul>
    <ul id="social">
    <li id="share">
        <span class="icon icon-bubbles"> </span>
        <span class="title"> share </span>
        <div class="dropdown share">
            <ul class="social">
                <li> <a href="https://twitter.com/intent/tweet?status=%e8%bf%90%e8%a1%8c%e6%94%af%e6%8c%81kubernetes%e5%8e%9f%e7%94%9f%e8%b0%83%e5%ba%a6%e7%9a%84spark%e7%a8%8b%e5%ba%8f-Spark%20on%20Kubernetes-https%3a%2f%2fjimmysong.io%2fblogs%2frunning-spark-with-kubernetes-native-scheduler%2f" target="_blank" title="Follow me on Twitter" class="twitter"><span class="icon icon-twitter"></span>Twitter</a> </li>
                <li> <a href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fjimmysong.io%2fblogs%2frunning-spark-with-kubernetes-native-scheduler%2f" target="_blank" title="Join me on Facebook" class="facebook"><span class="icon icon-facebook"></span>Facebook</a> </li>
                <li> <a href="https://plus.google.com/share?url=https%3a%2f%2fjimmysong.io%2fblogs%2frunning-spark-with-kubernetes-native-scheduler%2f" target="_blank" title="Google+" class="googleplus"><span class="icon icon-google-plus"></span>Google+</a> </li>
                <li> <a href="http://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fjimmysong.io%2fblogs%2frunning-spark-with-kubernetes-native-scheduler%2f&title=%e8%bf%90%e8%a1%8c%e6%94%af%e6%8c%81kubernetes%e5%8e%9f%e7%94%9f%e8%b0%83%e5%ba%a6%e7%9a%84spark%e7%a8%8b%e5%ba%8f-Spark%20on%20Kubernetes&source=spf13" target="_blank" title="LinkedIn" class="linkedin"><span class="icon icon-linkedin"></span>LinkedIn</a> </li>
                <li> <a href="http://del.icio.us/post?url=https%3a%2f%2fjimmysong.io%2fblogs%2frunning-spark-with-kubernetes-native-scheduler%2f" target="_blank" title="Delicious" class="delicious"><span class="icon icon-delicious"></span>Delicious</a> </li>
                <li> <a href="http://www.reddit.com/submit?url=https%3a%2f%2fjimmysong.io%2fblogs%2frunning-spark-with-kubernetes-native-scheduler%2f" target="_blank" title="Reddit" class="reddit"><span class="icon icon-reddit"></span>Reddit</a> </li>
            </ul>
            <span class="subcount">sharing is caring</span>
        </div>
    </li>
    <li id="follow">
        <span class="icon icon-rocket"> </span>
        <span class="title"> follow </span>
        <div class="dropdown follow">
            <ul class="social">
                <li> <a href="http://www.twitter.com/jimmysongio" target="_blank" title="Follow me on Twitter" class="twitter"><span class="icon icon-twitter"></span>Twitter</a> </li>
                <li> <a href="http://www.facebook.com/jimmysongio" target="_blank" title="Join me on Facebook" class="facebook"><span class="icon icon-facebook"></span>Facebook</a> </li>
                <li> <a href="http://www.linkedin.com/in/jimmysongio" target="_blank" title="LinkedIn" class="linkedin"><span class="icon icon-linkedin"></span>LinkedIn</a> </li>
                <li> <a href="http://github.com/rootsongjc" target="_blank" title="GitHub" class="github"><span class="icon icon-github"></span>GitHub</a> </li>
                <li> <a href="https://www.douban.com/people/deamonj/" target="_blank" title="豆瓣" class="facebook"><span class="icon icon-idea"></span>Douban</a> </li>
                <li> <a href="https://jimmysongio.tuchong.com/" target="_blank" title="图虫" class="github"><span class="icon icon-cc-2"></span>Tuchong</a> </li>
            </ul>
            <span class="subcount">join 10k+ subscribers &amp; followers</span>
        </div>
    </li>
</ul>

    </nav>
</header>
 
    <section id="main">
        <h1 itemprop="name" id="title">运行支持kubernetes原生调度的spark程序-Spark on Kubernetes</h1>
        <div>
            <article itemprop="articleBody" id="content">
                

<p>TL;DR 关于 Spark on kubernetes 的详细信息和最新进展请见 <a href="https://jimmysong.io/spark-on-">https://jimmysong.io/spark-on-</a></p>

<p>我们之前就在 kubernetes 中运行过 standalone 方式的 spark 集群，见 <a href="https://jimmysong.io/kubernetes-handbook/usecases/spark-standalone-on-kubernetes.html">Spark standalone on kubernetes</a>。</p>

<p>目前运行支持 kubernetes 原生调度的 spark 程序项目由 Google 主导，fork 自 spark 的官方代码库，见 <a href="https://github.com/apache-spark-on-k8s/spark/">https://github.com/apache-spark-on-k8s/spark/</a> ，属于Big Data SIG。</p>

<p>参与到该项目的公司有：</p>

<ul>
<li>Bloomberg</li>
<li>Google</li>
<li>Haiwen</li>
<li>Hyperpilot</li>
<li>Intel</li>
<li>Palantir</li>
<li>Pepperdata</li>
<li>Red Hat</li>
</ul>

<h2 id="spark-概念说明">Spark 概念说明</h2>

<p><a href="http://spark.apache.org">Apache Spark</a> 是一个围绕速度、易用性和复杂分析构建的大数据处理框架。最初在2009年由加州大学伯克利分校的AMPLab开发，并于2010年成为Apache的开源项目之一。</p>

<p>在 Spark 中包括如下组件或概念：</p>

<ul>
<li><strong>Application</strong>：Spark Application 的概念和 Hadoop 中的 MapReduce 类似，指的是用户编写的 Spark 应用程序，包含了一个 Driver 功能的代码和分布在集群中多个节点上运行的 Executor 代码；</li>
<li><strong>Driver</strong>：Spark 中的 Driver 即运行上述 Application 的 main() 函数并且创建 SparkContext，其中创建 SparkContext 的目的是为了准备Spark应用程序的运行环境。在 Spark 中由 SparkContext 负责和 ClusterManager 通信，进行资源的申请、任务的分配和监控等；当 Executor 部分运行完毕后，Driver负责将SparkContext 关闭。通常用 SparkContext 代表 Driver；</li>
<li><strong>Executor</strong>：Application运行在Worker 节点上的一个进程，该进程负责运行Task，并且负责将数据存在内存或者磁盘上，每个Application都有各自独立的一批Executor。在Spark on Yarn模式下，其进程名称为<code>CoarseGrainedExecutorBackend</code>，类似于 Hadoop MapReduce 中的 YarnChild。一个 <code>CoarseGrainedExecutorBackend</code> 进程有且仅有一个 executor 对象，它负责将 Task 包装成 taskRunner，并从线程池中抽取出一个空闲线程运行 Task。每个 <code>CoarseGrainedExecutorBackend</code> 能并行运行 Task 的数量就取决于分配给它的 CPU 的个数了；</li>
<li><strong>Cluster Manager</strong>：指的是在集群上获取资源的外部服务，目前有：

<ul>
<li>Standalone：Spark原生的资源管理，由Master负责资源的分配；</li>
<li>Hadoop Yarn：由YARN中的ResourceManager负责资源的分配；</li>
</ul></li>
<li><strong>Worker</strong>：集群中任何可以运行Application代码的节点，类似于YARN中的NodeManager节点。在Standalone模式中指的就是通过Slave文件配置的Worker节点，在Spark on Yarn模式中指的就是NodeManager节点；</li>
<li><strong>作业（Job）</strong>：包含多个Task组成的并行计算，往往由Spark Action催生，一个JOB包含多个RDD及作用于相应RDD上的各种Operation；</li>
<li><strong>阶段（Stage）</strong>：每个Job会被拆分很多组 Task，每组任务被称为Stage，也可称TaskSet，一个作业分为多个阶段，每一个stage的分割点是action。比如一个job是：（transformation1 -&gt; transformation1 -&gt; action1 -&gt; transformation3 -&gt; action2），这个job就会被分为两个stage，分割点是action1和action2。</li>

<li><p><strong>任务（Task）</strong>： 被送到某个Executor上的工作任务；</p></li>

<li><p><strong>Context</strong>：启动spark application的时候创建，作为Spark 运行时环境。</p></li>

<li><p><strong>Dynamic Allocation（动态资源分配）</strong>：一个配置选项，可以将其打开。从Spark1.2之后，对于On Yarn模式，已经支持动态资源分配（Dynamic Resource Allocation），这样，就可以根据Application的负载（Task情况），动态的增加和减少executors，这种策略非常适合在YARN上使用spark-sql做数据开发和分析，以及将spark-sql作为长服务来使用的场景。Executor 的动态分配需要在 cluster mode 下启用 &ldquo;external shuffle service&rdquo;。</p></li>

<li><p><strong>动态资源分配策略</strong>：开启动态分配策略后，application会在task因没有足够资源被挂起的时候去动态申请资源，这意味着该application现有的executor无法满足所有task并行运行。spark一轮一轮的申请资源，当有task挂起或等待 <code>spark.dynamicAllocation.schedulerBacklogTimeout</code> (默认1s)时间的时候，会开始动态资源分配；之后会每隔 <code>spark.dynamicAllocation.sustainedSchedulerBacklogTimeout</code> (默认1s)时间申请一次，直到申请到足够的资源。每次申请的资源量是指数增长的，即1,2,4,8等。之所以采用指数增长，出于两方面考虑：其一，开始申请的少是考虑到可能application会马上得到满足；其次要成倍增加，是为了防止application需要很多资源，而该方式可以在很少次数的申请之后得到满足。</p></li>
</ul>

<h2 id="架构设计">架构设计</h2>

<p>关于 spark standalone 的局限性与 kubernetes native spark 架构之间的区别请参考 Anirudh Ramanathan 在 2016年10月8日提交的 issue <a href="https://github.com/kubernetes/kubernetes/issues/34377">Support Spark natively in Kubernetes #34377</a>。</p>

<p>简而言之，spark standalone on kubernetes 有如下几个缺点：</p>

<ul>
<li>无法对于多租户做隔离，每个用户都想给 pod 申请 node 节点可用的最大的资源。</li>
<li>Spark 的 master／worker 本来不是设计成使用 kubernetes 的资源调度，这样会存在两层的资源调度问题，不利于与 kuberentes 集成。</li>
</ul>

<p>而 kubernetes native spark 集群中，spark 可以调用 kubernetes API 获取集群资源和调度。要实现 kubernetes native spark 需要为 spark 提供一个集群外部的 manager 可以用来跟 kubernetes API 交互。</p>

<h3 id="调度器后台">调度器后台</h3>

<p>使用 kubernetes 原生调度的 spark 的基本设计思路是将 spark 的 driver 和 executor 都放在 kubernetes 的 pod 中运行，另外还有两个附加的组件：<code>ResourceStagingServer</code> 和 <code>KubernetesExternalShuffleService</code>。</p>

<p>Spark driver 其实可以运行在 kubernetes 集群内部（cluster mode）可以运行在外部（client mode），executor 只能运行在集群内部，当有 spark 作业提交到 kubernetes 集群上时，调度器后台将会为 executor pod 设置如下属性：</p>

<ul>
<li>使用我们预先编译好的包含 kubernetes 支持的 spark 镜像，然后调用 <code>CoarseGrainedExecutorBackend</code> main class 启动 JVM。</li>
<li>调度器后台为 executor pod 的运行时注入环境变量，例如各种 JVM 参数，包括用户在 <code>spark-submit</code> 时指定的那些参数。</li>
<li>Executor 的 CPU、内存限制根据这些注入的环境变量保存到应用程序的 <code>SparkConf</code> 中。</li>
<li>可以在配置中指定 spark 运行在指定的 namespace 中。</li>
</ul>

<p>参考：<a href="https://github.com/apache-spark-on-k8s/spark/blob/branch-2.2-kubernetes/resource-managers/kubernetes/architecture-docs/scheduler-backend.md">Scheduler backend 文档</a></p>

<h2 id="安装指南">安装指南</h2>

<p>我们可以直接使用官方已编译好的 docker 镜像来部署，下面是官方发布的镜像：</p>

<table>
<thead>
<tr>
<th>组件</th>
<th>镜像</th>
</tr>
</thead>

<tbody>
<tr>
<td>Spark Driver Image</td>
<td><code>kubespark/spark-driver:v2.1.0-kubernetes-0.3.1</code></td>
</tr>

<tr>
<td>Spark Executor Image</td>
<td><code>kubespark/spark-executor:v2.1.0-kubernetes-0.3.1</code></td>
</tr>

<tr>
<td>Spark Initialization Image</td>
<td><code>kubespark/spark-init:v2.1.0-kubernetes-0.3.1</code></td>
</tr>

<tr>
<td>Spark Staging Server Image</td>
<td><code>kubespark/spark-resource-staging-server:v2.1.0-kubernetes-0.3.1</code></td>
</tr>

<tr>
<td>PySpark Driver Image</td>
<td><code>kubespark/driver-py:v2.1.0-kubernetes-0.3.1</code></td>
</tr>

<tr>
<td>PySpark Executor Image</td>
<td><code>kubespark/executor-py:v2.1.0-kubernetes-0.3.1</code></td>
</tr>
</tbody>
</table>

<p>我将这些镜像放到了我的私有镜像仓库中了。</p>

<p>还需要安装支持 kubernetes 的 spark 客户端，在这里下载：<a href="https://github.com/apache-spark-on-k8s/spark/releases">https://github.com/apache-spark-on-k8s/spark/releases</a></p>

<p>根据使用的镜像版本，我下载的是 <a href="https://github.com/apache-spark-on-k8s/spark/releases/tag/v2.1.0-kubernetes-0.3.1">v2.1.0-kubernetes-0.3.1</a></p>

<p><strong>运行 SparkPi 测试</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="">./bin/spark-submit </span><span class="se">\
</span><span class="se"></span><span class="">  --deploy-mode cluster </span><span class="se">\
</span><span class="se"></span><span class="">  --class org.apache.spark.examples.SparkPi </span><span class="se">\
</span><span class="se"></span><span class="">  --master k8s://https://172.20.0.113:6443 </span><span class="se">\
</span><span class="se"></span><span class="">  --kubernetes-namespace spark-cluster </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.executor.instances</span><span class="o">=</span><span class="m">5</span><span class=""> </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.app.name</span><span class="o">=</span><span class="">spark-pi </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.kubernetes.driver.docker.image</span><span class="o">=</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/kubespark-spark-driver:v2.1.0-kubernetes-0.3.1 </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.kubernetes.executor.docker.image</span><span class="o">=</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/kubespark-spark-executor:v2.1.0-kubernetes-0.3.1 </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.kubernetes.initcontainer.docker.image</span><span class="o">=</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/kubespark-spark-init:v2.1.0-kubernetes-0.3.1 </span><span class="se">\
</span><span class="se"></span><span class="">local:///opt/spark/examples/jars/spark-examples_2.11-2.1.0-k8s-0.3.1-SNAPSHOT.jar</span></code></pre>
</div>
<p>关于该命令参数的介绍请参考：<a href="https://apache-spark-on-k8s.github.io/userdocs/running-on-kubernetes.html">https://apache-spark-on-k8s.github.io/userdocs/running-on-kubernetes.html</a></p>

<p><strong>注意：</strong> 该 jar 包实际上是 <code>spark.kubernetes.executor.docker.image</code> 镜像中的。</p>

<p>这时候提交任务运行还是失败，报错信息中可以看到两个问题：</p>

<ul>
<li>Executor 无法找到 driver pod</li>
<li>用户 <code>system:serviceaccount:spark-cluster:defaul</code> 没有权限获取 <code>spark-cluster</code> 中的 pod 信息。</li>
</ul>

<p>提了个 issue <a href="https://github.com/apache-spark-on-k8s/spark/issues/478">Failed to run the sample spark-pi test using spark-submit on the doc #478</a></p>

<p>需要为 spark 集群创建一个 <code>serviceaccount</code> 和 <code>clusterrolebinding</code>：</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="">kubectl create serviceaccount spark --namespace spark-cluster
</span><span class="">kubectl create rolebinding spark-edit --clusterrole</span><span class="o">=</span><span class="">edit --serviceaccount</span><span class="o">=</span><span class="">spark-cluster:spark --namespace</span><span class="o">=</span><span class="">spark-cluster</span></code></pre>
</div>
<p>该 Bug 将在新版本中修复。</p>

<h2 id="开发文档">开发文档</h2>

<h3 id="编译">编译</h3>

<p>Fork 并克隆项目到本地：</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="">git clone https://github.com/rootsongjc/spark.git</span></code></pre>
</div>
<p>编译前请确保你的环境中已经安装 Java8 和 Maven3。</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="c1">## 第一次编译前需要安装依赖
</span><span class="c1"></span><span class="">build/mvn install -Pkubernetes -pl resource-managers/kubernetes/core -am -DskipTests
</span><span class="">
</span><span class=""></span><span class="c1">## 编译 spark on kubernetes
</span><span class="c1"></span><span class="">build/mvn compile -Pkubernetes -pl resource-managers/kubernetes/core -am -DskipTests
</span><span class="">
</span><span class=""></span><span class="c1">## 发布
</span><span class="c1"></span><span class="">dev/make-distribution.sh --tgz -Phadoop-2.7 -Pkubernetes</span></code></pre>
</div>
<p>第一次编译和发布的过程耗时可能会比较长，请耐心等待，如果有依赖下载不下来，请自备梯子。</p>

<p>详细的开发指南请见：<a href="https://github.com/apache-spark-on-k8s/spark/blob/branch-2.2-kubernetes/resource-managers/kubernetes/README.md">https://github.com/apache-spark-on-k8s/spark/blob/branch-2.2-kubernetes/resource-managers/kubernetes/README.md</a></p>

<h3 id="构建镜像">构建镜像</h3>

<p>使用该脚本来自动构建容器镜像：<a href="https://github.com/apache-spark-on-k8s/spark/pull/488">https://github.com/apache-spark-on-k8s/spark/pull/488</a></p>

<p>将该脚本放在 <code>dist</code> 目录下，执行：</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="">./build-push-docker-images.sh -r sz-pg-oam-docker-hub-001.tendcloud.com/library -t v2.1.0-kubernetes-0.3.1-1 build
</span><span class="">./build-push-docker-images.sh -r sz-pg-oam-docker-hub-001.tendcloud.com/library -t v2.1.0-kubernetes-0.3.1-1 push</span></code></pre>
</div>
<p><strong>注意：</strong>如果你使用的 MacOS，bash 的版本可能太低，执行改脚本将出错，请检查你的 bash 版本：</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="">bash --version
</span><span class="">GNU bash, version </span><span class="m">3</span><span class="">.2.57</span><span class="o">(</span><span class="m">1</span><span class="o">)</span><span class="">-release </span><span class="o">(</span><span class="">x86_64-apple-darwin16</span><span class="o">)</span><span class="">
</span><span class="">Copyright </span><span class="o">(</span><span class="">C</span><span class="o">)</span><span class=""> </span><span class="m">2007</span><span class=""> Free Software Foundation, Inc.</span></code></pre>
</div>
<p>上面我在升级 bash 之前获取的版本信息，使用下面的命令升级 bash：</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="">brew install bash</span></code></pre>
</div>
<p>升级后的 bash 版本为 <code>4.4.12(1)-release (x86_64-apple-darwin16.3.0)</code>。</p>

<p>编译并上传镜像到我的私有镜像仓库，将会构建出如下几个镜像：</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1
</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-resource-staging-server:v2.1.0-kubernetes-0.3.1-1
</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-init:v2.1.0-kubernetes-0.3.1-1
</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-shuffle:v2.1.0-kubernetes-0.3.1-1
</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-executor:v2.1.0-kubernetes-0.3.1-1
</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-executor-py:v2.1.0-kubernetes-0.3.1-1
</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver-py:v2.1.0-kubernetes-0.3.1-1</span></code></pre>
</div>
<h2 id="运行测试">运行测试</h2>

<p>在 <code>dist/bin</code> 目录下执行 spark-pi 测试：</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="">./spark-submit </span><span class="se">\
</span><span class="se"></span><span class="">  --deploy-mode cluster </span><span class="se">\
</span><span class="se"></span><span class="">  --class org.apache.spark.examples.SparkPi </span><span class="se">\
</span><span class="se"></span><span class="">  --master k8s://https://172.20.0.113:6443 </span><span class="se">\
</span><span class="se"></span><span class="">  --kubernetes-namespace spark-cluster </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.kubernetes.authenticate.driver.serviceAccountName</span><span class="o">=</span><span class="">spark </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.executor.instances</span><span class="o">=</span><span class="m">5</span><span class=""> </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.app.name</span><span class="o">=</span><span class="">spark-pi </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.kubernetes.driver.docker.image</span><span class="o">=</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1 </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.kubernetes.executor.docker.image</span><span class="o">=</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-executor:v2.1.0-kubernetes-0.3.1-1 </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.kubernetes.initcontainer.docker.image</span><span class="o">=</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-init:v2.1.0-kubernetes-0.3.1-1 </span><span class="se">\
</span><span class="se"></span><span class="">local:///opt/spark/examples/jars/spark-examples_2.11-2.2.0-k8s-0.4.0-SNAPSHOT.jar</span></code></pre>
</div>
<p>详细的参数说明见：<a href="https://apache-spark-on-k8s.github.io/userdocs/running-on-kubernetes.html">https://apache-spark-on-k8s.github.io/userdocs/running-on-kubernetes.html</a></p>

<p><strong>注意：</strong><code>local:///opt/spark/examples/jars/spark-examples_2.11-2.2.0-k8s-0.4.0-SNAPSHOT.jar</code> 文件是在 <code>spark-driver</code> 和 <code>spark-executor</code> 镜像里的，在上一步构建镜像时已经构建并上传到了镜像仓库中。</p>

<p>执行日志显示：</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="m">2017</span><span class="">-09-14 </span><span class="m">14</span><span class="">:59:01 INFO  Client:54 - Waiting </span><span class="k">for</span><span class=""> application spark-pi to finish...
</span><span class=""></span><span class="m">2017</span><span class="">-09-14 </span><span class="m">14</span><span class="">:59:01 INFO  LoggingPodStatusWatcherImpl:54 - State changed, new state:
</span><span class="">	 pod name: spark-pi-1505372339796-driver
</span><span class="">	 namespace: spark-cluster
</span><span class="">	 labels: spark-app-selector -&gt; spark-f4d3a5d3ad964a05a51feb6191d50357, spark-role -&gt; driver
</span><span class="">	 pod uid: 304cf440-991a-11e7-970c-f4e9d49f8ed0
</span><span class="">	 creation time: </span><span class="m">2017</span><span class="">-09-14T06:59:01Z
</span><span class="">	 service account name: spark
</span><span class="">	 volumes: spark-token-zr8wv
</span><span class="">	 node name: N/A
</span><span class="">	 start time: N/A
</span><span class="">	 container images: N/A
</span><span class="">	 phase: Pending
</span><span class="">	 status: </span><span class="o">[]</span><span class="">
</span><span class=""></span><span class="m">2017</span><span class="">-09-14 </span><span class="m">14</span><span class="">:59:01 INFO  LoggingPodStatusWatcherImpl:54 - State changed, new state:
</span><span class="">	 pod name: spark-pi-1505372339796-driver
</span><span class="">	 namespace: spark-cluster
</span><span class="">	 labels: spark-app-selector -&gt; spark-f4d3a5d3ad964a05a51feb6191d50357, spark-role -&gt; driver
</span><span class="">	 pod uid: 304cf440-991a-11e7-970c-f4e9d49f8ed0
</span><span class="">	 creation time: </span><span class="m">2017</span><span class="">-09-14T06:59:01Z
</span><span class="">	 service account name: spark
</span><span class="">	 volumes: spark-token-zr8wv
</span><span class="">	 node name: </span><span class="m">172</span><span class="">.20.0.114
</span><span class="">	 start time: N/A
</span><span class="">	 container images: N/A
</span><span class="">	 phase: Pending
</span><span class="">	 status: </span><span class="o">[]</span><span class="">
</span><span class=""></span><span class="m">2017</span><span class="">-09-14 </span><span class="m">14</span><span class="">:59:01 INFO  LoggingPodStatusWatcherImpl:54 - State changed, new state:
</span><span class="">	 pod name: spark-pi-1505372339796-driver
</span><span class="">	 namespace: spark-cluster
</span><span class="">	 labels: spark-app-selector -&gt; spark-f4d3a5d3ad964a05a51feb6191d50357, spark-role -&gt; driver
</span><span class="">	 pod uid: 304cf440-991a-11e7-970c-f4e9d49f8ed0
</span><span class="">	 creation time: </span><span class="m">2017</span><span class="">-09-14T06:59:01Z
</span><span class="">	 service account name: spark
</span><span class="">	 volumes: spark-token-zr8wv
</span><span class="">	 node name: </span><span class="m">172</span><span class="">.20.0.114
</span><span class="">	 start time: </span><span class="m">2017</span><span class="">-09-14T06:59:01Z
</span><span class="">	 container images: sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1
</span><span class="">	 phase: Pending
</span><span class="">	 status: </span><span class="o">[</span><span class="">ContainerStatus</span><span class="o">(</span><span class="nv">containerID</span><span class=""></span><span class="o">=</span><span class="">null, </span><span class="nv">image</span><span class=""></span><span class="o">=</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1, </span><span class="nv">imageID</span><span class=""></span><span class="o">=</span><span class="">, </span><span class="nv">lastState</span><span class=""></span><span class="o">=</span><span class="">ContainerState</span><span class="o">(</span><span class="nv">running</span><span class=""></span><span class="o">=</span><span class="">null, </span><span class="nv">terminated</span><span class=""></span><span class="o">=</span><span class="">null, </span><span class="nv">waiting</span><span class=""></span><span class="o">=</span><span class="">null, </span><span class="nv">additionalProperties</span><span class=""></span><span class="o">={})</span><span class="">, </span><span class="nv">name</span><span class=""></span><span class="o">=</span><span class="">spark-kubernetes-driver, </span><span class="nv">ready</span><span class=""></span><span class="o">=</span><span class="">false, </span><span class="nv">restartCount</span><span class=""></span><span class="o">=</span><span class="m">0</span><span class="">, </span><span class="nv">state</span><span class=""></span><span class="o">=</span><span class="">ContainerState</span><span class="o">(</span><span class="nv">running</span><span class=""></span><span class="o">=</span><span class="">null, </span><span class="nv">terminated</span><span class=""></span><span class="o">=</span><span class="">null, </span><span class="nv">waiting</span><span class=""></span><span class="o">=</span><span class="">ContainerStateWaiting</span><span class="o">(</span><span class="nv">message</span><span class=""></span><span class="o">=</span><span class="">null, </span><span class="nv">reason</span><span class=""></span><span class="o">=</span><span class="">ContainerCreating, </span><span class="nv">additionalProperties</span><span class=""></span><span class="o">={})</span><span class="">, </span><span class="nv">additionalProperties</span><span class=""></span><span class="o">={})</span><span class="">, </span><span class="nv">additionalProperties</span><span class=""></span><span class="o">={})]</span><span class="">
</span><span class=""></span><span class="m">2017</span><span class="">-09-14 </span><span class="m">14</span><span class="">:59:03 INFO  LoggingPodStatusWatcherImpl:54 - State changed, new state:
</span><span class="">	 pod name: spark-pi-1505372339796-driver
</span><span class="">	 namespace: spark-cluster
</span><span class="">	 labels: spark-app-selector -&gt; spark-f4d3a5d3ad964a05a51feb6191d50357, spark-role -&gt; driver
</span><span class="">	 pod uid: 304cf440-991a-11e7-970c-f4e9d49f8ed0
</span><span class="">	 creation time: </span><span class="m">2017</span><span class="">-09-14T06:59:01Z
</span><span class="">	 service account name: spark
</span><span class="">	 volumes: spark-token-zr8wv
</span><span class="">	 node name: </span><span class="m">172</span><span class="">.20.0.114
</span><span class="">	 start time: </span><span class="m">2017</span><span class="">-09-14T06:59:01Z
</span><span class="">	 container images: sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1
</span><span class="">	 phase: Running
</span><span class="">	 status: </span><span class="o">[</span><span class="">ContainerStatus</span><span class="o">(</span><span class="nv">containerID</span><span class=""></span><span class="o">=</span><span class="">docker://5c5c821c482a1e35552adccb567020532b79244392374f25754f0050e6cd4c62, </span><span class="nv">image</span><span class=""></span><span class="o">=</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1, </span><span class="nv">imageID</span><span class=""></span><span class="o">=</span><span class="">docker-pullable://sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver@sha256:beb92a3e3f178e286d9e5baebdead88b5ba76d651f347ad2864bb6f8eda26f94, </span><span class="nv">lastState</span><span class=""></span><span class="o">=</span><span class="">ContainerState</span><span class="o">(</span><span class="nv">running</span><span class=""></span><span class="o">=</span><span class="">null, </span><span class="nv">terminated</span><span class=""></span><span class="o">=</span><span class="">null, </span><span class="nv">waiting</span><span class=""></span><span class="o">=</span><span class="">null, </span><span class="nv">additionalProperties</span><span class=""></span><span class="o">={})</span><span class="">, </span><span class="nv">name</span><span class=""></span><span class="o">=</span><span class="">spark-kubernetes-driver, </span><span class="nv">ready</span><span class=""></span><span class="o">=</span><span class="">true, </span><span class="nv">restartCount</span><span class=""></span><span class="o">=</span><span class="m">0</span><span class="">, </span><span class="nv">state</span><span class=""></span><span class="o">=</span><span class="">ContainerState</span><span class="o">(</span><span class="nv">running</span><span class=""></span><span class="o">=</span><span class="">ContainerStateRunning</span><span class="o">(</span><span class="nv">startedAt</span><span class=""></span><span class="o">=</span><span class="m">2017</span><span class="">-09-14T06:59:02Z, </span><span class="nv">additionalProperties</span><span class=""></span><span class="o">={})</span><span class="">, </span><span class="nv">terminated</span><span class=""></span><span class="o">=</span><span class="">null, </span><span class="nv">waiting</span><span class=""></span><span class="o">=</span><span class="">null, </span><span class="nv">additionalProperties</span><span class=""></span><span class="o">={})</span><span class="">, </span><span class="nv">additionalProperties</span><span class=""></span><span class="o">={})]</span><span class="">
</span><span class=""></span><span class="m">2017</span><span class="">-09-14 </span><span class="m">14</span><span class="">:59:12 INFO  LoggingPodStatusWatcherImpl:54 - State changed, new state:
</span><span class="">	 pod name: spark-pi-1505372339796-driver
</span><span class="">	 namespace: spark-cluster
</span><span class="">	 labels: spark-app-selector -&gt; spark-f4d3a5d3ad964a05a51feb6191d50357, spark-role -&gt; driver
</span><span class="">	 pod uid: 304cf440-991a-11e7-970c-f4e9d49f8ed0
</span><span class="">	 creation time: </span><span class="m">2017</span><span class="">-09-14T06:59:01Z
</span><span class="">	 service account name: spark
</span><span class="">	 volumes: spark-token-zr8wv
</span><span class="">	 node name: </span><span class="m">172</span><span class="">.20.0.114
</span><span class="">	 start time: </span><span class="m">2017</span><span class="">-09-14T06:59:01Z
</span><span class="">	 container images: sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1
</span><span class="">	 phase: Succeeded
</span><span class="">	 status: </span><span class="o">[</span><span class="">ContainerStatus</span><span class="o">(</span><span class="nv">containerID</span><span class=""></span><span class="o">=</span><span class="">docker://5c5c821c482a1e35552adccb567020532b79244392374f25754f0050e6cd4c62, </span><span class="nv">image</span><span class=""></span><span class="o">=</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1, </span><span class="nv">imageID</span><span class=""></span><span class="o">=</span><span class="">docker-pullable://sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver@sha256:beb92a3e3f178e286d9e5baebdead88b5ba76d651f347ad2864bb6f8eda26f94, </span><span class="nv">lastState</span><span class=""></span><span class="o">=</span><span class="">ContainerState</span><span class="o">(</span><span class="nv">running</span><span class=""></span><span class="o">=</span><span class="">null, </span><span class="nv">terminated</span><span class=""></span><span class="o">=</span><span class="">null, </span><span class="nv">waiting</span><span class=""></span><span class="o">=</span><span class="">null, </span><span class="nv">additionalProperties</span><span class=""></span><span class="o">={})</span><span class="">, </span><span class="nv">name</span><span class=""></span><span class="o">=</span><span class="">spark-kubernetes-driver, </span><span class="nv">ready</span><span class=""></span><span class="o">=</span><span class="">false, </span><span class="nv">restartCount</span><span class=""></span><span class="o">=</span><span class="m">0</span><span class="">, </span><span class="nv">state</span><span class=""></span><span class="o">=</span><span class="">ContainerState</span><span class="o">(</span><span class="nv">running</span><span class=""></span><span class="o">=</span><span class="">null, </span><span class="nv">terminated</span><span class=""></span><span class="o">=</span><span class="">ContainerStateTerminated</span><span class="o">(</span><span class="nv">containerID</span><span class=""></span><span class="o">=</span><span class="">docker://5c5c821c482a1e35552adccb567020532b79244392374f25754f0050e6cd4c62, </span><span class="nv">exitCode</span><span class=""></span><span class="o">=</span><span class="m">0</span><span class="">, </span><span class="nv">finishedAt</span><span class=""></span><span class="o">=</span><span class="m">2017</span><span class="">-09-14T06:59:11Z, </span><span class="nv">message</span><span class=""></span><span class="o">=</span><span class="">null, </span><span class="nv">reason</span><span class=""></span><span class="o">=</span><span class="">Completed, </span><span class="nv">signal</span><span class=""></span><span class="o">=</span><span class="">null, </span><span class="nv">startedAt</span><span class=""></span><span class="o">=</span><span class="">null, </span><span class="nv">additionalProperties</span><span class=""></span><span class="o">={})</span><span class="">, </span><span class="nv">waiting</span><span class=""></span><span class="o">=</span><span class="">null, </span><span class="nv">additionalProperties</span><span class=""></span><span class="o">={})</span><span class="">, </span><span class="nv">additionalProperties</span><span class=""></span><span class="o">={})]</span><span class="">
</span><span class=""></span><span class="m">2017</span><span class="">-09-14 </span><span class="m">14</span><span class="">:59:12 INFO  LoggingPodStatusWatcherImpl:54 - Container final statuses:
</span><span class="">
</span><span class="">
</span><span class="">	 Container name: spark-kubernetes-driver
</span><span class="">	 Container image: sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1
</span><span class="">	 Container state: Terminated
</span><span class="">	 Exit code: </span><span class="m">0</span><span class="">
</span><span class=""></span><span class="m">2017</span><span class="">-09-14 </span><span class="m">14</span><span class="">:59:12 INFO  Client:54 - Application spark-pi finished.</span></code></pre>
</div>
<p>从日志中可以看到任务运行的状态信息。</p>

<p>使用下面的命令可以看到 kubernetes 启动的 Pod 信息：</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="">kubectl --namespace spark-cluster get pods -w</span></code></pre>
</div>
<p>将会看到 <code>spark-driver</code> 和 <code>spark-exec</code> 的 Pod 信息。</p>

<h2 id="依赖管理">依赖管理</h2>

<p>上文中我们在运行测试程序时，命令行中指定的 jar 文件已包含在 docker 镜像中，是不是说我们每次提交任务都需要重新创建一个镜像呢？非也！如果真是这样也太麻烦了。</p>

<h4 id="创建-resource-staging-server">创建 resource staging server</h4>

<p>为了方便用户提交任务，不需要每次提交任务的时候都创建一个镜像，我们使用了 <strong>resource staging server</strong> 。</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="">kubectl create -f conf/kubernetes-resource-staging-server.yaml</span></code></pre>
</div>
<p>我们同样将其部署在 <code>spark-cluster</code> namespace 下，该 yaml 文件见 <a href="https://github.com/rootsongjc/kubernetes-handbook">kubernetes-handbook</a> 的 <code>manifests/spark-with-kubernetes-native-scheduler</code> 目录。</p>

<h4 id="优化">优化</h4>

<p>其中有一点需要优化，在使用下面的命令提交任务时，使用 <code>--conf spark.kubernetes.resourceStagingServer.uri</code> 参数指定 <em>resource staging server</em> 地址，用户不应该关注 <em>resource staging server</em> 究竟运行在哪台宿主机上，可以使用下面两种方式实现：</p>

<ul>
<li>使用 <code>nodeSelector</code> 将 <em>resource staging server</em> 固定调度到某一台机器上，该地址依然使用宿主机的 IP 地址</li>
<li>改变 <code>spark-resource-staging-service</code> service 的 type 为 <strong>ClusterIP</strong>， 然后使用 <strong>Ingress</strong> 将其暴露到集群外部，然后加入的内网 DNS 里，用户使用 DNS 名称指定 <em>resource staging server</em> 的地址。</li>
</ul>

<p>然后可以执行下面的命令来提交本地的 jar 到 kubernetes 上运行。</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="">./spark-submit </span><span class="se">\
</span><span class="se"></span><span class="">  --deploy-mode cluster </span><span class="se">\
</span><span class="se"></span><span class="">  --class org.apache.spark.examples.SparkPi </span><span class="se">\
</span><span class="se"></span><span class="">  --master k8s://https://172.20.0.113:6443 </span><span class="se">\
</span><span class="se"></span><span class="">  --kubernetes-namespace spark-cluster </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.kubernetes.authenticate.driver.serviceAccountName</span><span class="o">=</span><span class="">spark </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.executor.instances</span><span class="o">=</span><span class="m">5</span><span class=""> </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.app.name</span><span class="o">=</span><span class="">spark-pi </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.kubernetes.driver.docker.image</span><span class="o">=</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1 </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.kubernetes.executor.docker.image</span><span class="o">=</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-executor:v2.1.0-kubernetes-0.3.1-1 </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.kubernetes.initcontainer.docker.image</span><span class="o">=</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-init:v2.1.0-kubernetes-0.3.1-1 </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.kubernetes.resourceStagingServer.uri</span><span class="o">=</span><span class="">http://172.20.0.114:31000 </span><span class="se">\
</span><span class="se"></span><span class="">  ../examples/jars/spark-examples_2.11-2.2.0-k8s-0.4.0-SNAPSHOT.jar</span></code></pre>
</div>
<p>该命令将提交本地的 <code>../examples/jars/spark-examples_2.11-2.2.0-k8s-0.4.0-SNAPSHOT.jar</code> 文件到 <strong>resource staging server</strong>，executor 将从该 server 上获取 jar 包并运行，这样用户就不需要每次提交任务都编译一个镜像了。</p>

<p>详见：<a href="https://apache-spark-on-k8s.github.io/userdocs/running-on-kubernetes.html#dependency-management">https://apache-spark-on-k8s.github.io/userdocs/running-on-kubernetes.html#dependency-management</a></p>

<h4 id="设置-hdfs-用户">设置 HDFS 用户</h4>

<p>如果 Hadoop 集群没有设置 kerbros 安全认证的话，在指定 <code>spark-submit</code> 的时候可以通过指定如下四个环境变量， 设置 Spark 与 HDFS 通信使用的用户：</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="">  --conf spark.kubernetes.driverEnv.SPARK_USER</span><span class="o">=</span><span class="">hadoop 
</span><span class="">  --conf spark.kubernetes.driverEnv.HADOOP_USER_NAME</span><span class="o">=</span><span class="">hadoop 
</span><span class="">  --conf spark.executorEnv.HADOOP_USER_NAME</span><span class="o">=</span><span class="">hadoop 
</span><span class="">  --conf spark.executorEnv.SPARK_USER</span><span class="o">=</span><span class="">hadoop </span></code></pre>
</div>
<p>使用 hadoop 用户提交本地 jar 包的命令示例：</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="">./spark-submit </span><span class="se">\
</span><span class="se"></span><span class="">  --deploy-mode cluster </span><span class="se">\
</span><span class="se"></span><span class="">  --class com.talkingdata.alluxio.hadooptest </span><span class="se">\
</span><span class="se"></span><span class="">  --master k8s://https://172.20.0.113:6443 </span><span class="se">\
</span><span class="se"></span><span class="">  --kubernetes-namespace spark-cluster </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.kubernetes.driverEnv.SPARK_USER</span><span class="o">=</span><span class="">hadoop </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.kubernetes.driverEnv.HADOOP_USER_NAME</span><span class="o">=</span><span class="">hadoop </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.executorEnv.HADOOP_USER_NAME</span><span class="o">=</span><span class="">hadoop </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.executorEnv.SPARK_USER</span><span class="o">=</span><span class="">hadoop </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.kubernetes.authenticate.driver.serviceAccountName</span><span class="o">=</span><span class="">spark </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.executor.instances</span><span class="o">=</span><span class="m">5</span><span class=""> </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.app.name</span><span class="o">=</span><span class="">spark-pi </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.kubernetes.driver.docker.image</span><span class="o">=</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-driver:v2.1.0-kubernetes-0.3.1-1 </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.kubernetes.executor.docker.image</span><span class="o">=</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-executor:v2.1.0-kubernetes-0.3.1-1 </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.kubernetes.initcontainer.docker.image</span><span class="o">=</span><span class="">sz-pg-oam-docker-hub-001.tendcloud.com/library/spark-init:v2.1.0-kubernetes-0.3.1-1 </span><span class="se">\
</span><span class="se"></span><span class="">  --conf spark.kubernetes.resourceStagingServer.uri</span><span class="o">=</span><span class="">http://172.20.0.114:31000 </span><span class="se">\
</span><span class="se"></span><span class="">~/Downloads/tendcloud_2.10-1.0.jar</span></code></pre>
</div>
<p>详见：<a href="https://github.com/apache-spark-on-k8s/spark/issues/408">https://github.com/apache-spark-on-k8s/spark/issues/408</a></p>

<h2 id="参考">参考</h2>

<p><a href="http://lxw1234.com/archives/2015/12/593.htm">Spark动态资源分配-Dynamic Resource Allocation</a></p>

<p><a href="https://apache-spark-on-k8s.github.io/userdocs/running-on-kubernetes.html">Running Spark on Kubernetes</a></p>

<p><a href="https://issues.apache.org/jira/browse/SPARK-18278">Apache Spark Jira Issue - 18278 - SPIP: Support native submission of spark jobs to a kubernetes cluster</a></p>

<p><a href="https://github.com/kubernetes/kubernetes/issues/34377">Kubernetes Github Issue - 34377 Support Spark natively in Kubernetes</a></p>

<p><a href="https://github.com/kubernetes/kubernetes/tree/master/examples/spark">Kubernetes example spark</a></p>

<p><a href="https://github.com/rootsongjc/spark-on-kubernetes">https://github.com/rootsongjc/spark-on-kubernetes</a></p>

            </article>
             
            <h2>See Also</h2>
            <ul>
                
                <li><a href="/blogs/3-things-every-cto-should-know-about-kubernetes/">每位CTO都该知道的关于kubernetes的三件事</a></li>
                
                <li><a href="/blogs/kubectl-user-authentication-authorization/">kubectl的用户认证授权</a></li>
                
                <li><a href="/blogs/migrating-hadoop-yarn-to-kubernetes/">迁移传统应用到Kubernetes步骤详解——以Hadoop YARN为例</a></li>
                
                <li><a href="/blogs/kubernetes-tls-bootstrapping/">Kubernetes TLS bootstrap引导程序</a></li>
                
                <li><a href="/blogs/linkerd-user-guide/">Linkerd 使用指南</a></li>
                
            </ul>
            
        </div>
    </section>

    

<aside id="meta">

<div>
    <section id="datecount">
        <h4 id="date"> Thu Sep 14, 2017 </h4>
        <h5 id="wc"> 4700 Words </h5>
        <h5 id="readtime"> Read in about 10 Min </h5>
    </section>
    <ul id="categories">
        
    </ul>
    <ul id="tags">
        
        <li> <a href="https://jimmysong.io//tags/kubernetes">kubernetes</a> </li>
        
        <li> <a href="https://jimmysong.io//tags/spark">spark</a> </li>
        
        <li> <a href="https://jimmysong.io//tags/big-data">big-data</a> </li>
        
    </ul>
</div>

<div>
    <section id="prev">
        &nbsp;<a class="previous" href="https://jimmysong.io/blogs/creating-cloud-native-app-with-kubernetes/"><i class="icon-arrow-left"></i> 如何开发部署kubernetes native应用</a><br>
    </section>
    <section id="next">
        &nbsp;<a class="next" href="https://jimmysong.io/blogs/3-things-every-cto-should-know-about-kubernetes/">每位CTO都该知道的关于kubernetes的三件事 <i class="icon-arrow-right"></i></a>
    </section>
</div>

<div>
    <section id="author">
        <h4>About the Author</h4>
        <p>
            <a href="https://jimmysong.io/about/">Jimmy Song</a> is a software engineer in Beijing, also an open source enthusiast and Big Data, Cloud Native fans. If you not see him front of computer, he must be traveling or taking pictures outside,
            visit the amazing pictures at <a href=https://jimmysongio.tuchong.com/>tuchong(图虫)</a>. Feel free to <a href=https://twitter.com/jimmysongio>follow him on twitter</a>.
        </p>
    </section>

</div>

</aside>

<meta itemprop="wordCount" content="4684">
<meta itemprop="datePublished" content="2017-09-14">
<meta itemprop="url" content="https://jimmysong.io/blogs/running-spark-with-kubernetes-native-scheduler/">
 <aside id=comments>
    <div>
        <h2> Comments </h2>
    </div>
    
    
    
    <div id="container"></div>
    <link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
    <script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
    <script>
        var gitment = new Gitment({
            owner: 'rootsongjc', 
            repo: 'rootsongjc.github.io', 
            oauth: {
                client_id: '93a0df08e0f93ff0c8a3',
                client_secret: '3bdbf0b42c525f78582600bd38cf7f722ee40541',
            },
        })
        gitment.render('container')
    </script>
</aside> <footer>
    <div>
        <p>
            <a href="https://jimmysong.io/kubernetes-handbook">Kubernetes Handbook中文指南/实践手册</a> |
            <a href="https://jimmysong.io/cloud-native-go">Cloud Native Go</a> |
            <a href="https://jimmysong.io/awesome-cloud-native">Awesome Cloud Native</a> |
            <a href="https://jimmysong.io/migrating-to-cloud-native-application-architectures">迁移到云原生应用架构手册</a> |
            <a href="https://istio.doczh.cn/">Istio Service Mesh中文文档</a> |
            <a href="https://jimmysong.io/spark-on-k8s">Spark on Kubernetes</a> |
            Cloud Native Python comming soon...
    </div>
    <div>
        <p>

        </p>
        <p>Copyright &copy; 2013-2017 <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span itemprop="name"><a href="https://jimmysong.io/about">Jimmy Song</a></span><span>
                Powered by <a href="https://gohugo.io">Hugo</a> ❤️  &nbsp; </span> <span> Theme <a href="https://themes.gohugo.io/nixon/">nixon</a></span>
            </span>
    </div>
</footer>


</body>

</html>

    
