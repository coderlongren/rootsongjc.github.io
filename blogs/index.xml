<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on Jimmy&#39;s blog</title>
    <link>http://rootsongjc.github.io/blogs/index.xml</link>
    <description>Recent content in Blogs on Jimmy&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 19 Mar 2017 23:00:29 +0800</lastBuildDate>
    <atom:link href="http://rootsongjc.github.io/blogs/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Docker源码分析第一篇——代码结构</title>
      <link>http://rootsongjc.github.io/blogs/docker-source-code-analysis-code-structure/</link>
      <pubDate>Sun, 19 Mar 2017 23:00:29 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/docker-source-code-analysis-code-structure/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20151001042.jpg&#34; alt=&#34;八达岭长城&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(题图：北京八达岭长城  Oct 1,2015)&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;之前陆陆续续看过一点&lt;strong&gt;docker&lt;/strong&gt;的源码，都未成体系，最近在研究&lt;strong&gt;Docker-17.03-CE&lt;/strong&gt;，趁此机会研究下docker的源码，在网上找到一些相关资料，都比较过时了，发现*孙宏亮*大哥写过一本书叫《Docker源码分析》，而且之前也在&lt;strong&gt;InfoQ&lt;/strong&gt;上陆续发过一些文章，虽然文章都比较老了，基于老的docker版本，但我认为依然有阅读的价值。起码能有这三方面收获：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一是培养阅读源码的思维方式，为自己阅读docker源码提供借鉴。&lt;/li&gt;
&lt;li&gt;二是可以了解docker版本的来龙去脉。&lt;/li&gt;
&lt;li&gt;三还可以作为Go语言项目开发作为借鉴。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;下载地址&#34;&gt;下载地址&lt;/h3&gt;

&lt;p&gt;鉴于这本书已经发行一年半了了，基于的docker版本还是&lt;strong&gt;1.2.0&lt;/strong&gt;，而如今都到了&lt;strong&gt;1.13.0&lt;/strong&gt;（docker17.03的老版本号），应该很少有人买了吧，可以说这本书的纸质版本的生命周期也差不多了吧。如果有人感兴趣可以下载pdf版本看看，&lt;a href=&#34;http://olz1di9xf.bkt.clouddn.com/Docker%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%AD%99%E5%AE%8F%E4%BA%AE%E8%91%97.pdf&#34;&gt;Docker源码解析-机械工业出版社-孙宏亮著-2015年8月&lt;/a&gt;（完整文字版，大小25.86M），&lt;a href=&#34;http://olz1di9xf.bkt.clouddn.com/Docker%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%AD%99%E5%AE%8F%E4%BA%AE-%E7%9C%8B%E4%BA%91%E7%89%88.pdf&#34;&gt;Docker源码解析-看云整理版&lt;/a&gt;（文字版，有缩略，大小7.62M）。&lt;/p&gt;

&lt;h2 id=&#34;out-of-date&#34;&gt;Out-of-date&lt;/h2&gt;

&lt;p&gt;有一点必须再次强调一下，这本书中的docker源码分析是基于&lt;strong&gt;docker1.2.0&lt;/strong&gt;，而这个版本的docker源码在github上已经无法下载到了，github上available的最低版本的docker源码是&lt;strong&gt;1.4.1&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;顺便感叹一句，科技行业发展实在太快了，尤其是互联网，一本书能连续用上三年都不过时，如果这样的话那么这门技术恐怕都就要被淘汰了吧？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;总体架构&#34;&gt;总体架构&lt;/h2&gt;

&lt;p&gt;Docker总体上是用的是&lt;strong&gt;Client/Server&lt;/strong&gt;模式，所有的命令都可以通过RESTful接口传递。&lt;/p&gt;

&lt;p&gt;整个Docker软件的架构中可以分成三个角色：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Daemon&lt;/strong&gt;：常驻后台运行的进程，接收客户端请求，管理docker容器。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clien&lt;/strong&gt;t：命令行终端，包装命令发送API请求。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;：真正处理客户端请求的后端程序。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;代码结构&#34;&gt;代码结构&lt;/h2&gt;

&lt;p&gt;Docker的代码结构比较清晰，分成的目录比较多，有以下这些：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;api&lt;/strong&gt;：定义API，使用了&lt;strong&gt;Swagger2.0&lt;/strong&gt;这个工具来生成API，配置文件在&lt;code&gt;api/swagger.yaml&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;builder&lt;/strong&gt;：用来build docker镜像的包，看来历史比较悠久了&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bundles&lt;/strong&gt;：这个包是在进行&lt;a href=&#34;http://rootsongjc.github.io/blogs/docker-dev-env/&#34;&gt;docker源码编译和开发环境搭建&lt;/a&gt;的时候用到的，编译生成的二进制文件都在这里。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;cli&lt;/strong&gt;：使用&lt;a href=&#34;http://www.github.com/spf13/cobra&#34;&gt;cobra&lt;/a&gt;工具生成的docker客户端命令行解析器。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;client&lt;/strong&gt;：接收&lt;code&gt;cli&lt;/code&gt;的请求，调用RESTful API中的接口，向server端发送http请求。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;cmd&lt;/strong&gt;：其中包括&lt;code&gt;docker&lt;/code&gt;和&lt;code&gt;dockerd&lt;/code&gt;两个包，他们分别包含了客户端和服务端的main函数入口。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;container&lt;/strong&gt;：容器的配置管理，对不同的platform适配。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;contrib&lt;/strong&gt;：这个目录包括一些有用的脚本、镜像和其他非docker core中的部分。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;daemon&lt;/strong&gt;：这个包中将docker deamon运行时状态expose出来。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;distribution&lt;/strong&gt;：负责docker镜像的pull、push和镜像仓库的维护。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;dockerversion&lt;/strong&gt;：编译的时候自动生成的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;docs&lt;/strong&gt;：文档。这个目录已经不再维护，文档在另一个仓库里&lt;a href=&#34;https://github.com/docker/docker.github.io/。&#34;&gt;https://github.com/docker/docker.github.io/。&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;experimental&lt;/strong&gt;：从docker1.13.0版本起开始增加了实验特性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;hack&lt;/strong&gt;：创建docker开发环境和编译打包时用到的脚本和配置文件。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;image&lt;/strong&gt;：用于构建docker镜像的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;integration-cli&lt;/strong&gt;：集成测试&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;layer&lt;/strong&gt;：管理 union file system driver上的read-only和read-write mounts。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;libcontainerd&lt;/strong&gt;：访问内核中的容器系统调用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;man&lt;/strong&gt;：生成man pages。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;migrate&lt;/strong&gt;：将老版本的graph目录转换成新的metadata。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;oci&lt;/strong&gt;：Open Container Interface库&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;opts&lt;/strong&gt;：命令行的选项库。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pkg&lt;/strong&gt;：&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;plugin&lt;/strong&gt;：docker插件后端实现包。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;profiles&lt;/strong&gt;：里面有apparmor和seccomp两个目录。用于内核访问控制。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;project&lt;/strong&gt;：项目管理的一些说明文档。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;reference&lt;/strong&gt;：处理docker store中镜像的reference。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;registry&lt;/strong&gt;：docker registry的实现。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;restartmanager&lt;/strong&gt;：处理重启后的动作。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;runconfig&lt;/strong&gt;：配置格式解码和校验。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;vendor&lt;/strong&gt;：各种依赖包。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;volume&lt;/strong&gt;：docker volume的实现。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下一篇将讲解docker的各个功能模块和原理。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Contiv Ultimate-Docker17.03CE下思科docker网络插件contiv趟坑终极版（持续更新中）</title>
      <link>http://rootsongjc.github.io/blogs/contiv-ultimate/</link>
      <pubDate>Fri, 17 Mar 2017 17:52:37 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/contiv-ultimate/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20140810001.jpg&#34; alt=&#34;广州石牌桥&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：广州石牌桥 Aug 10,2014）&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;前几天写的几篇&lt;a href=&#34;http://rootsongjc.github.io/tags/contiv/&#34;&gt;关于Contiv的文章&lt;/a&gt;已经把引入坑了😂&lt;/p&gt;

&lt;p&gt;今天这篇文章将带领大家用正确的姿势编译和打包一个&lt;strong&gt;contiv netplugin&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;请一定要在&lt;strong&gt;Linux&lt;/strong&gt;环境中编译。docker中编译也会报错，最好还是搞个虚拟🐔吧，最好还有VPN能翻墙。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;环境准备&#34;&gt;环境准备&lt;/h2&gt;

&lt;p&gt;我使用的是docker17.03-CE、安装了open vSwitch(这个包redhat的源里没有，需要自己的编译安装)，如果你懒得编译可以用我编译的rpm包，&lt;a href=&#34;http://olz1di9xf.bkt.clouddn.com/openvswitch-2.5.0-2.el7.x86_64.rpm&#34;&gt;点这里下载&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;编译&#34;&gt;编译&lt;/h2&gt;

&lt;p&gt;这一步是很容易失败的，有人提过&lt;a href=&#34;https://github.com/contiv/netplugin/issues/779&#34;&gt;issue-779&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;具体步骤&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;创建一个link &lt;strong&gt;/go&lt;/strong&gt;链接到你的GOPATH目录，下面编译的时候要用。&lt;/li&gt;
&lt;li&gt;将源码的&lt;strong&gt;vender&lt;/strong&gt;目录下的文件拷贝到$GOPATH/src目录。&lt;/li&gt;
&lt;li&gt;执行编译&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在netplugin目录下执行以下命令能够编译出二进制文件。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;NET_CONTAINER_BUILD=1 make build
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在你的&lt;strong&gt;/$GOPATH/bin&lt;/strong&gt;目录下应该会有如下几个文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;contivk8s  github-release  godep  golint  misspell  modelgen  netcontiv  netctl  netmaster  netplugin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;⚠️编译过程中可能会遇到 有些包不存在或者需要翻墙下载。&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;打包&#34;&gt;打包&lt;/h2&gt;

&lt;p&gt;我们将其打包为docker plugin。&lt;/p&gt;

&lt;p&gt;Makefile里用于创建plugin rootfs的命令是：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Makefile&#34;&gt;host-pluginfs-create:
        @echo dev: creating a docker v2plugin rootfs ...
        sh scripts/v2plugin_rootfs.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;v2plugin_rootfs.sh&lt;/strong&gt;这个脚本的内容：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;#!/bin/bash
# Script to create the docker v2 plugin
# run this script from contiv/netplugin directory

echo &amp;quot;Creating rootfs for v2plugin &amp;quot;, ${CONTIV_V2PLUGIN_NAME}
cat install/v2plugin/config.template | grep -v &amp;quot;##&amp;quot; &amp;gt; install/v2plugin/config.json
sed -i &amp;quot;s%PluginName%${CONTIV_V2PLUGIN_NAME}%&amp;quot; install/v2plugin/config.json
cp bin/netplugin bin/netmaster bin/netctl install/v2plugin
docker build -t contivrootfs install/v2plugin
id=$(docker create contivrootfs true)
mkdir -p install/v2plugin/rootfs
sudo docker export &amp;quot;${id}&amp;quot; | sudo tar -x -C install/v2plugin/rootfs
docker rm -vf &amp;quot;${id}&amp;quot;
docker rmi contivrootfs
rm install/v2plugin/netplugin install/v2plugin/netmaster install/v2plugin/netctl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;先把&lt;code&gt;$GOPATH/bin&lt;/code&gt;下生成的&lt;code&gt;netplugin&lt;/code&gt;、&lt;code&gt;netmaster&lt;/code&gt;、&lt;code&gt;netctl&lt;/code&gt;、&lt;code&gt;netplugin&lt;/code&gt;这几个二进制文件拷贝到netplugin源码的bin目录下。&lt;/p&gt;

&lt;p&gt;这里面用语创建contivrootfs镜像的Dockerfile内容：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Dockerfile&#34;&gt;# Docker v2plugin container with OVS / netplugin / netmaster 

FROM alpine:3.5
MAINTAINER Cisco Contiv (http://contiv.github.io/)

RUN mkdir -p /run/docker/plugins /etc/openvswitch /var/run/contiv/log \
    &amp;amp;&amp;amp; echo &#39;http://dl-cdn.alpinelinux.org/alpine/v3.4/main&#39; &amp;gt;&amp;gt; /etc/apk/repositories \
    &amp;amp;&amp;amp; apk update &amp;amp;&amp;amp; apk add openvswitch=2.5.0-r0 iptables

COPY netplugin netmaster netctl startcontiv.sh /

ENTRYPOINT [&amp;quot;/startcontiv.sh&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行&lt;code&gt;make host-pluginfs-create&lt;/code&gt;创建rootfs。&lt;/p&gt;

&lt;p&gt;创建出了rootfs后，然后执行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;docker plugin create localhost:5000/contiv/netplugin .
docker push localhost:5000/contiv/netplugin
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;注：我们将插件push到docker registry的镜像仓库中，当前&lt;a href=&#34;www.github.com/vmware/harbor&#34;&gt;Harbor&lt;/a&gt;还不支持docker插件的push。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Install plugin&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;下面是编译和安装我自己生成v2plugin的过程。&lt;/p&gt;

&lt;p&gt;修改&lt;strong&gt;config.json&lt;/strong&gt;文件中的&lt;code&gt;plugin_name&lt;/code&gt;字段的值为插件的名称。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$docker plugin install localhost:5000/contiv/v2plugin 
Plugin &amp;quot;localhost:5000/contiv/v2plugin&amp;quot; is requesting the following privileges:
 - network: [host]
 - mount: [/etc/openvswitch]
 - mount: [/var/log/openvswitch]
 - mount: [/var/run]
 - mount: [/lib/modules]
 - capabilities: [CAP_SYS_ADMIN CAP_NET_ADMIN CAP_SYS_MODULE]
Do you grant the above permissions? [y/N] y
latest: Pulling from contiv/v2plugin
fd87a71d9090: Download complete 
Digest: sha256:b13ad7930f771c9602acf562c2ae147482466f4d94e708692a215935663215a6
Status: Downloaded newer image for localhost:5000/contiv/v2plugin:latest
Installed plugin localhost:5000/contiv/v2plugin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;自己create的插件enable的时候从docker daemon的日志中依然可以看到之前看到找不到socket的错误，实际上也确实是没有生成。如果直接使用&lt;code&gt;docker plugin install store/contiv/v2plugin:1.0.0-beta.3&lt;/code&gt;的方式安装插件是没有问题的。&lt;/p&gt;

&lt;h2 id=&#34;docker17-03-ce中插件机制存在的问题&#34;&gt;Docker17.03-CE中插件机制存在的问题&lt;/h2&gt;

&lt;p&gt;Docker17.03的插件机制是为了docker公司的商业化策略而实行的，所有的docker插件都运行在自己的namespace和rootfs中，插件接口&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Plugin backend接口&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;// Backend for Plugin
type Backend interface {
	Disable(name string, config *enginetypes.PluginDisableConfig) error
	Enable(name string, config *enginetypes.PluginEnableConfig) error
	List(filters.Args) ([]enginetypes.Plugin, error)
	Inspect(name string) (*enginetypes.Plugin, error)
	Remove(name string, config *enginetypes.PluginRmConfig) error
	Set(name string, args []string) error
	Privileges(ctx context.Context, ref reference.Named, metaHeaders http.Header, authConfig *enginetypes.AuthConfig) (enginetypes.PluginPrivileges, error)
	Pull(ctx context.Context, ref reference.Named, name string, metaHeaders http.Header, authConfig *enginetypes.AuthConfig, privileges enginetypes.PluginPrivileges, outStream io.Writer) error
	Push(ctx context.Context, name string, metaHeaders http.Header, authConfig *enginetypes.AuthConfig, outStream io.Writer) error
	Upgrade(ctx context.Context, ref reference.Named, name string, metaHeaders http.Header, authConfig *enginetypes.AuthConfig, privileges enginetypes.PluginPrivileges, outStream io.Writer) error
	CreateFromContext(ctx context.Context, tarCtx io.ReadCloser, options *enginetypes.PluginCreateOptions) error
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从Plugin的后端接口中可以看到，没有像镜像一样的两个常用方法：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;没有修改plugin名字的方法，因为没有这个方法，就无法push plugin到自己的镜像仓库，另外&lt;strong&gt;Harbor&lt;/strong&gt;还是不支持&lt;code&gt;docker plugin push&lt;/code&gt; &lt;a href=&#34;https://github.com/vmware/harbor/issues/1532&#34;&gt;Issue-1532&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;没有导出plugin的方法，这样就只能在联网的主机上安装docker plugin了，对于无法联网的主机只好束手无策了。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;估计docker官方也不会开放这两个接口吧。毕竟这是&lt;strong&gt;Docker EE&lt;/strong&gt; 的一个重要卖点：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Docker EE&amp;rsquo;s Certified Plugins&lt;/strong&gt; provide networking and volume plugins and easy to download and install containers to the Docker EE environment.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;疑问&#34;&gt;疑问&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;为什么一定要使用docker plugin install&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;因为&lt;code&gt;docker plugin install&lt;/code&gt;的时候会申请一些访问权限。&lt;/p&gt;

&lt;p&gt;这一块在上面的步骤中可以看到。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;为什么docker plugin不能改名字？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们看下Plugin的结构体（在api/types/plugin.go中定义）：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// Plugin A plugin for the Engine API
// swagger:model Plugin
type Plugin struct {

	// config
	// Required: true
	Config PluginConfig `json:&amp;quot;Config&amp;quot;`

	// True when the plugin is running. False when the plugin is not running, only installed.
	// Required: true
	Enabled bool `json:&amp;quot;Enabled&amp;quot;`

	// Id
	ID string `json:&amp;quot;Id,omitempty&amp;quot;`

	// name
	// Required: true
	Name string `json:&amp;quot;Name&amp;quot;`

	// plugin remote reference used to push/pull the plugin
	PluginReference string `json:&amp;quot;PluginReference,omitempty&amp;quot;`

	// settings
	// Required: true
	Settings PluginSettings `json:&amp;quot;Settings&amp;quot;`
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意其中有一个&lt;code&gt;PluginReference&lt;/code&gt;结构体，它的方法有：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;type pluginReference struct {
	name     reference.Named
	pluginID digest.Digest
}

func (r *pluginReference) References(id digest.Digest) []reference.Named {
	if r.pluginID != id {
		return nil
	}
	return []reference.Named{r.name}
}

func (r *pluginReference) ReferencesByName(ref reference.Named) []refstore.Association {
	return []refstore.Association{
		{
			Ref: r.name,
			ID:  r.pluginID,
		},
	}
}

func (r *pluginReference) Get(ref reference.Named) (digest.Digest, error) {
	if r.name.String() != ref.String() {
		return digest.Digest(&amp;quot;&amp;quot;), refstore.ErrDoesNotExist
	}
	return r.pluginID, nil
}

func (r *pluginReference) AddTag(ref reference.Named, id digest.Digest, force bool) error {
	// Read only, ignore
	return nil
}
func (r *pluginReference) AddDigest(ref reference.Canonical, id digest.Digest, force bool) error {
	// Read only, ignore
	return nil
}
func (r *pluginReference) Delete(ref reference.Named) (bool, error) {
	// Read only, ignore
	return false, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意其中有三个方法&lt;code&gt;AddTag&lt;/code&gt;、&lt;code&gt;AddDigest&lt;/code&gt;、&lt;code&gt;Delete&lt;/code&gt;方法都是只读的。在&lt;code&gt;migrate/v1/migratev1.go&lt;/code&gt;中有引用到了这个。&lt;/p&gt;

&lt;p&gt;再看下&lt;strong&gt;Reference&lt;/strong&gt;的的定义（vendor/github.com/docker/distribution/reference/reference.go）&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;// Package reference provides a general type to represent any way of referencing images within the registry.
// Its main purpose is to abstract tags and digests (content-addressable hash).
//
// Grammar
//
// 	reference                       := name [ &amp;quot;:&amp;quot; tag ] [ &amp;quot;@&amp;quot; digest ]
//	name                            := [domain &#39;/&#39;] path-component [&#39;/&#39; path-component]*
//	domain                          := domain-component [&#39;.&#39; domain-component]* [&#39;:&#39; port-number]
//	domain-component                := /([a-zA-Z0-9]|[a-zA-Z0-9][a-zA-Z0-9-]*[a-zA-Z0-9])/
//	port-number                     := /[0-9]+/
//	path-component                  := alpha-numeric [separator alpha-numeric]*
// 	alpha-numeric                   := /[a-z0-9]+/
//	separator                       := /[_.]|__|[-]*/
//
//	tag                             := /[\w][\w.-]{0,127}/
//
//	digest                          := digest-algorithm &amp;quot;:&amp;quot; digest-hex
//	digest-algorithm                := digest-algorithm-component [ digest-algorithm-separator digest-algorithm-component ]
//	digest-algorithm-separator      := /[+.-_]/
//	digest-algorithm-component      := /[A-Za-z][A-Za-z0-9]*/
//	digest-hex                      := /[0-9a-fA-F]{32,}/ ; At least 128 bit digest value
//
//	identifier                      := /[a-f0-9]{64}/
//	short-identifier                := /[a-f0-9]{6,64}/
// Reference is an opaque object reference identifier that may include
// modifiers such as a hostname, name, tag, and digest.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;修改plugin的名字的方法是不是还没实现？&lt;/p&gt;

&lt;h2 id=&#34;解决方法&#34;&gt;解决方法&lt;/h2&gt;

&lt;p&gt;在代码存在bug的情况下，可以先用下面的方法暂时创建plugin。&lt;/p&gt;

&lt;p&gt;虽然docker代码里没有提供&lt;strong&gt;rename plugin&lt;/strong&gt;的接口，但是使用&lt;strong&gt;docker install&lt;/strong&gt;命令安装的plugin会存储在&lt;code&gt;/var/lib/docker/plugins/${PLUGIN_ID}&lt;/code&gt;目录下。&lt;/p&gt;

&lt;p&gt;可以在这个目录下使用&lt;strong&gt;docker plugin create&lt;/strong&gt;命令创建你自己想要的名称的docker plugin。&lt;/p&gt;

&lt;p&gt;使用&lt;code&gt;docker plugin set&lt;/code&gt;命令修改plugin中的属性:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;cluster_store&lt;/li&gt;
&lt;li&gt;plugin_role&lt;/li&gt;
&lt;li&gt;plugin_name&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;插件调试&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;日志地址&lt;code&gt;/run/contiv/log/&lt;/code&gt;。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker17.03-CE插件开发-举个🌰</title>
      <link>http://rootsongjc.github.io/blogs/docker-plugin-develop/</link>
      <pubDate>Wed, 15 Mar 2017 13:57:26 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/docker-plugin-develop/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20161016022.jpg&#34; alt=&#34;杭州吴山&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：杭州吴山步道旁的墙壁 Oct 16,2016）&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;当你看到这篇文章时，如果你也正在进行docker1.13+版本下的plugin开发，恭喜你也入坑了，如果你趟出坑，麻烦告诉你的方法，感恩不尽🙏&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;看了文章后你可能会觉得，官网上的可能是个假🌰。&lt;strong&gt;虽然官网上的文档写的有点不对，不过你使用docker-ssh-volume的开源代码自己去构建plugin的还是可以成功的！&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;docker-plugin开发文档&#34;&gt;Docker plugin开发文档&lt;/h3&gt;

&lt;p&gt;首先docker官方给出了一个&lt;a href=&#34;https://docs.docker.com/engine/extend/legacy_plugins/&#34;&gt;docker legacy plugin文档&lt;/a&gt;，这篇文章基本就是告诉你docker目前支持哪些插件，罗列了一系列连接，不过对不起，这些不是docker官方插件，有问题去找它们的开发者去吧😂&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Docker plugin貌似开始使用了新的v2 plugin了，legacy版本的plugin可以能在后期被废弃。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;从docker的源码&lt;strong&gt;plugin/store.go&lt;/strong&gt;中可以看到：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;/* allowV1PluginsFallback determines daemon&#39;s support for V1 plugins.
 * When the time comes to remove support for V1 plugins, flipping
 * this bool is all that will be needed.
 */
const allowV1PluginsFallback bool = true

/* defaultAPIVersion is the version of the plugin API for volume, network,
   IPAM and authz. This is a very stable API. When we update this API, then
   pluginType should include a version. e.g. &amp;quot;networkdriver/2.0&amp;quot;.
*/
const defaultAPIVersion string = &amp;quot;1.0&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;随着docker公司是的战略调整，推出了docker-CE和docker-EE之后，未来有些插件就可能要收费了，v2版本的插件都是在docker store中下载了，而这种插件在创建的时候都是打包成docker image，如果不开放源码的话，你即使pull下来插件也无法修改和导出的，&lt;strong&gt;docker plugin目前没有导出接口&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;真正要开发一个docker plugin还是得看&lt;a href=&#34;https://docs.docker.com/engine/extend/plugin_api/&#34;&gt;docker plugin API&lt;/a&gt;，这篇文档告诉我们：&lt;/p&gt;

&lt;h4 id=&#34;插件发现&#34;&gt;插件发现&lt;/h4&gt;

&lt;p&gt;当你开发好一个插件&lt;strong&gt;docker engine&lt;/strong&gt;怎么才能发现它们呢？有三种方式：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;.sock&lt;/strong&gt;，linux下放在/run/docker/plugins目录下，或该目录下的子目录比如&lt;a href=&#34;https://github.com/ClusterHQ/flocker&#34;&gt;flocker&lt;/a&gt;插件的&lt;code&gt;.sock&lt;/code&gt;文件放在&lt;code&gt;/run/docker/plugins/flocker/flocker.sock&lt;/code&gt;下&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;.spec&lt;/strong&gt;，比如&lt;strong&gt;convoy&lt;/strong&gt;插件在&lt;code&gt;/etc/docker/plugins/convoy.spec&lt;/code&gt;定义，内容为&lt;code&gt;unix:///var/run/convoy/convoy.sock&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;.json&lt;/strong&gt;，比如&lt;strong&gt;infinit&lt;/strong&gt;插件在&lt;code&gt;/usr/lib/docker/plugins/infinit.json&lt;/code&gt;定义，内容为&lt;code&gt;{&amp;quot;Addr&amp;quot;:&amp;quot;https://infinit.sh&amp;quot;,&amp;quot;Name&amp;quot;:&amp;quot;infinit&amp;quot;}&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;文章中的其它部分&lt;strong&gt;貌似都过时&lt;/strong&gt;了，新的插件不是作为&lt;strong&gt;systemd&lt;/strong&gt;进程运行的，而是完全通过&lt;strong&gt;docker plugin&lt;/strong&gt;命令来管理的。&lt;/p&gt;

&lt;p&gt;当你使用&lt;strong&gt;docker plugin enable &lt;plugin_name&gt;&lt;/strong&gt;来激活了插件后，理应在&lt;code&gt;/run/docker/plugins&lt;/code&gt;目录下生成插件的&lt;code&gt;.sock&lt;/code&gt;文件，但是现在只有一个以runc ID命名的目录，这个问题下面有详细的叙述过程，你也可以跳过，直接看&lt;a href=&#34;https://github.com/docker/docker/issues/31723&#34;&gt;issue-31723&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/engine/extend/&#34;&gt;docker plugin管理&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;创建sshfs-volume-plugin&#34;&gt;创建sshfs volume plugin&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/docker/docker/blob/17.03.x/docs/extend/index.md#developing-a-plugin&#34;&gt;官方示例文档&lt;/a&gt;（这个文档有问题）&lt;a href=&#34;https://github.com/docker/docker/issues/29886&#34;&gt;docker-issue29886&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;官方以开发一个&lt;strong&gt;sshfs&lt;/strong&gt;的volume plugin为例。&lt;/p&gt;

&lt;p&gt;执行&lt;code&gt;docker plugin create&lt;/code&gt;命令的目录下必须包含以下内容：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;config.json&lt;/strong&gt;文件，里面是插件的配置信息，&lt;a href=&#34;https://github.com/docker/docker/blob/17.03.x/docs/extend/config.md&#34;&gt;plugin config参考文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;rootfs&lt;/strong&gt;目录，插件镜像解压后的目录。v2版本的docker plugin都是以docker镜像的方式包装的。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/vieux/docker-volume-sshfs
$ cd docker-volume-sshfs
$ go get github.com/docker/go-plugins-helpers/volume
$ go build -o docker-volume-sshfs main.go  
$ docker build -t rootfsimage .
$ id=$(docker create rootfsimage true) # id was cd851ce43a403 when the image was created
$ sudo mkdir -p myplugin/rootfs
$ sudo docker export &amp;quot;$id&amp;quot; | sudo tar -x -C myplugin/rootfs
$ docker rm -vf &amp;quot;$id&amp;quot;
$ docker rmi rootfsimage
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们可以看到&lt;strong&gt;sshfs&lt;/strong&gt;的Dockerfile是这样的：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Dockerfile&#34;&gt;FROM alpine

RUN apk update &amp;amp;&amp;amp; apk add sshfs

RUN mkdir -p /run/docker/plugins /mnt/state /mnt/volumes

COPY docker-volume-sshfs docker-volume-sshfs

CMD [&amp;quot;docker-volume-sshfs&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实际上是编译好的可执行文件复制到alpine linux容器中运行。&lt;/p&gt;

&lt;p&gt;编译rootfsimage镜像的过程。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker build -t rootfsimage .
Sending build context to Docker daemon 11.71 MB
Step 1/5 : FROM alpine
 ---&amp;gt; 4a415e366388
Step 2/5 : RUN apk update &amp;amp;&amp;amp; apk add sshfs
 ---&amp;gt; Running in 1551ecc1c847
fetch http://dl-cdn.alpinelinux.org/alpine/v3.5/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.5/community/x86_64/APKINDEX.tar.gz
v3.5.2-2-ge626ce8c3c [http://dl-cdn.alpinelinux.org/alpine/v3.5/main]
v3.5.1-71-gc7bb9a04f0 [http://dl-cdn.alpinelinux.org/alpine/v3.5/community]
OK: 7959 distinct packages available
(1/10) Installing openssh-client (7.4_p1-r0)
(2/10) Installing fuse (2.9.7-r0)
(3/10) Installing libffi (3.2.1-r2)
(4/10) Installing libintl (0.19.8.1-r0)
(5/10) Installing libuuid (2.28.2-r1)
(6/10) Installing libblkid (2.28.2-r1)
(7/10) Installing libmount (2.28.2-r1)
(8/10) Installing pcre (8.39-r0)
(9/10) Installing glib (2.50.2-r0)
(10/10) Installing sshfs (2.8-r0)
Executing busybox-1.25.1-r0.trigger
Executing glib-2.50.2-r0.trigger
OK: 11 MiB in 21 packages
 ---&amp;gt; 1a73c501f431
Removing intermediate container 1551ecc1c847
Step 3/5 : RUN mkdir -p /run/docker/plugins /mnt/state /mnt/volumes
 ---&amp;gt; Running in 032af3b2595a
 ---&amp;gt; 30c7e8463e96
Removing intermediate container 032af3b2595a
Step 4/5 : COPY docker-volume-sshfs docker-volume-sshfs
 ---&amp;gt; a924c6fcc1e4
Removing intermediate container ffc5e3c97707
Step 5/5 : CMD docker-volume-sshfs
 ---&amp;gt; Running in 0dc938fe4f4e
 ---&amp;gt; 0fd2e3d94860
Removing intermediate container 0dc938fe4f4e
Successfully built 0fd2e3d94860
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;编写&lt;code&gt;config.json&lt;/code&gt;文档&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Json&#34;&gt;{
    &amp;quot;description&amp;quot;: &amp;quot;sshFS plugin for Docker&amp;quot;,
    &amp;quot;documentation&amp;quot;: &amp;quot;https://docs.docker.com/engine/extend/plugins/&amp;quot;,
    &amp;quot;entrypoint&amp;quot;: [
        &amp;quot;/docker-volume-sshfs&amp;quot;
    ],
    &amp;quot;env&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;DEBUG&amp;quot;,
            &amp;quot;settable&amp;quot;: [
                &amp;quot;value&amp;quot;
            ],
            &amp;quot;value&amp;quot;: &amp;quot;0&amp;quot;
        }
    ],
    &amp;quot;interface&amp;quot;: {
        &amp;quot;socket&amp;quot;: &amp;quot;sshfs.sock&amp;quot;,
        &amp;quot;types&amp;quot;: [
            &amp;quot;docker.volumedriver/1.0&amp;quot;
        ]
    },
    &amp;quot;linux&amp;quot;: {
        &amp;quot;capabilities&amp;quot;: [
            &amp;quot;CAP_SYS_ADMIN&amp;quot;
        ],
        &amp;quot;devices&amp;quot;: [
            {
                &amp;quot;path&amp;quot;: &amp;quot;/dev/fuse&amp;quot;
            }
        ]
    },
    &amp;quot;mounts&amp;quot;: [
        {
            &amp;quot;destination&amp;quot;: &amp;quot;/mnt/state&amp;quot;,
            &amp;quot;options&amp;quot;: [
                &amp;quot;rbind&amp;quot;
            ],
            &amp;quot;source&amp;quot;: &amp;quot;/var/lib/docker/plugins/&amp;quot;,
            &amp;quot;type&amp;quot;: &amp;quot;bind&amp;quot;
        }
    ],
    &amp;quot;network&amp;quot;: {
        &amp;quot;type&amp;quot;: &amp;quot;host&amp;quot;
    },
    &amp;quot;propagatedmount&amp;quot;: &amp;quot;/mnt/volumes&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该插件使用host网络类型，使用/run/docker/plugins/sshfs.sock接口与docker engine通信。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注意官网上的这个文档有问题，config.json与代码里的不符，尤其是Entrypoint的二进制文件的位置不对。&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;注意&lt;strong&gt;socket&lt;/strong&gt;配置的地址不要写详细地址，默认会在/run/docker/plugins目录下生成socket文件。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;创建plugin&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;使用&lt;code&gt;docker plugin create &amp;lt;plugin_name&amp;gt; /path/to/plugin/data/&lt;/code&gt;命令创建插件。&lt;/p&gt;

&lt;p&gt;具体到sshfs插件，在myplugin目录下使用如下命令创建插件：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker plugin create jimmmysong/sshfs:latest .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在就可以看到刚创建的插件了&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker plugin ls
ID                  NAME                 DESCRIPTION               ENABLED
8aa1f6098fca        jimmysong/sshfs:latest   sshFS plugin for Docker   true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;push plugin&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;先登录你的docker hub账户，然后使用&lt;code&gt;docker plugin push jimmysong/sshfs:latest&lt;/code&gt;即可以推送docker plugin到docker hub中。&lt;/p&gt;

&lt;p&gt;目前推送到&lt;strong&gt;harbor&lt;/strong&gt;镜像仓库有问题，报错信息：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c08c951b53b7: Preparing 
denied: requested access to the resource is denied
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;已给harbor提&lt;a href=&#34;https://github.com/vmware/harbor/issues/1532&#34;&gt;issue-1532&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;plugin的使用&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;有发现了个问题&lt;a href=&#34;https://github.com/docker/docker/issues/31723&#34;&gt;docker issue-31723&lt;/a&gt;，使用plugin创建volume的时候居然找不到&lt;code&gt;sshfs.sock&lt;/code&gt;文件！😢刚开始手动创建plugin的时候测试了下是正常的，不知道为啥弄到这台测试机器上出问题了。&lt;/p&gt;

&lt;h3 id=&#34;关于docker-plugin-enable失败的问题&#34;&gt;关于docker plugin enable失败的问题&lt;/h3&gt;

&lt;p&gt;当docker  plugin创建成功并enable的时候docker并没有报错，这与docker plugin的&lt;strong&gt;activate&lt;/strong&gt;机制有关，只有当你最终使用该plugin的时候才会激活它。&lt;/p&gt;

&lt;p&gt;使用&lt;strong&gt;sshfs&lt;/strong&gt;插件创建volume。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker volume create -d jimmysong/sshfs --name sshvolume -o sshcmd=1.2.3.4:/remote -o password=password
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;报错如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error response from daemon: create sshvolume: Post http://%2Frun%2Fdocker%2Fplugins%2F8f7b8f931b38a4ef53d0e4f8d738e26e8f10ef8bd26c8244f4b8dcc7276b685f%2Fsshfs.sock/VolumeDriver.Create: dial unix /run/docker/plugins/8f7b8f931b38a4ef53d0e4f8d738e26e8f10ef8bd26c8244f4b8dcc7276b685f/sshfs.sock: connect: no such file or directory
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Docker daemon在enable这个插件的时候会寻找这个&lt;strong&gt;.sock&lt;/strong&gt;文件，然后在自己的plugindb中注册它，相关代码在这个文件里：&lt;a href=&#34;https://github.com/docker/docker/blob/17.03.x/plugin/manager_linux.go&#34;&gt;https://github.com/docker/docker/blob/17.03.x/plugin/manager_linux.go&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;相关代码片段：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;func (pm *Manager) enable(p *v2.Plugin, c *controller, force bool) error {
	...
	return pm.pluginPostStart(p, c)
}

func (pm *Manager) pluginPostStart(p *v2.Plugin, c *controller) error {
    //这里需要获取.sock文件的地址 
    //pm.conifg.ExecRoot就是/run/docker/plugins
    //p.GetID()返回的就是很长的那串plugin ID
	sockAddr := filepath.Join(pm.config.ExecRoot, p.GetID(), p.GetSocket())
	client, err := plugins.NewClientWithTimeout(&amp;quot;unix://&amp;quot;+sockAddr, nil, c.timeoutInSecs)
	if err != nil {
		c.restart = false
		shutdownPlugin(p, c, pm.containerdClient)
		return errors.WithStack(err)
	}

	p.SetPClient(client)

	maxRetries := 3
	var retries int
	for {
		time.Sleep(3 * time.Second)
		retries++

		if retries &amp;gt; maxRetries {
			logrus.Debugf(&amp;quot;error net dialing plugin: %v&amp;quot;, err)
			c.restart = false
			shutdownPlugin(p, c, pm.containerdClient)
			return err
		}

		// net dial into the unix socket to see if someone&#39;s listening.
		conn, err := net.Dial(&amp;quot;unix&amp;quot;, sockAddr)
		if err == nil {
			conn.Close()
			break
		}
	}
	pm.config.Store.SetState(p, true)
	pm.config.Store.CallHandler(p)

	return pm.save(p)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意这段代码里的&lt;strong&gt;sockAddr := filepath.Join(pm.config.ExecRoot, p.GetID(), p.GetSocket())&lt;/strong&gt;，我在上面添加了注释。&lt;/p&gt;

&lt;p&gt;这个&lt;strong&gt;.sock&lt;/strong&gt;文件应该有docker plugin来生成，具体怎样生成的呢？还以&lt;strong&gt;docker-volume-ssh&lt;/strong&gt;这个插件为例。&lt;/p&gt;

&lt;p&gt;整个项目就一个&lt;strong&gt;main.go&lt;/strong&gt;文件，里面最后一行生成了&lt;strong&gt;/run/docker/plugins/sshfs.sock&lt;/strong&gt;这个sock。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;logrus.Error(h.ServeUnix(socketAddress, 0))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这行代码调用&lt;strong&gt;docker/go-plugin-helpers/sdk/handler.go&lt;/strong&gt;中的:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;// ServeUnix makes the handler to listen for requests in a unix socket.
// It also creates the socket file on the right directory for docker to read.
func (h Handler) ServeUnix(addr string, gid int) error {
	l, spec, err := newUnixListener(addr, gid)
	if err != nil {
		return err
	}
	if spec != &amp;quot;&amp;quot; {
		defer os.Remove(spec)
	}
	return h.Serve(l)
}

// Serve sets up the handler to serve requests on the passed in listener
func (h Handler) Serve(l net.Listener) error {
	server := http.Server{
		Addr:    l.Addr().String(),
		Handler: h.mux,
	}
	return server.Serve(l)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;//unix_listener_unsupoorted.go
func newUnixListener(pluginName string, gid int) (net.Listener, string, error) {
	return nil, &amp;quot;&amp;quot;, errOnlySupportedOnLinuxAndFreeBSD
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看了上面这这些，你看出socket文件是怎么创建的吗？&lt;/p&gt;

&lt;p&gt;这又是一个&lt;a href=&#34;https://github.com/vieux/docker-volume-sshfs/issues/19&#34;&gt;issue-19&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;如果你修改&lt;strong&gt;config.json&lt;/strong&gt;文件，将其中的&lt;strong&gt;interfaces - socket&lt;/strong&gt;指定为&lt;code&gt;/run/docker/plugins/sshfs.sock&lt;/code&gt;然后创建plugin，则能成功生成socket文件，但是当你enable它的时候又会报错&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error response from daemon: Unix socket path &amp;quot;/run/docker/plugins/ac34f7b246ac6c029023b1ebd48e166eadcdd2c9d0cc682cadca0336951d72f7/run/docker/plugins/sshfs.sock&amp;quot; is too long
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从docker daemon的日志里可以看到详细报错：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Mar 13 17:15:20 sz-pg-oam-docker-test-001.tendcloud.com dockerd[51757]: time=&amp;quot;2017-03-13T17:15:20+08:00&amp;quot; level=info msg=&amp;quot;standard_init_linux.go:178: exec user process caused \&amp;quot;no such file or directory\&amp;quot;&amp;quot; plugin=ac34f7b246ac6c029023b1ebd48e166eadcdd2c9d0cc682cadca0336951d72f7
Mar 13 17:15:20 sz-pg-oam-docker-test-001.tendcloud.com dockerd[51757]: time=&amp;quot;2017-03-13T17:15:20.321277088+08:00&amp;quot; level=error msg=&amp;quot;Sending SIGTERM to plugin failed with error: rpc error: code = 2 desc = no such process&amp;quot;
Mar 13 17:15:20 sz-pg-oam-docker-test-001.tendcloud.com dockerd[51757]: time=&amp;quot;2017-03-13T17:15:20.321488680+08:00&amp;quot; level=error msg=&amp;quot;Handler for POST /v1.26/plugins/sshfs/enable returned error: Unix socket path \&amp;quot;/run/docker/plugins/ac34f7b246ac6c029023b1ebd48e166eadcdd2c9d0cc682cadca0336951d72f7/run/docker/plugins/sshfs.sock\&amp;quot; is too long\ngithub.com/docker/docker/plugin.(*Manager).pluginPostStart\n\t/root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/plugin/manager_linux.go:84\ngithub.com/docker/docker/plugin.(*Manager).enable\n\t/root/rpmbuild/BUILD/docker-
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正好验证了上面的&lt;strong&gt;enable&lt;/strong&gt;代码，docker默认是到&lt;code&gt;/run/docker/plugins&lt;/code&gt;目录下找&lt;strong&gt;sshfs.sock&lt;/strong&gt;这个文件的。&lt;/p&gt;

&lt;p&gt;我在docker daemon中发现一个很诡异的错误，&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Mar 13 17:29:41 sz-pg-oam-docker-test-001.tendcloud.com dockerd[51757]: time=&amp;quot;2017-03-13T17:29:41+08:00&amp;quot; level=info msg=&amp;quot;standard_init_linux.go:178: exec user process caused \&amp;quot;no such file or directory\&amp;quot;&amp;quot; plugin=85760810b4850009fc965f5c20d8534dc9aba085340a2ac0b4b9167a6fef7d53
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我查看了下&lt;code&gt;github.com/libnetwork/vendor/github.com/opencontainers/run/libcontainer/standard_init_linux.go&lt;/code&gt;文件，这个那个文件只有114行，见这里&lt;a href=&#34;https://github.com/docker/libnetwork/blob/master/vendor/github.com/opencontainers/runc/libcontainer/standard_init_linux.go&#34;&gt;https://github.com/docker/libnetwork/blob/master/vendor/github.com/opencontainers/runc/libcontainer/standard_init_linux.go&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;但是在&lt;strong&gt;opencontainers&lt;/strong&gt;的github项目里才有那么多行，见这里：&lt;a href=&#34;https://github.com/opencontainers/runc/blob/master/libcontainer/standard_init_linux.go&#34;&gt;https://github.com/opencontainers/runc/blob/master/libcontainer/standard_init_linux.go&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这个报错前后的函数是：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;// PR_SET_NO_NEW_PRIVS isn&#39;t exposed in Golang so we define it ourselves copying the value
// the kernel
const PR_SET_NO_NEW_PRIVS = 0x26

func (l *linuxStandardInit) Init() error {
	if !l.config.Config.NoNewKeyring {
		ringname, keepperms, newperms := l.getSessionRingParams()

		// do not inherit the parent&#39;s session keyring
		sessKeyId, err := keys.JoinSessionKeyring(ringname)
		if err != nil {
			return err
		}
		// make session keyring searcheable
		if err := keys.ModKeyringPerm(sessKeyId, keepperms, newperms); err != nil {
			return err
		}
	}

...
	}
	if l.config.Config.Seccomp != nil &amp;amp;&amp;amp; l.config.NoNewPrivileges {
         //下面这行是第178行
		if err := seccomp.InitSeccomp(l.config.Config.Seccomp); err != nil {
			return newSystemErrorWithCause(err, &amp;quot;init seccomp&amp;quot;)
		}
	}
	// close the statedir fd before exec because the kernel resets dumpable in the wrong order
	// https://github.com/torvalds/linux/blob/v4.9/fs/exec.c#L1290-L1318
	syscall.Close(l.stateDirFD)
	if err := syscall.Exec(name, l.config.Args[0:], os.Environ()); err != nil {
		return newSystemErrorWithCause(err, &amp;quot;exec user process&amp;quot;)
	}
	return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;结论&#34;&gt;&lt;del&gt;结论&lt;/del&gt;&lt;/h2&gt;

&lt;p&gt;&lt;del&gt;到此了问题还没解决。&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;问题的关键是执行&lt;strong&gt;docker create plugin&lt;/strong&gt;之后&lt;strong&gt;.sock&lt;/strong&gt;文件创建到哪里去了？为什么在&lt;strong&gt;config.json&lt;/strong&gt;指定成&lt;code&gt;/run/docker/plugins/sshfs.sock&lt;/code&gt;就可以在指定的目录下创建出.sock文件，说明&lt;strong&gt;创建socket的定义和get socket时寻找的路径不一样&lt;/strong&gt;，创建socket时就是固定在/run/docker/plugins目录下创建，而enable plugin的时候，Get socket的时候还要加上docker plugin的ID，可是按照官网的配置在本地create plugin后并没有在/run/docker/plugins目录下生成插件的socket文件，直到enable插件的时候才会生成以plugin ID命名的目录，但是socket文件没有！☹️&lt;/del&gt;&lt;/p&gt;

&lt;h2 id=&#34;问题解决&#34;&gt;问题解决&lt;/h2&gt;

&lt;p&gt;之所以出现上面的那些问题，是因为create docker plugin的时候有问题，也就是那个二进制文件有问题，我在&lt;strong&gt;Mac&lt;/strong&gt;上build的image，而且还没有用&lt;strong&gt;Dockerfile.dev&lt;/strong&gt;这个专门用来搭建二进制文件编译环境的Dockerfile来创建golang的编译环境，虽然docker plugin是创建成功了，但是当docker plugin enable的时候，这个热紧张文件不能正确的运行，所以就没能生成&lt;strong&gt;sshfs.sock&lt;/strong&gt;文件。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;请在Linux环境下使用&lt;strong&gt;make all&lt;/strong&gt;命令来创建plugin。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Docker 17.03-CE create plugin源码解析</title>
      <link>http://rootsongjc.github.io/blogs/docker-create-plugin/</link>
      <pubDate>Wed, 15 Mar 2017 12:09:26 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/docker-create-plugin/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20160403050.jpg&#34; alt=&#34;故宫博物院&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：故宫 Apr 3,2016）&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;继续上一篇&lt;a href=&#34;http://rootsongjc.github.io/blogs/docker-plugin-develop/&#34;&gt;Docker17.03-CE插件开发的🌰&lt;/a&gt;，今天来看下&lt;strong&gt;docker create plugin&lt;/strong&gt;的源码。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;cli/command/plugin/create.go&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Docker命令行&lt;code&gt;docker plugin create&lt;/code&gt;调用的，使用的是&lt;a href=&#34;http://github.com/spf13/cobra&#34;&gt;cobra&lt;/a&gt;，这个命令行工具开发包很好用，推荐下。&lt;/p&gt;

&lt;p&gt;执行这两个函数&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func newCreateCommand(dockerCli *command.DockerCli) *cobra.Command 
//调用下面的函数，拼装成URL调用RESTful API接口
func runCreate(dockerCli *command.DockerCli, options pluginCreateOptions) error {
  ...
  if err = dockerCli.Client().PluginCreate(ctx, createCtx, createOptions); err != nil {
		return err
	}
  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在&lt;strong&gt;api/server/router/plugin/plugin_routes.go&lt;/strong&gt;中&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (pr *pluginRouter) createPlugin(ctx context.Context, w http.ResponseWriter, r *http.Request, vars map[string]string) error {
  ...
  if err := pr.backend.CreateFromContext(ctx, r.Body, options); err != nil {
		return err
	}
  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;createPlugin&lt;/strong&gt;这个方法定义在api/server/route/plugin/backen.go的&lt;strong&gt;Backend&lt;/strong&gt;接口中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PluginCreate&lt;/strong&gt;这个方法定义在docker/docker/client/Interface.go的&lt;strong&gt;PluginAPIClient&lt;/strong&gt;接口中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;docker/client/plugin_create.go&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// PluginCreate creates a plugin
func (cli *Client) PluginCreate(ctx context.Context, createContext io.Reader, createOptions types.PluginCreateOptions) error {
	headers := http.Header(make(map[string][]string))
	headers.Set(&amp;quot;Content-Type&amp;quot;, &amp;quot;application/x-tar&amp;quot;)

	query := url.Values{}
	query.Set(&amp;quot;name&amp;quot;, createOptions.RepoName)

	resp, err := cli.postRaw(ctx, &amp;quot;/plugins/create&amp;quot;, query, createContext, headers)
	if err != nil {
		return err
	}
	ensureReaderClosed(resp)
	return err
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;plugin在后端接收到请求后会执行下面的方法。最终&lt;strong&gt;create plugin&lt;/strong&gt;的实现在plugin/backend_linux.go下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// CreateFromContext creates a plugin from the given pluginDir which contains
// both the rootfs and the config.json and a repoName with optional tag.
func (pm *Manager) CreateFromContext(ctx context.Context, tarCtx io.ReadCloser, options *types.PluginCreateOptions) (err error) {}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至于docker create plugin时docker后台究竟做了什么，就看👆那个文件。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker v.s Kubernetes part2</title>
      <link>http://rootsongjc.github.io/blogs/docker-vs-kubernetes-part2/</link>
      <pubDate>Fri, 10 Mar 2017 22:06:32 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/docker-vs-kubernetes-part2/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20160709044.jpg&#34; alt=&#34;承德兴隆星空&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：河北承德兴隆县雾灵山京郊最佳星空拍摄点 July 9,2016)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;本文是&lt;code&gt;Docker v.s Kubernetes&lt;/code&gt;第二篇，续接上文&lt;a href=&#34;http://rootsongjc.github.io/blogs/docker-vs-kubernetes-part1/&#34;&gt;Docker v.s Kuberntes Part1&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;Kubernetes是典型的&lt;strong&gt;Master/Slave&lt;/strong&gt;架构模式，本文简要的介绍kubenetes的架构和组件构成。&lt;/p&gt;

&lt;h2 id=&#34;kubernetes核心架构&#34;&gt;Kubernetes核心架构&lt;/h2&gt;

&lt;h3 id=&#34;master节点&#34;&gt;master节点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;apiserver：作为kubernetes系统的入口，封装了核心对象的增删改查操作，以RESTFul接口方式提供给外部客户和内部组件调用。它维护的REST对象将持久化到etcd（一个分布式强一致性的key/value存储）。&lt;/li&gt;
&lt;li&gt;scheduler：负责集群的资源调度，为新建的Pod分配机器。这部分工作分出来变成一个组件，意味着可以很方便地替换成其他的调度器。&lt;/li&gt;
&lt;li&gt;controller-manager：负责执行各种控制器，目前有两类：

&lt;ol&gt;
&lt;li&gt;endpoint-controller：定期关联service和Pod(关联信息由endpoint对象维护)，保证service到Pod的映射总是最新的。&lt;/li&gt;
&lt;li&gt;replication-controller：定期关联replicationController和Pod，保证replicationController定义的复制数量与实际运行Pod的数量总是一致的。&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;node节点&#34;&gt;node节点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;kubelet：负责管控docker容器，如启动/停止、监控运行状态等。它会定期从etcd获取分配到本机的Pod，并根据Pod信息启动或停止相应的容器。同时，它也会接收apiserver的HTTP请求，汇报Pod的运行状态。&lt;/li&gt;
&lt;li&gt;proxy：负责为Pod提供代理。它会定期从etcd获取所有的service，并根据service信息创建代理。当某个客户Pod要访问其他Pod时，访问请求会经过本机proxy做转发。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://valleylord.github.io/images/201601-kubernetes-concepts/kubernetes-masterslave.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;kubernetes组件详细介绍&#34;&gt;Kubernetes组件详细介绍&lt;/h2&gt;

&lt;h3 id=&#34;etcd&#34;&gt;etcd&lt;/h3&gt;

&lt;p&gt;虽然不是Kubernetes的组件但是有必要提一下，etcd是一个分布式协同数据库，基于Go语言开发，&lt;code&gt;CoreOS&lt;/code&gt;公司出品，使用&lt;a href=&#34;http://rootsongjc.github.io/blogs/raft/&#34;&gt;raft一致性算法&lt;/a&gt;协同。Kubernetes的主数据库，在安装kubernetes之前就要先安装它，很多开源下项目都用到，老版本的&lt;code&gt;docker swarm&lt;/code&gt;也用到了它。目前主要使用的是&lt;code&gt;2.7.x&lt;/code&gt;版本，&lt;code&gt;3.0+&lt;/code&gt;版本的API变化太大。&lt;/p&gt;

&lt;h3 id=&#34;apiserver&#34;&gt;APIServer&lt;/h3&gt;

&lt;p&gt;APIServer负责对外提供kubernetes API服务，它运行在master节点上。任何对资源的增删改查都要交给APIServer处理后才能提交给etcd。APIServer总体上由两部分组成：HTTP/HTTPS服务和一些功能性插件。这些功能性插件又分为两种：一部分与底层IaaS平台（Cloud Provide）相关；另一部分与资源管理控制（Admission Control）相关。&lt;/p&gt;

&lt;h3 id=&#34;scheduler&#34;&gt;Scheduler&lt;/h3&gt;

&lt;p&gt;Scheduler的作用是&lt;strong&gt;根据特定的调度算法将pod调度到node节点上&lt;/strong&gt;，这一过程也被称为绑定。Scheduler调度器的输入是待调度的pod和可用的工作节点列表，输出则是一个已经绑定了pod的节点，这个节点是通过调度算法在工作节点列表中选择的最优节点。&lt;/p&gt;

&lt;p&gt;工作节点从哪里来？工作节点并不是由Kubernetes创建，它是由IaaS平台创建，或者就是由用户管理的物理机或者虚拟机。但是Kubernetes会创建一个Node对象，用来描述这个工作节点。描述的具体信息由创建Node对象的配置文件给出。一旦用户创建节点的请求被成功处理，Kubernetes又会立即在内部创建一个node对象，再去检查该节点的健康状况。只有那些当前可用的node才会被认为是一个有效的节点并允许pod调度到上面运行。&lt;/p&gt;

&lt;p&gt;工作节点可以通过资源配置文件或者kubectl命令行工具来创建。Kubernetes主要维护工作节点的两个属性：spec和status来描述一个工作节点的期望状态和当前状态。其中，所谓的当前状态信息由3个信息组成：&lt;code&gt;HostIp&lt;/code&gt;、&lt;code&gt;NodePhase&lt;/code&gt;和&lt;code&gt;Node Condition&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;工作节点的动态维护过程依靠&lt;strong&gt;Node Controller&lt;/strong&gt;来完成，它是&lt;code&gt;Kubernetes Controller Manager&lt;/code&gt;下属的一个控制器。它会一直不断的检查Kubernetes已知的每台node节点是否正常工作，如果一个之前已经失败的节点在这个检查循环中被检查为可以工作的，那么Node Controller会把这个节点添加到工作节点中，Node Controller会从工作节点中删除这个节点。&lt;/p&gt;

&lt;h3 id=&#34;controller-manager&#34;&gt;Controller Manager&lt;/h3&gt;

&lt;p&gt;Controller Manager运行在集群的Master节点上，是基于pod API的一个独立服务，它&lt;strong&gt;重点实现service Endpoint（服务端点）的动态更新&lt;/strong&gt;。管理着Kubernetes集群中各种控制节点，包括&lt;strong&gt;replication Controller&lt;/strong&gt;和&lt;strong&gt;node Controller&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;与APIServer相比，APIServer负责接受用户请求并创建对应的资源，而Controller Manager在系统中扮演的角色是在一旁旁默默的管控这些资源，确保他们永远保持在预期的状态&lt;/strong&gt;。它采用各种管理器定时的对pod、节点等资源进行预设的检查，然后判断出于预期的是否一致，若不一致，则通知APIServer采取行动，比如重启、迁移、删除等。&lt;/p&gt;

&lt;h3 id=&#34;kubelet&#34;&gt;kubelet&lt;/h3&gt;

&lt;p&gt;kubelet组件工作在Kubernetes的node上，&lt;strong&gt;负责管理和维护在这台主机上运行着的所有容器&lt;/strong&gt;。 kubelet与cAdvisor交互来抓取docker容器和主机的资源信息。 kubelet垃圾回收机制，包括容器垃圾回收和镜像垃圾回收。 kubelet工作节点状态同步。&lt;/p&gt;

&lt;h3 id=&#34;kube-proxy&#34;&gt;kube-proxy&lt;/h3&gt;

&lt;p&gt;kube-proxy提供两种功能:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;提供算法将客服端流量负载均衡到service对应的一组后端pod。&lt;/li&gt;
&lt;li&gt;使用etcd的watch机制，实现服务发现功能，维护一张从service到endpoint的映射关系，从而保证后端pod的IP变化不会对访问者的访问造成影响。&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Docker v.s Kubernetes part1</title>
      <link>http://rootsongjc.github.io/blogs/docker-vs-kubernetes-part1/</link>
      <pubDate>Fri, 10 Mar 2017 21:09:47 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/docker-vs-kubernetes-part1/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20161016031.jpg&#34; alt=&#34;杭州西湖&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：杭州西湖 Oct 16,2016）&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;前言&#34;&gt;前言&lt;/h3&gt;

&lt;p&gt;这一系列文章是对比kubernetes 和docker两者之间的差异，鉴于我之前从docker1.10.3起开始使用docker，对原生docker的了解比较多，最近又正在看&lt;strong&gt;Kunernetes权威指南（第二版）&lt;/strong&gt;这本书（P.S感谢&lt;u&gt;电子工业出版社&lt;/u&gt;的编辑朋友赠送此书）。这系列文章不是为了比较孰优孰劣，&lt;strong&gt;适合自己的才是最好的&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;此系列文章中所说的&lt;strong&gt;docker&lt;/strong&gt;指的是*17.03-ce*版本。&lt;/p&gt;

&lt;h3 id=&#34;概念性的差别&#34;&gt;概念性的差别&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;了解一样东西首先要高屋建瓴的了解它的概念，kubernetes包括以下几种资源对象：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/abstractions/pod/&#34;&gt;Pod&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Service&lt;/li&gt;
&lt;li&gt;Volume&lt;/li&gt;
&lt;li&gt;Namespace&lt;/li&gt;
&lt;li&gt;ReplicaSet&lt;/li&gt;
&lt;li&gt;Deployment&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/abstractions/controllers/statefulsets/&#34;&gt;StatefulSet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;DaemonSet&lt;/li&gt;
&lt;li&gt;Job&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Docker&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Docker的资源对象相对于kubernetes来说就简单多了，只有以下几个：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Service&lt;/li&gt;
&lt;li&gt;Node&lt;/li&gt;
&lt;li&gt;Stack&lt;/li&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;就这么简单，使用一个*docker-compose.yml*即可以启动一系列服务。当然简单的好处是便于理解和管理，但是在功能方面就没有kubernetes那么强大了。&lt;/p&gt;

&lt;h3 id=&#34;功能性差别&#34;&gt;功能性差别&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Kubernetes 资源限制 CPU 100m千分之一核为单位，绝对值，requests 和limits，超过这个值可能被杀掉，资源限制力度比docker更细。&lt;/li&gt;
&lt;li&gt;Pod中有个最底层的pause 容器，其他业务容器共用他的IP，docker因为没有这层概念，所以没法共用IP，而是使用overlay网络同处于一个网络里来通信。&lt;/li&gt;
&lt;li&gt;Kubernetes在rc中使用环境变量传递配置（1.3版本是这样的，后续版本还没有研究过）&lt;/li&gt;
&lt;li&gt;Kuberentes Label 可以在开始和动态的添加修改，所有的资源对象都有，这一点docker也有，但是资源调度因为没有kubernetes那么层级，所有还是相对比较弱一些。&lt;/li&gt;
&lt;li&gt;Kubernetes对象选择机制继续通过label selector，用于对象调度。&lt;/li&gt;
&lt;li&gt;Kubernetes中有一个比较特别的镜像，叫做&lt;code&gt;google_containers/pause&lt;/code&gt;，这个镜像是用来实现Pod概念的。&lt;/li&gt;
&lt;li&gt;HPA horizontal pod autoscaling 横向移动扩容，也是一种资源对象，根据负载变化情况针对性的调整pod目标副本数。&lt;/li&gt;
&lt;li&gt;Kubernetes中有三个IP，Node,Pod,Cluster IP的关系比较复杂，docker中没有Cluster IP的概念。&lt;/li&gt;
&lt;li&gt;持久化存储，在Kubernetes中有Persistent volume 只能是网络存储，不属于任何node，独立于pod之外，而docker只能使用&lt;code&gt;volume plugin&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;多租户管理，kubernetes中有`Namespace，docker暂时没有多租户管理功能。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总体来说Docker架构更加简单，使用起来也没有那么多的配置，只需要每个结点都安装docker即可，调度和管理功能没kubernetes那么复杂。但是kubernetes本身就是一个通用的数据中心管理工具，不仅可以用来管理docker，*pod*这个概念里就可以运行不仅是docker了。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;以后的文章中将结合docker着重讲Kubernetes，基于1.3版本。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Contiv入坑指南-v2plugin</title>
      <link>http://rootsongjc.github.io/blogs/contiv-v2plugin/</link>
      <pubDate>Fri, 10 Mar 2017 11:51:09 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/contiv-v2plugin/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20161022082.jpg&#34; alt=&#34;上海交通大学&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(题图：上海交通大学 Oct 22,2016)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;继续趟昨天挖的坑。&lt;/p&gt;

&lt;p&gt;昨天的&lt;a href=&#34;https://github.com/contiv/netplugin/issues/776&#34;&gt;issue-776&lt;/a&gt;已经得到@gkvijay的回复，原来是因为没有安装contiv/v2plugin的缘故，所以create contiv network失败，我需要自己build一个&lt;strong&gt;docker plugin&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;查看下这个&lt;a href=&#34;https://github.com/contiv/netplugin/commit/8afd1b7718c8424a876760d18484124e0aad3557&#34;&gt;commit&lt;/a&gt;里面有build &lt;strong&gt;v2plugin&lt;/strong&gt;的脚本更改，所以直接调用以下命令就可以build自己的v2plugin。&lt;/p&gt;

&lt;p&gt;前提你需要先build出&lt;code&gt;netctl&lt;/code&gt;、&lt;code&gt;netmaster&lt;/code&gt;、&lt;code&gt;netplugin&lt;/code&gt;三个二进制文件并保存到&lt;strong&gt;bin&lt;/strong&gt;目录下，如果你没自己build直接下载&lt;strong&gt;release&lt;/strong&gt;里面的文件保存进去也行。&lt;/p&gt;

&lt;h3 id=&#34;编译v2plugin插件&#34;&gt;编译v2plugin插件&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;修改config.json插件配置文件&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Json&#34;&gt;{
    &amp;quot;manifestVersion&amp;quot;: &amp;quot;v0&amp;quot;,
    &amp;quot;description&amp;quot;: &amp;quot;Contiv network plugin for Docker&amp;quot;,
    &amp;quot;documentation&amp;quot;: &amp;quot;https://contiv.github.io&amp;quot;,
    &amp;quot;entrypoint&amp;quot;: [&amp;quot;/startcontiv.sh&amp;quot;],
    &amp;quot;network&amp;quot;: {
           &amp;quot;type&amp;quot;: &amp;quot;host&amp;quot;
    },
    &amp;quot;env&amp;quot;: [
       {
          &amp;quot;Description&amp;quot;: &amp;quot;To enable debug mode, set to &#39;-debug&#39;&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;dbg_flag&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;-debug&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;VLAN uplink interface used by OVS&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;iflist&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;Etcd or Consul cluster store url&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;cluster_store&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;etcd://172.20.0.113:2379&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;Local IP address to be used by netplugin for control communication&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;ctrl_ip&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;none&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;Local VTEP IP address to be used by netplugin&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;vtep_ip&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;none&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;In &#39;master&#39; role, plugin runs netmaster and netplugin&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;plugin_role&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;master&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;Netmaster url to listen http requests on&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;listen_url&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;172.20.0.113:9999&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;Network Driver name for requests to dockerd. Should be same as name:tag of the plugin&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;plugin_name&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;contiv/v2plugin:latest&amp;quot;
       }
    ],
    &amp;quot;mounts&amp;quot;: [
       {
          &amp;quot;type&amp;quot;: &amp;quot;bind&amp;quot;,
          &amp;quot;options&amp;quot;: [&amp;quot;rbind&amp;quot;],
          &amp;quot;source&amp;quot;: &amp;quot;/etc/openvswitch&amp;quot;,
          &amp;quot;destination&amp;quot;: &amp;quot;/etc/openvswitch&amp;quot;
       },
       {
          &amp;quot;type&amp;quot;: &amp;quot;bind&amp;quot;,
          &amp;quot;options&amp;quot;: [&amp;quot;rbind&amp;quot;],
          &amp;quot;source&amp;quot;: &amp;quot;/var/log/openvswitch&amp;quot;,
          &amp;quot;destination&amp;quot;: &amp;quot;/var/log/openvswitch&amp;quot;
       },
       {
          &amp;quot;type&amp;quot;: &amp;quot;bind&amp;quot;,
          &amp;quot;options&amp;quot;: [&amp;quot;rbind&amp;quot;],
          &amp;quot;source&amp;quot;: &amp;quot;/var/run&amp;quot;,
          &amp;quot;destination&amp;quot;: &amp;quot;/var/run&amp;quot;
       },
       {
          &amp;quot;type&amp;quot;: &amp;quot;bind&amp;quot;,
          &amp;quot;options&amp;quot;: [&amp;quot;rbind&amp;quot;],
          &amp;quot;source&amp;quot;: &amp;quot;/lib/modules&amp;quot;,
          &amp;quot;destination&amp;quot;: &amp;quot;/lib/modules&amp;quot;
       }
    ],
    &amp;quot;interface&amp;quot; : {
          &amp;quot;types&amp;quot;: [&amp;quot;docker.networkdriver/1.0&amp;quot;, &amp;quot;docker.ipamdriver/1.0&amp;quot;],
          &amp;quot;socket&amp;quot;: &amp;quot;netplugin.sock&amp;quot;
    },
    &amp;quot;Linux&amp;quot;: {
          &amp;quot;Capabilities&amp;quot;: [&amp;quot;CAP_SYS_ADMIN&amp;quot;, &amp;quot;CAP_NET_ADMIN&amp;quot;, &amp;quot;CAP_SYS_MODULE&amp;quot;]
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/docker/docker/blob/master/docs/extend/config.md&#34;&gt;关于&lt;strong&gt;docker plugin v2&lt;/strong&gt;配置文件的说明&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;方法一&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;自动化make&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$make host-pluginfs-create
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;方法二&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;直接调用Makefile里指定的那个shell脚本&lt;code&gt;scripts/v2plugin_rootfs.sh&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;$bash scripts/v2plugin_rootfs
Creating rootfs for v2plugin ,
sed: 1: &amp;quot;install/v2plugin/config ...&amp;quot;: command i expects \ followed by text
Sending build context to Docker daemon 73.94 MB
Step 1/5 : FROM alpine:3.5
 ---&amp;gt; 4a415e366388
Step 2/5 : MAINTAINER Cisco Contiv (http://contiv.github.io/)
 ---&amp;gt; Running in fada1677341b
 ---&amp;gt; f0440792dff6
Removing intermediate container fada1677341b
Step 3/5 : RUN mkdir -p /run/docker/plugins /etc/openvswitch /var/run/contiv/log     &amp;amp;&amp;amp; echo &#39;http://dl-cdn.alpinelinux.org/alpine/v3.4/main&#39; &amp;gt;&amp;gt; /etc/apk/repositories     &amp;amp;&amp;amp; apk update &amp;amp;&amp;amp; apk add openvswitch=2.5.0-r0 iptables
 ---&amp;gt; Running in 2ae2fbee6834
fetch http://dl-cdn.alpinelinux.org/alpine/v3.5/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.5/community/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.4/main/x86_64/APKINDEX.tar.gz
v3.5.2-3-g3649125268 [http://dl-cdn.alpinelinux.org/alpine/v3.5/main]
v3.5.1-71-gc7bb9a04f0 [http://dl-cdn.alpinelinux.org/alpine/v3.5/community]
v3.4.6-81-g1f1f409 [http://dl-cdn.alpinelinux.org/alpine/v3.4/main]
OK: 13194 distinct packages available
(1/6) Installing libmnl (1.0.4-r0)
(2/6) Installing libnftnl-libs (1.0.7-r0)
(3/6) Installing iptables (1.6.0-r0)
(4/6) Installing libcrypto1.0 (1.0.2k-r0)
(5/6) Installing libssl1.0 (1.0.2k-r0)
(6/6) Installing openvswitch (2.5.0-r0)
Executing busybox-1.25.1-r0.trigger
OK: 19 MiB in 17 packages
 ---&amp;gt; b130141ad660
Removing intermediate container 2ae2fbee6834
Step 4/5 : COPY netplugin netmaster netctl startcontiv.sh /
 ---&amp;gt; 2b88b2f8e5e7
Removing intermediate container d7580a394c64
Step 5/5 : ENTRYPOINT /startcontiv.sh
 ---&amp;gt; Running in e6fc5c887cb3
 ---&amp;gt; 1c569e4c633d
Removing intermediate container e6fc5c887cb3
Successfully built 1c569e4c633d
Password:
03d60dc01488362156f98a062d17af7a34e4b17569c2fe4f5d2048d619860314
Untagged: contivrootfs:latest
Deleted: sha256:1c569e4c633d27bd3e79d9d30b2825ce57452d30f90a3452304b932835331b13
Deleted: sha256:2b88b2f8e5e7bae348bf296f6254662c1d444760db5acd1764b9c955b106adad
Deleted: sha256:b60594671dc9312bf7ba73bf17abb9704d2b0d0e802c0d990315c5b4a5ca11fe
Deleted: sha256:b130141ad660d4ee291d9eb9a1e0704c4bc009fc91a73de28e8fd110aa45c481
Deleted: sha256:ab3c02d5a171681ba00d27f2c456cf8b63eeeaf408161dc84d9d89526d0399de
Deleted: sha256:f0440792dff6a89e321cc5d34ecaa21b4cb993f0c4e4df6c2b04eef8878bb471
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;创建镜像这一步需要输入你的docker hub密码。而且alpine下载软件需要翻墙的。打包v2plugin目录需要使用sudo，不然会报一个错。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;整个插件打包压缩后的大小是91M。现在&lt;code&gt;rootfs&lt;/code&gt;和&lt;code&gt;config.json&lt;/code&gt;都已经有了，就可以在你自己的系统上create docker plugin了。&lt;/p&gt;

&lt;h2 id=&#34;启动contiv-plugin&#34;&gt;启动contiv plugin&lt;/h2&gt;

&lt;p&gt;创建docker network plugin并enable。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;$docker plugin create contiv/v2plugin .
contiv/v2plugin
$docker plugin enable contiv/v2plugin
$docker plugin ls
ID                  NAME                     DESCRIPTION                        ENABLED
574d4a4d82a3        contiv/v2plugin:latest   Contiv network plugin for Docker   true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至此*contiv plugin*已经创建好了，enable后执行&lt;code&gt;ip addr&lt;/code&gt;命令可以看到多出一个网络*contivh0*。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;contivh0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UNKNOWN qlen 1000
link/ether 02:02:ac:13:ff:fe brd ff:ff:ff:ff:ff:ff
inet 172.19.255.254/16 scope global contivh0
	valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;且主机多了一个IP地址*172.19.255.254*。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;不需要再主机上安装&lt;code&gt;netctl&lt;/code&gt;、&lt;code&gt;netmaster&lt;/code&gt;、&lt;code&gt;netplugin&lt;/code&gt;这几个二进制文件了，只需要安装&lt;code&gt;docker plugin&lt;/code&gt;即可，这些都已经封装到plugin中了，如果你看下插件的目录结构就知道了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;因为插件安装的问题，目前我测试机上的自定义插件都无法使用，正在troubleshooting中，一旦有进展会及时更新该文档。&lt;/p&gt;

&lt;p&gt;另外正在同步跟开发者沟通中，因为时差问题，下周一才能有结果。😪&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Contiv入坑指南-试用全记录</title>
      <link>http://rootsongjc.github.io/blogs/contiv-tryout/</link>
      <pubDate>Thu, 09 Mar 2017 14:23:04 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/contiv-tryout/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/2017013129.jpg&#34; alt=&#34;黄昏&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(题图：山东荣成滨海风力发电场  Jan 31,2017）&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;关于contiv的介绍请看我的上一篇文章&lt;a href=&#34;http://rootsongjc.github.io/post/contiv_guide/&#34;&gt;Contiv Intro&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;开发环境使用&lt;strong&gt;Vagrant&lt;/strong&gt;搭建，昨天试用了下，真不知道它们是怎么想的，即然是docker插件为啥不直接在docker中开发呢，我有篇文章介绍&lt;a href=&#34;http://rootsongjc.github.io/post/docker-dev-env/&#34;&gt;如何搭建docker开发环境&lt;/a&gt;，可以在docker中开发docker，当然也可以用来开发contiv啊😄，只要下载一个docker镜像&lt;code&gt;dockercore/docker:latest&lt;/code&gt;即可，不过有点大2.31G，使用阿里云的mirror下载倒是也划算，总比你自己部署一个开发环境节省时间。&lt;/p&gt;

&lt;h3 id=&#34;contiv概念解析&#34;&gt;Contiv概念解析&lt;/h3&gt;

&lt;p&gt;Contiv用于给容器创建和分配网路，可以创建策略管理容器的安全、带宽、优先级等，相当于一个SDN。&lt;/p&gt;

&lt;h4 id=&#34;group&#34;&gt;Group&lt;/h4&gt;

&lt;p&gt;按容器或Pod的功能给容器分配策略组，通常是按照容器/Pod的&lt;code&gt;label&lt;/code&gt;来分组，应用组跟contiv的network不是一一对应的，可以很多应用组属于同一个network或IP subnet。&lt;/p&gt;

&lt;h4 id=&#34;polices&#34;&gt;Polices&lt;/h4&gt;

&lt;p&gt;用来限定group的行为，contiv支持两种类型的policy：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Bandwidth 限定应用组的资源使用上限&lt;/li&gt;
&lt;li&gt;Isolation 资源组的访问权限&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Group可以同时应用一个或多个policy，当有容器调度到该group里就会适用该group的policy。&lt;/p&gt;

&lt;h4 id=&#34;network&#34;&gt;Network&lt;/h4&gt;

&lt;p&gt;IPv4或IPv6网络，可以配置subnet和gateway。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Contiv中的网络&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在contiv中可以配置两种类型的网络&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;application network：容器使用的网络&lt;/li&gt;
&lt;li&gt;infrastructure network：host namespace的虚拟网络，比如基础设施监控网络&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;网络封装&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Contiv中有两种类型的网络封装&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Routed：overlay topology和L3-routed BGP topology&lt;/li&gt;
&lt;li&gt;Bridged：layer2 VLAN&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;tenant&#34;&gt;Tenant&lt;/h4&gt;

&lt;p&gt;Tenant提供contiv中的namespace隔离。一个tenant可以有很多个network，每个network都有个subnet。该tenant中的用户可以使用它的任意network和subnet的IP。&lt;/p&gt;

&lt;p&gt;物理网络中的tenant称作&lt;code&gt;虚拟路由转发(VRF)&lt;/code&gt;。Contiv使用VLAN和VXLAN ID来实现外部网络访问，这取决你使用的是layer2、layer3还是Cisco ACI。&lt;/p&gt;

&lt;h3 id=&#34;contiv下载&#34;&gt;Contiv下载&lt;/h3&gt;

&lt;p&gt;Contiv的编译安装比较复杂，我们直接下载github上的&lt;a href=&#34;[1.0.0-beta.3-03-08-2017.18-51-20.UTC](https://github.com/contiv/netplugin/releases/tag/1.0.0-beta.3-03-08-2017.18-51-20.UTC)&#34;&gt;release-1.0.0-beta.3-03-08-2017.18-51-20.UTC&lt;/a&gt;文件解压获得二进制文件安装。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/contiv/install/blob/master/README.md这个官方文档已经过时，不要看了。&#34;&gt;https://github.com/contiv/install/blob/master/README.md这个官方文档已经过时，不要看了。&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;如果试用可以的话，我会后续写contiv开发环境搭建的文章。&lt;/p&gt;

&lt;p&gt;这个release是2017年3月8日发布的，就在我写这篇文章的前一天。有个&lt;strong&gt;最重要的更新&lt;/strong&gt;是&lt;u&gt;支持docker1.13 swarm mode&lt;/u&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/contiv/netplugin/blob/master/install/HowtoSetupContiv.md&#34;&gt;官方安装文档&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;下载解压后会得到如下几个文件：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;contivk8s  k8s专用的&lt;/li&gt;
&lt;li&gt;contrib  文件夹，里面有个&lt;code&gt;netctl&lt;/code&gt;的bash脚本&lt;/li&gt;
&lt;li&gt;netcontiv  这个命令就一个-version选项用来查看contiv的版本😓&lt;/li&gt;
&lt;li&gt;netctl  contiv命令行工具，用来配置网络、策略、服务负载均衡，&lt;a href=&#34;http://contiv.github.io/documents/reference/netctlcli.html&#34;&gt;使用说明&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;netmaster  contiv的主节点服务&lt;/li&gt;
&lt;li&gt;netplugin&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面的安装中用到的只有netctl、netmaster和netplugin这三个二进制文件。&lt;/p&gt;

&lt;p&gt;我们将这三个文件都copy到/usr/bin目录下。&lt;/p&gt;

&lt;p&gt;我们在docker17.03-ce中安装contiv。&lt;/p&gt;

&lt;h3 id=&#34;contiv安装依赖&#34;&gt;Contiv安装依赖&lt;/h3&gt;

&lt;p&gt;Contiv依赖于consul或etcd，我们选择使用etcd，slack里的人说只支持2.3.x版本，可能不支持3.0+版本的吧，还没实际测过，先使用2.3.7。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;contiv master&lt;/code&gt;启动后自动向etcd中注册信息：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/contiv.io/oper
/contiv.io/oper/auto-vlan
/contiv.io/oper/auto-vlan/global
/contiv.io/oper/auto-vxlan
/contiv.io/oper/auto-vxlan/global
/contiv.io/oper/global
/contiv.io/oper/global/global
/contiv.io/oper/ovs-driver
/contiv.io/oper/ovs-driver/sz-pg-oam-docker-test-001.tendcloud.com
/contiv.io/master
/contiv.io/master/config
/contiv.io/master/config/global
/contiv.io/obj
/contiv.io/obj/modeldb
/contiv.io/obj/modeldb/global
/contiv.io/obj/modeldb/global/global
/contiv.io/obj/modeldb/tenant
/contiv.io/obj/modeldb/tenant/default
/contiv.io/lock
/contiv.io/lock/netmaster
/contiv.io/lock/netmaster/leader
/contiv.io/service
/contiv.io/service/netmaster
/contiv.io/service/netmaster/172.20.0.113:9999
/contiv.io/service/netmaster.rpc
/contiv.io/service/netmaster.rpc/172.20.0.113:9001
/contiv.io/state
/contiv.io/state/auto-vlan
/contiv.io/state/auto-vlan/global
/contiv.io/state/auto-vxlan
/contiv.io/state/auto-vxlan/global
/contiv.io/state/global
/contiv.io/state/global/global
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;contiv启动&#34;&gt;Contiv启动&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;启动netmaster&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$nohup netmaster -cluster-mode docker -cluster-store etcd://172.20.0.113:2379 -debug -listen-url 172.20.0.113:9999 -plugin-name netplugin &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为了突出netmaster命令的使用，我把所有可以使用默认值的参数都明确的写出。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;netmaster&lt;/code&gt;监听9999端口。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;查看已有的contiv网络&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$netctl --netmaster http://172.20.0.113:9999 network ls
Tenant  Network  Nw Type  Encap type  Packet tag  Subnet   Gateway  IPv6Subnet  IPv6Gateway
------  -------  -------  ----------  ----------  -------  ------   ----------  -----------
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为了以后执行命令方便，不用来回输入&lt;code&gt;$NETMASTER&lt;/code&gt;地址，可以将其设置为环境变量&lt;/p&gt;

&lt;p&gt;&lt;code&gt;export NETMASTER=&amp;quot;http://172.20.0.113:9999&amp;quot;&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;netplugin需要使用Open vSwitch，所以你需要先安装&lt;strong&gt;Open vSwitch&lt;/strong&gt;。否则你会遇到这个问题&lt;a href=&#34;https://github.com/contiv/netplugin/issues/760&#34;&gt;netplugin issue-760&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;open-vswitch安装&#34;&gt;Open vSwitch安装&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://supercomputing.caltech.edu/blog/index.php/2016/05/03/open-vswitch-installation-on-centos-7-2/&#34;&gt;Open vSwitch installation on CentOS7.2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;参考上面链接里的方法。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#!/bin/bash
yum -y install make gcc openssl-devel autoconf automake rpm-build redhat-rpm-config python-devel openssl-devel kernel-devel kernel-debug-devel libtool wget
mkdir -p ~/rpmbuild/SOURCES
cp openvswitch-2.5.1.tar.gz ~/rpmbuild/SOURCES/
tar xfz openvswitch-2.5.1.tar.gz
sed &#39;s/openvswitch-kmod, //g&#39; openvswitch-2.5.1/rhel/openvswitch.spec &amp;gt; openvswitch-2.5.1/rhel/openvswitch_no_kmod.spec
rpmbuild -bb --nocheck ~/openvswitch-2.5.1/rhel/openvswitch_no_kmod.spec
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;编译好的rpm包在&lt;code&gt;~/rpmbuild/RPMS/x86_64/openvswitch-2.5.1-1.x86_64.rpm&lt;/code&gt;目录下。&lt;/p&gt;

&lt;p&gt;安装好Open vSwitch后就可以启动&lt;strong&gt;netplugin&lt;/strong&gt;。&lt;/p&gt;

&lt;h3 id=&#34;创建contiv网络&#34;&gt;创建contiv网络&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;启动netplugin&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;nohup netplugin -cluster-store etcd://172.20.0.113:2379 &amp;amp;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;创建network&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;netctl --netmaster http://172.20.0.113:9999 network create --subnet=10.1.2.0/24 contiv-net&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;获得以下报错：&lt;/p&gt;

&lt;p&gt;ERRO[0000] Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&lt;/p&gt;

&lt;p&gt;但是执行第二次的时候居然成功了，不过当我查看docker network的时候根本就看不到刚刚创建的contiv-net网络。*这只是一场游戏一场梦。。。*😢&lt;/p&gt;

&lt;p&gt;Creating network default:contiv-net&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$netctl network ls
Tenant   Network     Nw Type  Encap type  Packet tag  Subnet       Gateway  IPv6Subnet  IPv6Gateway
------   -------     -------  ----------  ----------  -------      ------   ----------  -----------
default  contiv-net  data     vxlan       0           10.1.2.0/24  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看刚创建的contiv-net网络。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$netctl network inspect contiv-net
Inspeting network: contiv-net tenant: default
{
  &amp;quot;Config&amp;quot;: {
    &amp;quot;key&amp;quot;: &amp;quot;default:contiv-net&amp;quot;,
    &amp;quot;encap&amp;quot;: &amp;quot;vxlan&amp;quot;,
    &amp;quot;networkName&amp;quot;: &amp;quot;contiv-net&amp;quot;,
    &amp;quot;nwType&amp;quot;: &amp;quot;data&amp;quot;,
    &amp;quot;subnet&amp;quot;: &amp;quot;10.1.2.0/24&amp;quot;,
    &amp;quot;tenantName&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;link-sets&amp;quot;: {},
    &amp;quot;links&amp;quot;: {
      &amp;quot;Tenant&amp;quot;: {
        &amp;quot;type&amp;quot;: &amp;quot;tenant&amp;quot;,
        &amp;quot;key&amp;quot;: &amp;quot;default&amp;quot;
      }
    }
  },
  &amp;quot;Oper&amp;quot;: {
    &amp;quot;availableIPAddresses&amp;quot;: &amp;quot;10.1.2.1-10.1.2.254&amp;quot;,
    &amp;quot;externalPktTag&amp;quot;: 1,
    &amp;quot;pktTag&amp;quot;: 1
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从&lt;strong&gt;netmaster&lt;/strong&gt;日志中可以看到如下报错：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;time=&amp;quot;Mar  9 21:44:14.746627381&amp;quot; level=debug msg=&amp;quot;NwInfra type is default, no ACI&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.750278056&amp;quot; level=info msg=&amp;quot;Creating docker network: {CheckDuplicate:true Driver:netplugin EnableIPv6:false IPAM:0xc4204d8ea0 Internal:false Attachable:true Options:map[tenant:default encap:vxlan pkt-tag:1] Labels:map[]}&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.752034749&amp;quot; level=error msg=&amp;quot;Error creating network contiv-net. Err: Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.752067294&amp;quot; level=error msg=&amp;quot;Error creating network contiv-net.default in docker. Err: Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.752102735&amp;quot; level=error msg=&amp;quot;Error creating network {&amp;amp;{Key:default:contiv-net Encap:vxlan Gateway: Ipv6Gateway: Ipv6Subnet: NetworkName:contiv-net NwType:data PktTag:0 Subnet:10.1.2.0/24 TenantName:default LinkSets:{EndpointGroups:map[] Servicelbs:map[] Services:map[]} Links:{Tenant:{ObjType: ObjKey:}}}}. Err: Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.752129195&amp;quot; level=error msg=&amp;quot;NetworkCreate retruned error for: &amp;amp;{Key:default:contiv-net Encap:vxlan Gateway: Ipv6Gateway: Ipv6Subnet: NetworkName:contiv-net NwType:data PktTag:0 Subnet:10.1.2.0/24 TenantName:default LinkSets:{EndpointGroups:map[] Servicelbs:map[] Services:map[]} Links:{Tenant:{ObjType: ObjKey:}}}. Err: Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.752155973&amp;quot; level=error msg=&amp;quot;CreateNetwork error for: {Key:default:contiv-net Encap:vxlan Gateway: Ipv6Gateway: Ipv6Subnet: NetworkName:contiv-net NwType:data PktTag:0 Subnet:10.1.2.0/24 TenantName:default LinkSets:{EndpointGroups:map[] Servicelbs:map[] Services:map[]} Links:{Tenant:{ObjType: ObjKey:}}}. Err: Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.752172138&amp;quot; level=error msg=&amp;quot;Handler for POST /api/v1/networks/default:contiv-net/ returned error: Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&amp;quot; 
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;从日志中看到一个令人悲痛语句的话*legacy plugin netplugin of type NetworkDriver is not supported in swarm mode*，你们昨天不是刚发的版本说已经支持swarm mode吗？&lt;a href=&#34;https://github.com/contiv/netplugin/commit/8afd1b7718c8424a876760d18484124e0aad3557&#34;&gt;&lt;code&gt;commit-8afd1b7&lt;/code&gt;&lt;/a&gt;不是白纸黑字的写着吗？&lt;/p&gt;

&lt;p&gt;我提了个&lt;a href=&#34;https://github.com/contiv/netplugin/issues/776&#34;&gt;issue-776&lt;/a&gt;，看看怎样解决这个问题，另外netplugin命令怎么用，文档上没写啊？&lt;/p&gt;

&lt;p&gt;&lt;code&gt;netplugin -h&lt;/code&gt;可以中有两个选项我不明白，不知道怎么设置，有知道的人请告诉我一声。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  -vlan-if value
    	VLAN uplink interface
  -vtep-ip string
    	My VTEP ip address
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同时我会继续关注contiv的slack和github &lt;a href=&#34;https://github.com/contiv/netplugin/issues/776&#34;&gt;Issue-776&lt;/a&gt;的进展。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Contiv Intro</title>
      <link>http://rootsongjc.github.io/blogs/contiv-guide/</link>
      <pubDate>Thu, 09 Mar 2017 11:28:34 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/contiv-guide/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/2017021162.jpg&#34; alt=&#34;蓝色港湾&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(题图：北京蓝色港湾夜景 Feb 11,2017 元宵节)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Contiv&lt;/strong&gt;是思科开发的docker网络插件，从2015年就开源了，业界通常拿它和Calico比较。貌似Contiv以前还开发过volume plugin，现在销声匿迹了，只有netplugin仍在活跃开发。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://dockone.io/article/1935&#34;&gt;容器网络插件 Calico 与 Contiv Netplugin深入比较&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;还有篇文章讲解了&lt;a href=&#34;http://blog.dataman-inc.com/shurenyun-docker-133/&#34;&gt;docker网络方案的改进&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;contiv-netplugin-简介&#34;&gt;Contiv Netplugin 简介&lt;/h3&gt;

&lt;p&gt;Contiv Netplugin 是来自思科的解决方案。编程语言为 Go。它基于 OpenvSwitch，以插件化的形式支持容器访问网络，支持 VLAN，Vxlan，多租户，主机访问控制策略等。作为思科整体支持容器基础设施contiv项目的网络部分，最大的亮点在于容器被赋予了 SDN 能力，实现对容器更细粒度，更丰富的访问控制功能。另外，对 Docker CNM 网络模型的支持，并内置了 IPAM 接口，不仅仅提供了一容器一 IP，而且容器的网络信息被记录的容器配置中，伴随着容器的整个生命周期，减低因为状态不同步造成网络信息丢失的风险。有别于 CNI，这种内聚化的设计有利于减少对第三方模块的依赖。随着项目的发展，除了 Docker，还提供了对 Kubernetes 以及 Mesos 的支持，即 CNI 接口。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://dockerone.com/uploads/article/20161221/c737f78ce7c50c84e49648aaf771a6b4.png&#34;&gt;&lt;img src=&#34;http://dockerone.com/uploads/article/20161221/c737f78ce7c50c84e49648aaf771a6b4.png&#34; alt=&#34;9260E9B7-43C0-48B8-B5C7-CF8B952959D2.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Netmaster 后台进程负责记录所有节点状态，保存网络信息，分配 IP 地址&lt;/li&gt;
&lt;li&gt;Netplugin 后台进程作为每个宿主机上的 Agent 与 Docker 及 OVS 通信，处理来自 Docker 的请求，管理 OVS。Docker 方面接口为 remote driver，包括一系列 Docker 定义的 JSON-RPC(POST) 消息。OVS 方面接口为 remote ovsdb，也是 JSON-RPC 消息。以上消息都在 localhost 上处理。&lt;/li&gt;
&lt;li&gt;集群管理依赖 etcd/serf&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;http://dockerone.com/uploads/article/20161221/852b276222482c4740b690eb7f078409.png&#34;&gt;&lt;img src=&#34;http://dockerone.com/uploads/article/20161221/852b276222482c4740b690eb7f078409.png&#34; alt=&#34;580469BC-468C-49C8-B29E-8B88143AFE0A.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;netplugin的优势&#34;&gt;Netplugin的优势&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;较早支持CNM模型。与已有的网络基础设施兼容性较高，改造影响小。基于VLAN的平行扩展与现有网络结构地位对等&lt;/li&gt;
&lt;li&gt;SDN能力，能够对容器的网络访问做更精细的控制&lt;/li&gt;
&lt;li&gt;多租户支持，具备未来向混合云/公有云迁移的潜力&lt;/li&gt;
&lt;li&gt;代码规模不大，逻辑结构清晰，并发好，VLAN在公司内部有开发部署运维实践经验，稳定性经过生产环境验证&lt;/li&gt;
&lt;li&gt;&lt;u&gt;&lt;strong&gt;京东&lt;/strong&gt;基于相同的技术栈（OVS + VLAN）已支持10w+ 容器的运行。&lt;/u&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;next&#34;&gt;Next&lt;/h3&gt;

&lt;p&gt;后续文章会讲解contiv netplugin的环境配置和开发。目前还在1.0-beta版本。&lt;strong&gt;Docker store&lt;/strong&gt;上提供了contiv插件的&lt;a href=&#34;https://store.docker.com/plugins/803eecee-0780-401a-a454-e9523ccf86b3&#34;&gt;下载地址&lt;/a&gt;。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Packer Intro</title>
      <link>http://rootsongjc.github.io/blogs/packer-intro/</link>
      <pubDate>Thu, 09 Mar 2017 10:58:42 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/packer-intro/</guid>
      <description>&lt;p&gt;昨天研究了下&lt;a href=&#34;https://github.com/mitchellh/vagrant&#34;&gt;&lt;strong&gt;Vagrant&lt;/strong&gt;&lt;/a&gt;，感觉它的虚拟机ruby格式定义很麻烦，经人指点还有一个叫做&lt;a href=&#34;https://github.com/mitchellh/packer&#34;&gt;&lt;strong&gt;packer&lt;/strong&gt;&lt;/a&gt;的东西，也是Hashicorp这家公司出品的，今天看了下。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Packer&lt;/strong&gt;是一款开源轻量级的镜像定义工具，可以根据一份定义文件生成多个平台的镜像，支持的平台有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Amazon EC2 (AMI). Both EBS-backed and instance-store AMIs&lt;/li&gt;
&lt;li&gt;Azure&lt;/li&gt;
&lt;li&gt;DigitalOcean&lt;/li&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;li&gt;Google Compute Engine&lt;/li&gt;
&lt;li&gt;OpenStack&lt;/li&gt;
&lt;li&gt;Parallels&lt;/li&gt;
&lt;li&gt;QEMU. Both KVM and Xen images.&lt;/li&gt;
&lt;li&gt;VirtualBox&lt;/li&gt;
&lt;li&gt;VMware&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Packer创造的镜像也能转换成&lt;strong&gt;Vagrant boxes&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;Packer的镜像创建需要一个json格式的定义文件，例如&lt;code&gt;quick-start.json&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;variables&amp;quot;: {
    &amp;quot;access_key&amp;quot;: &amp;quot;{{env `AWS_ACCESS_KEY_ID`}}&amp;quot;,
    &amp;quot;secret_key&amp;quot;: &amp;quot;{{env `AWS_SECRET_ACCESS_KEY`}}&amp;quot;
  },
  &amp;quot;builders&amp;quot;: [{
    &amp;quot;type&amp;quot;: &amp;quot;amazon-ebs&amp;quot;,
    &amp;quot;access_key&amp;quot;: &amp;quot;{{user `access_key`}}&amp;quot;,
    &amp;quot;secret_key&amp;quot;: &amp;quot;{{user `secret_key`}}&amp;quot;,
    &amp;quot;region&amp;quot;: &amp;quot;us-east-1&amp;quot;,
    &amp;quot;source_ami&amp;quot;: &amp;quot;ami-af22d9b9&amp;quot;,
    &amp;quot;instance_type&amp;quot;: &amp;quot;t2.micro&amp;quot;,
    &amp;quot;ssh_username&amp;quot;: &amp;quot;ubuntu&amp;quot;,
    &amp;quot;ami_name&amp;quot;: &amp;quot;packer-example {{timestamp}}&amp;quot;
  }]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用&lt;code&gt;packer build quick-start.json&lt;/code&gt;可以在AWS上build一个AIM镜像。&lt;/p&gt;

&lt;p&gt;Packer的详细文档：&lt;a href=&#34;https://www.packer.io/docs/&#34;&gt;https://www.packer.io/docs/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Vagrant介绍-从使用到放弃完全指南</title>
      <link>http://rootsongjc.github.io/blogs/vagrant-intro/</link>
      <pubDate>Wed, 08 Mar 2017 20:40:08 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/vagrant-intro/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/2017030513.jpg&#34; alt=&#34;光熙家园夜景&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：北京地铁13号线光熙家园夜景 Mar 5,2017）&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;起源&#34;&gt;起源&lt;/h2&gt;

&lt;p&gt;久闻&lt;strong&gt;Vagrant&lt;/strong&gt;大名，之前经常看到有开源项目使用它作为分布式开发的环境配置。&lt;/p&gt;

&lt;p&gt;因为今天在看&lt;a href=&#34;https://github.com/contiv/netplugin&#34;&gt;contiv&lt;/a&gt;正好里面使用vagrant搭建的开发测试环境，所以顺便了解下。它的&lt;a href=&#34;https://github.com/contiv/netplugin/blob/master/Vagrantfile&#34;&gt;Vagrantfile&lt;/a&gt;文件中定义了三台主机。并安装了很多依赖软件，如consul、etcd、docker、go等，整的比较复杂。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;➜  netplugin git:(master) ✗ vagrant status
Current machine states:

netplugin-node1           running (virtualbox)
netplugin-node2           running (virtualbox)
netplugin-node3           running (virtualbox)

This environment represents multiple VMs. The VMs are all listed
above with their current state. For more information about a specific
VM, run `vagrant status NAME`.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Vagrant是&lt;a href=&#34;https://www.hashicorp.com/&#34;&gt;hashicorp&lt;/a&gt;这家公司的产品，这家公司主要做数据中心PAAS和虚拟化，其名下大名鼎鼎的产品有&lt;code&gt;Consul&lt;/code&gt;、&lt;code&gt;Vault&lt;/code&gt;、&lt;code&gt;Nomad&lt;/code&gt;、&lt;code&gt;Terraform&lt;/code&gt;。他们的产品都是基于&lt;strong&gt;Open Source&lt;/strong&gt;的&lt;a href=&#34;https://github.com/hashicorp&#34;&gt;Github地址&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;用途&#34;&gt;用途&lt;/h2&gt;

&lt;p&gt;Vagrant是用来管理虚拟机的，如VirtualBox、VMware、AWS等，主要好处是可以提供一个可配置、可移植和复用的软件环境，可以使用shell、chef、puppet等工具部署。所以vagrant不能单独使用，如果你用它来管理自己的开发环境的话，必须在自己的电脑里安装了虚拟机软件，我使用的是&lt;strong&gt;virtualbox&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;Vagrant提供一个命令行工具&lt;code&gt;vagrant&lt;/code&gt;，通过这个命令行工具可以直接启动一个虚拟机，当然你需要提前定义一个Vagrantfile文件，这有点类似Dockerfile之于docker了。&lt;/p&gt;

&lt;p&gt;跟docker类比这来看vagrant就比较好理解了，vagrant也是用来提供一致性环境的，vagrant本身也提供一个镜像源，使用&lt;code&gt;vagrant init hashicorp/precise64&lt;/code&gt;就可以初始化一个Ubuntu 12.04的镜像。&lt;/p&gt;

&lt;h2 id=&#34;用法&#34;&gt;用法&lt;/h2&gt;

&lt;p&gt;你可以下载安装文件来安装vagrant，也可以使用RubyGem安装，它是用Ruby开发的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Vagrantfile&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Vagrantfile是用来定义vagrant project的，使用ruby语法，不过你不必了解ruby就可以写一个Vagrantfile。&lt;/p&gt;

&lt;p&gt;看个例子，选自&lt;a href=&#34;https://github.com/fenbox/Vagrantfile&#34;&gt;https://github.com/fenbox/Vagrantfile&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Ruby&#34;&gt;# -*- mode: ruby -*-
# vi: set ft=ruby :

# All Vagrant configuration is done below. The &amp;quot;2&amp;quot; in Vagrant.configure
# configures the configuration version (we support older styles for
# backwards compatibility). Please don&#39;t change it unless you know what
# you&#39;re doing.
Vagrant.configure(&amp;quot;2&amp;quot;) do |config|
  # The most common configuration options are documented and commented below.
  # For a complete reference, please see the online documentation at
  # https://docs.vagrantup.com.

  # Every Vagrant development environment requires a box. You can search for
  # boxes at https://atlas.hashicorp.com/search.
  config.vm.box = &amp;quot;ubuntu/trusty64&amp;quot;

  # Disable automatic box update checking. If you disable this, then
  # boxes will only be checked for updates when the user runs
  # `vagrant box outdated`. This is not recommended.
  # config.vm.box_check_update = false

  # Create a forwarded port mapping which allows access to a specific port
  # within the machine from a port on the host machine. In the example below,
  # accessing &amp;quot;localhost:8080&amp;quot; will access port 80 on the guest machine.
  # config.vm.network &amp;quot;forwarded_port&amp;quot;, guest: 80, host: 8080

  # Create a private network, which allows host-only access to the machine
  # using a specific IP.
  config.vm.network &amp;quot;private_network&amp;quot;, ip: &amp;quot;192.168.33.10&amp;quot;

  # Create a public network, which generally matched to bridged network.
  # Bridged networks make the machine appear as another physical device on
  # your network.
  # config.vm.network &amp;quot;public_network&amp;quot;

  # Share an additional folder to the guest VM. The first argument is
  # the path on the host to the actual folder. The second argument is
  # the path on the guest to mount the folder. And the optional third
  # argument is a set of non-required options.
  # config.vm.synced_folder &amp;quot;../data&amp;quot;, &amp;quot;/vagrant_data&amp;quot;

  # Provider-specific configuration so you can fine-tune various
  # backing providers for Vagrant. These expose provider-specific options.
  # Example for VirtualBox:
  #
  # config.vm.provider &amp;quot;virtualbox&amp;quot; do |vb|
  #   # Display the VirtualBox GUI when booting the machine
  #   vb.gui = true
  #
  #   # Customize the amount of memory on the VM:
  #   vb.memory = &amp;quot;1024&amp;quot;
  # end
  #
  # View the documentation for the provider you are using for more
  # information on available options.

  # Define a Vagrant Push strategy for pushing to Atlas. Other push strategies
  # such as FTP and Heroku are also available. See the documentation at
  # https://docs.vagrantup.com/v2/push/atlas.html for more information.
  # config.push.define &amp;quot;atlas&amp;quot; do |push|
  #   push.app = &amp;quot;YOUR_ATLAS_USERNAME/YOUR_APPLICATION_NAME&amp;quot;
  # end

  # Enable provisioning with a shell script. Additional provisioners such as
  # Puppet, Chef, Ansible, Salt, and Docker are also available. Please see the
  # documentation for more information about their specific syntax and use.
  # config.vm.provision &amp;quot;shell&amp;quot;, inline: &amp;lt;&amp;lt;-SHELL
  #   apt-get update
  #   apt-get install -y apache2
  # SHELL
  config.vm.provision :shell, path: &amp;quot;bootstrap.sh&amp;quot;
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Boxes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Vagrant的基础镜像，相当于docker images。可以在这些基础镜像的基础上制作自己的虚拟机镜像。&lt;/p&gt;

&lt;p&gt;添加一个box&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ vagrant box add hashicorp/precise64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在Vagrantfile中指定box&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Ruby&#34;&gt;Vagrant.configure(&amp;quot;2&amp;quot;) do |config|
  config.vm.box = &amp;quot;hashicorp/precise64&amp;quot;
  config.vm.box_version = &amp;quot;1.1.0&amp;quot;
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;使用ssh进入vagrant&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;vagrant up&lt;/code&gt;后就可以用&lt;code&gt;vagrant ssh $name&lt;/code&gt;进入虚拟机内，如果主机上就一个vagrant可以不指定名字。默认进入的用户是vagrant。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;文件同步&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;vagrant up&lt;/code&gt;后在虚拟机中会有一个&lt;code&gt;/vagrant&lt;/code&gt;目录，这跟你定义&lt;code&gt;Vagrantfile&lt;/code&gt;是同一级目录。&lt;/p&gt;

&lt;p&gt;这个目录跟你宿主机上的目录文件是同步的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;软件安装&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在Vagrantfile中定义要安装的软件和操作。&lt;/p&gt;

&lt;p&gt;例如安装apache&lt;/p&gt;

&lt;p&gt;在与Vagrantfile同级的目录下创建一个&lt;code&gt;bootstrap.sh&lt;/code&gt;文件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#!/usr/bin/env bash

apt-get update
apt-get install -y apache2
if ! [ -L /var/www ]; then
  rm -rf /var/www
  ln -fs /vagrant /var/www
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后在Vagrantfile中使用它。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Ruby&#34;&gt;Vagrant.configure(&amp;quot;2&amp;quot;) do |config|
  config.vm.box = &amp;quot;hashicorp/precise64&amp;quot;
  config.vm.box_version = &amp;quot;1.1.0&amp;quot;
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;网络&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;端口转发&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;Vagrant.configure(&amp;quot;2&amp;quot;) do |config|
  config.vm.box = &amp;quot;hashicorp/precise64&amp;quot;
  config.vm.provision :shell, path: &amp;quot;bootstrap.sh&amp;quot;
  config.vm.network :forwarded_port, guest: 80, host: 4567
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行&lt;code&gt;vagrant reload&lt;/code&gt;或者&lt;code&gt;vagrant up&lt;/code&gt;可以生效。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;分享&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;你自己做的vagrant是可以分享给别人的用的，只要你有一个hashicorp账号，&lt;code&gt;vagrant login&lt;/code&gt;后就可以执行&lt;code&gt;vagrant share&lt;/code&gt;分享，会生成一个URL，其它人也可以访问到你的vagrant里的服务。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;中止&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;vagrant suspend&lt;/li&gt;
&lt;li&gt;Vagrant halt&lt;/li&gt;
&lt;li&gt;Vagrant destroy&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;重构&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;再次执行&lt;code&gt;vagrant up&lt;/code&gt;即可。&lt;/p&gt;

&lt;h2 id=&#34;分布式环境&#34;&gt;分布式环境&lt;/h2&gt;

&lt;p&gt;开发分布式环境下的应用时往往需要多个虚拟机用于测试，这时候才是vagrant显威力的时候。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;定义多个主机&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;Vagrant.configure(&amp;quot;2&amp;quot;) do |config|
  config.vm.provision &amp;quot;shell&amp;quot;, inline: &amp;quot;echo Hello&amp;quot;

  config.vm.define &amp;quot;web&amp;quot; do |web|
    web.vm.box = &amp;quot;apache&amp;quot;
  end

  config.vm.define &amp;quot;db&amp;quot; do |db|
    db.vm.box = &amp;quot;mysql&amp;quot;
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个比较复杂，详见&lt;a href=&#34;https://www.vagrantup.com/docs/multi-machine/&#34;&gt;https://www.vagrantup.com/docs/multi-machine/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;还有一些其它功能，如push、plugins、providers按下不表。&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;总的来说说Vagrant没有Docker好用，但是对于协同开发，用它来定义分布式开发环境还可以，ruby的语法看着有点不习惯，好在也不复杂，如果是团队几个人开发，弄几个虚拟机大家互相拷贝一下也没那么复杂吧？&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>docker源码编译和开发环境搭建</title>
      <link>http://rootsongjc.github.io/blogs/docker-dev-env/</link>
      <pubDate>Mon, 06 Mar 2017 17:03:19 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/docker-dev-env/</guid>
      <description>

&lt;p&gt;看了下网上其他人写的docker开发环境搭建，要么是在ubuntu下搭建，要么就是使用官方说明的build docker-dev镜像的方式一步步搭建的，甚是繁琐，docker hub上有一个docker官方推出的&lt;strong&gt;dockercore/docker&lt;/strong&gt;镜像，其实这就是官网上所说的docker-dev镜像，不过以前的那个deprecated了，使用目前这个镜像搭建docker开发环境是最快捷的了。&lt;/p&gt;

&lt;p&gt;想要修改docker源码和做docker定制开发的同学可以参考下。&lt;/p&gt;

&lt;p&gt;官方指导文档：&lt;a href=&#34;https://docs.docker.com/opensource/code/&#34;&gt;https://docs.docker.com/opensource/code/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;设置docker开发环境：&lt;a href=&#34;https://docs.docker.com/opensource/project/set-up-dev-env/&#34;&gt;https://docs.docker.com/opensource/project/set-up-dev-env/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;docker的编译实质上是在docker容器中运行docker。&lt;/p&gt;

&lt;p&gt;因此在本地编译docker的前提是需要安装了docker，还需要用git把代码pull下来。&lt;/p&gt;

&lt;h3 id=&#34;创建分支&#34;&gt;创建分支&lt;/h3&gt;

&lt;p&gt;为了方便以后给docker提交更改，我们从docker官方fork一个分支。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/rootsongjc/docker.git
git config --local user.name &amp;quot;Jimmy Song&amp;quot;
git config --local user.email &amp;quot;rootsongjc@gmail.com&amp;quot;
git remote add upstream https://github.com/docker/docker.git
git config --local -l
git remote -v
git checkout -b dry-run-test
touch TEST.md
vim TEST.md
git status
git add TEST.md
git commit -am &amp;quot;Making a dry run test.&amp;quot;
git push --set-upstream origin dry-run-test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后就可以在&lt;code&gt;dry-run-test&lt;/code&gt;这个分支下工作了。&lt;/p&gt;

&lt;h3 id=&#34;配置docker开发环境&#34;&gt;配置docker开发环境&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/opensource/project/set-up-dev-env/&#34;&gt;官网&lt;/a&gt;上说需要先清空自己电脑上已有的容器和镜像。&lt;/p&gt;

&lt;p&gt;docker开发环境本质上是创建一个docker镜像，镜像里包含了docker的所有开发运行环境，本地代码通过挂载的方式放到容器中运行，下面这条命令会自动创建这样一个镜像。&lt;/p&gt;

&lt;p&gt;在&lt;code&gt;dry-run-test&lt;/code&gt;分支下执行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;make BIND_DIR=. shell
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该命令会自动编译一个docker镜像，From debian:jessie。这一步会上网下载很多依赖包，速度比较慢。如果翻不了墙的话肯定都会失败。因为需要下载的软件和安装包都是在国外服务器上，不翻墙根本就下载不下来，为了不用这么麻烦，推荐直接使用docker官方的dockercore/docker镜像，也不用以前的docker-dev镜像，那个造就废弃了。这个镜像大小有2.31G。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker pull dockercore/docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用方法见这里：&lt;a href=&#34;https://hub.docker.com/r/dockercore/docker/&#34;&gt;https://hub.docker.com/r/dockercore/docker/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;然后就可以进入到容器里&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;docker run --rm -i --privileged -e BUILDFLAGS -e KEEPBUNDLE -e DOCKER_BUILD_GOGC -e DOCKER_BUILD_PKGS -e DOCKER_CLIENTONLY -e DOCKER_DEBUG -e DOCKER_EXPERIMENTAL -e DOCKER_GITCOMMIT -e DOCKER_GRAPHDRIVER=devicemapper -e DOCKER_INCREMENTAL_BINARY -e DOCKER_REMAP_ROOT -e DOCKER_STORAGE_OPTS -e DOCKER_USERLANDPROXY -e TESTDIRS -e TESTFLAGS -e TIMEOUT -v &amp;quot;/Users/jimmy/Workspace/github/rootsongjc/docker/bundles:/go/src/github.com/docker/docker/bundles&amp;quot; -t &amp;quot;dockercore/docker:latest&amp;quot; bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;按照官网的说明make会报错&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@f2753f78bb6d:/go/src/github.com/docker/docker# ./hack/make.sh binary                          

error: .git directory missing and DOCKER_GITCOMMIT not specified
  Please either build with the .git directory accessible, or specify the
  exact (--short) commit hash you are building using DOCKER_GITCOMMIT for
  future accountability in diagnosing build issues.  Thanks!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是一个&lt;a href=&#34;https://github.com/docker/docker/issues/27581&#34;&gt;issue-27581&lt;/a&gt;，解决方式就是在make的时候手动指定&lt;code&gt;DOCKER_GITCOMMIT&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@f2753f78bb6d:/go/src/github.com/docker/docker# DOCKER_GITCOMMIT=3385658 ./hack/make.sh binary

---&amp;gt; Making bundle: binary (in bundles/17.04.0-dev/binary)
Building: bundles/17.04.0-dev/binary-client/docker-17.04.0-dev
Created binary: bundles/17.04.0-dev/binary-client/docker-17.04.0-dev
Building: bundles/17.04.0-dev/binary-daemon/dockerd-17.04.0-dev
Created binary: bundles/17.04.0-dev/binary-daemon/dockerd-17.04.0-dev
Copying nested executables into bundles/17.04.0-dev/binary-daemon
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;bundles目录下会生成如下文件结构&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;.
├── 17.04.0-dev
│   ├── binary-client
│   │   ├── docker -&amp;gt; docker-17.04.0-dev
│   │   ├── docker-17.04.0-dev
│   │   ├── docker-17.04.0-dev.md5
│   │   └── docker-17.04.0-dev.sha256
│   └── binary-daemon
│       ├── docker-containerd
│       ├── docker-containerd-ctr
│       ├── docker-containerd-ctr.md5
│       ├── docker-containerd-ctr.sha256
│       ├── docker-containerd-shim
│       ├── docker-containerd-shim.md5
│       ├── docker-containerd-shim.sha256
│       ├── docker-containerd.md5
│       ├── docker-containerd.sha256
│       ├── docker-init
│       ├── docker-init.md5
│       ├── docker-init.sha256
│       ├── docker-proxy
│       ├── docker-proxy.md5
│       ├── docker-proxy.sha256
│       ├── docker-runc
│       ├── docker-runc.md5
│       ├── docker-runc.sha256
│       ├── dockerd -&amp;gt; dockerd-17.04.0-dev
│       ├── dockerd-17.04.0-dev
│       ├── dockerd-17.04.0-dev.md5
│       └── dockerd-17.04.0-dev.sha256
└── latest -&amp;gt; 17.04.0-dev

4 directories, 26 files
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在可以将docker-daemon和docker-client目录下的docker可以执行文件复制到容器的/usr/bin/目录下了。&lt;/p&gt;

&lt;p&gt;启动docker deamon&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;docker daemon -D&amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;检查下docker是否可用&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@f2753f78bb6d:/go/src/github.com/docker/docker/bundles/17.04.0-dev# docker version
DEBU[0048] Calling GET /_ping                           
DEBU[0048] Calling GET /v1.27/version                   
Client:
 Version:      17.04.0-dev
 API version:  1.27
 Go version:   go1.7.5
 Git commit:   3385658
 Built:        Mon Mar  6 08:39:06 2017
 OS/Arch:      linux/amd64

Server:
 Version:      17.04.0-dev
 API version:  1.27 (minimum version 1.12)
 Go version:   go1.7.5
 Git commit:   3385658
 Built:        Mon Mar  6 08:39:06 2017
 OS/Arch:      linux/amd64
 Experimental: false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到此docker源码编译和开发环境都已经搭建好了。&lt;/p&gt;

&lt;p&gt;如果想要修改docker源码，只要在你的IDE、容器里或者你本机上修改docker代码后，再执行上面的hack/make.sh binary命令就可以生成新的docker二进制文件，再替换原来的/usr/bin/目录下的docker二进制文件即可。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>《云计算技术架构与实践》读后感</title>
      <link>http://rootsongjc.github.io/blogs/cloud-computing-architecture-practice/</link>
      <pubDate>Wed, 01 Mar 2017 18:29:36 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/cloud-computing-architecture-practice/</guid>
      <description>&lt;p&gt;最近友人推荐了一本书，是华为的工程师写的《云计算架构与实践第二版》，正好在网上找到了这本书的pdf，分享给大家，&lt;a href=&#34;http://olz1di9xf.bkt.clouddn.com/docs/%E4%BA%91%E8%AE%A1%E7%AE%97%E6%9E%B6%E6%9E%84%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E8%B7%B5%E7%AC%AC2%E7%89%88.pdf&#34;&gt;点这里下载&lt;/a&gt;，书是文字版的，大小13.04MB，除了章节顺序有点问题外没有其他什么问题。&lt;/p&gt;

&lt;p&gt;后续我将会陆续分享这本书的读后感。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>12 factor app</title>
      <link>http://rootsongjc.github.io/blogs/12-factor-app/</link>
      <pubDate>Mon, 27 Feb 2017 22:32:40 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/12-factor-app/</guid>
      <description>

&lt;h1 id=&#34;twelve-factor-app&#34;&gt;Twelve-factor App&lt;/h1&gt;

&lt;h1 id=&#34;简介&#34;&gt;简介&lt;/h1&gt;

&lt;p&gt;如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建如下的 SaaS 应用提供了方法论：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;使用&lt;strong&gt;标准化&lt;/strong&gt;流程自动配置，从而使新的开发者花费最少的学习成本加入这个项目。&lt;/li&gt;
&lt;li&gt;和操作系统之间尽可能的&lt;strong&gt;划清界限&lt;/strong&gt;，在各个系统中提供&lt;strong&gt;最大的可移植性&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;适合&lt;strong&gt;部署&lt;/strong&gt;在现代的&lt;strong&gt;云计算平台&lt;/strong&gt;，从而在服务器和系统管理方面节省资源。&lt;/li&gt;
&lt;li&gt;将开发环境和生产环境的&lt;strong&gt;差异降至最低&lt;/strong&gt;，并使用&lt;strong&gt;持续交付&lt;/strong&gt;实施敏捷开发。&lt;/li&gt;
&lt;li&gt;可以在工具、架构和开发流程不发生明显变化的前提下实现&lt;strong&gt;扩展&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这套理论适用于任意语言和后端服务（数据库、消息队列、缓存等）开发的应用程序。&lt;/p&gt;

&lt;h1 id=&#34;背景&#34;&gt;背景&lt;/h1&gt;

&lt;p&gt;本文的贡献者者参与过数以百计的应用程序的开发和部署，并通过 &lt;a href=&#34;http://www.heroku.com/&#34;&gt;Heroku&lt;/a&gt; 平台间接见证了数十万应用程序的开发，运作以及扩展的过程。&lt;/p&gt;

&lt;p&gt;本文综合了我们关于 SaaS 应用几乎所有的经验和智慧，是开发此类应用的理想实践标准，并特别关注于应用程序如何保持良性成长，开发者之间如何进行有效的代码协作，以及如何 &lt;a href=&#34;http://blog.heroku.com/archives/2011/6/28/the_new_heroku_4_erosion_resistance_explicit_contracts/&#34;&gt;避免软件污染&lt;/a&gt; 。&lt;/p&gt;

&lt;p&gt;我们的初衷是分享在现代软件开发过程中发现的一些系统性问题，并加深对这些问题的认识。我们提供了讨论这些问题时所需的共享词汇，同时使用相关术语给出一套针对这些问题的广义解决方案。本文格式的灵感来自于 Martin Fowler 的书籍： *Patterns of Enterprise Application Architecture* ， *Refactoring* 。&lt;/p&gt;

&lt;h1 id=&#34;12-factors&#34;&gt;12-factors&lt;/h1&gt;

&lt;h2 id=&#34;i-基准代码-https-12factor-net-zh-cn-codebase&#34;&gt;&lt;a href=&#34;https://12factor.net/zh_cn/codebase&#34;&gt;I. 基准代码&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;一份基准代码-多份部署&#34;&gt;一份基准代码，多份部署&lt;/h3&gt;

&lt;h2 id=&#34;ii-依赖-https-12factor-net-zh-cn-dependencies&#34;&gt;&lt;a href=&#34;https://12factor.net/zh_cn/dependencies&#34;&gt;II. 依赖&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;显式声明依赖关系&#34;&gt;显式声明依赖关系&lt;/h3&gt;

&lt;h2 id=&#34;iii-配置-https-12factor-net-zh-cn-config&#34;&gt;&lt;a href=&#34;https://12factor.net/zh_cn/config&#34;&gt;III. 配置&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;在环境中存储配置&#34;&gt;在环境中存储配置&lt;/h3&gt;

&lt;h2 id=&#34;iv-后端服务-https-12factor-net-zh-cn-backing-services&#34;&gt;&lt;a href=&#34;https://12factor.net/zh_cn/backing-services&#34;&gt;IV. 后端服务&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;把后端服务当作附加资源&#34;&gt;把后端服务当作附加资源&lt;/h3&gt;

&lt;h2 id=&#34;v-构建-发布-运行-https-12factor-net-zh-cn-build-release-run&#34;&gt;&lt;a href=&#34;https://12factor.net/zh_cn/build-release-run&#34;&gt;V. 构建，发布，运行&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;严格分离构建和运行&#34;&gt;严格分离构建和运行&lt;/h3&gt;

&lt;h2 id=&#34;vi-进程-https-12factor-net-zh-cn-processes&#34;&gt;&lt;a href=&#34;https://12factor.net/zh_cn/processes&#34;&gt;VI. 进程&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;以一个或多个无状态进程运行应用&#34;&gt;以一个或多个无状态进程运行应用&lt;/h3&gt;

&lt;h2 id=&#34;vii-端口绑定-https-12factor-net-zh-cn-port-binding&#34;&gt;&lt;a href=&#34;https://12factor.net/zh_cn/port-binding&#34;&gt;VII. 端口绑定&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;通过端口绑定提供服务&#34;&gt;通过端口绑定提供服务&lt;/h3&gt;

&lt;h2 id=&#34;viii-并发-https-12factor-net-zh-cn-concurrency&#34;&gt;&lt;a href=&#34;https://12factor.net/zh_cn/concurrency&#34;&gt;VIII. 并发&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;通过进程模型进行扩展&#34;&gt;通过进程模型进行扩展&lt;/h3&gt;

&lt;h2 id=&#34;ix-易处理-https-12factor-net-zh-cn-disposability&#34;&gt;&lt;a href=&#34;https://12factor.net/zh_cn/disposability&#34;&gt;IX. 易处理&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;快速启动和优雅终止可最大化健壮性&#34;&gt;快速启动和优雅终止可最大化健壮性&lt;/h3&gt;

&lt;h2 id=&#34;x-开发环境与线上环境等价-https-12factor-net-zh-cn-dev-prod-parity&#34;&gt;&lt;a href=&#34;https://12factor.net/zh_cn/dev-prod-parity&#34;&gt;X. 开发环境与线上环境等价&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;尽可能的保持开发-预发布-线上环境相同&#34;&gt;尽可能的保持开发，预发布，线上环境相同&lt;/h3&gt;

&lt;h2 id=&#34;xi-日志-https-12factor-net-zh-cn-logs&#34;&gt;&lt;a href=&#34;https://12factor.net/zh_cn/logs&#34;&gt;XI. 日志&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;把日志当作事件流&#34;&gt;把日志当作事件流&lt;/h3&gt;

&lt;h2 id=&#34;xii-管理进程-https-12factor-net-zh-cn-admin-processes&#34;&gt;&lt;a href=&#34;https://12factor.net/zh_cn/admin-processes&#34;&gt;XII. 管理进程&lt;/a&gt;&lt;/h2&gt;

&lt;h3 id=&#34;后台管理任务当作一次性进程运行&#34;&gt;后台管理任务当作一次性进程运行&lt;/h3&gt;
</description>
    </item>
    
    <item>
      <title>docker service discovery</title>
      <link>http://rootsongjc.github.io/blogs/docker-service-discovery/</link>
      <pubDate>Mon, 27 Feb 2017 18:27:07 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/docker-service-discovery/</guid>
      <description>&lt;p&gt;Prior to Docker 1.12 release, setting up Swarm cluster needed some sort of &lt;a href=&#34;https://docs.docker.com/v1.11/swarm/discovery/&#34;&gt;service discovery backend&lt;/a&gt;. There are multiple discovery backends available like hosted discovery service, using a static file describing the cluster, etcd, consul, zookeeper or using static list of IP address.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://collabnix.com/wp-content/uploads/2016/07/pic-intro.png&#34;&gt;&lt;img src=&#34;http://collabnix.com/wp-content/uploads/2016/07/pic-intro.png&#34; alt=&#34;pic-intro&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Thanks to Docker 1.12 Swarm Mode&lt;/strong&gt;, we don’t have to depend upon these external tools and complex configurations. &lt;a href=&#34;https://github.com/docker/docker/releases/tag/v1.12.0-rc5&#34;&gt;Docker Engine 1.12&lt;/a&gt; runs it’s own internal DNS service to route services by name.Swarm manager nodes assign each service in the swarm a unique DNS name and load balances running containers. You can query every container running in the swarm through a DNS server embedded in the swarm.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How does it help?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;When you create a service and provide a name for it, you can use just that name as a target hostname, and it’s going to be automatically resolved to the proper container IP of the service. In short, within the swarm, containers can simply reference other services via their names and the built-in DNS will be used to find the appropriate IP and port automatically. It is important to note that if the service has multiple replicas, &lt;strong&gt;the requests would be round-robin load-balanced&lt;/strong&gt;. This would still work if you didn’t forward any ports when you created your docker services.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://collabnix.com/wp-content/uploads/2016/07/Pic10.png&#34;&gt;&lt;img src=&#34;http://collabnix.com/wp-content/uploads/2016/07/Pic10.png&#34; alt=&#34;Pic10&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Embedded DNS is not a new concept. It was first included under Docker 1.10 release. Please note that DNS lookup for containers connected to user-defined networks works differently compared to the containers connected to &lt;code&gt;default bridge&lt;/code&gt; network. As of Docker 1.10, the docker daemon implements an embedded DNS server which provides built-in service discovery for any container created with a valid &lt;code&gt;name&lt;/code&gt; or &lt;code&gt;net-alias&lt;/code&gt; or aliased by &lt;code&gt;link&lt;/code&gt;. Moreover,container name configured using &lt;code&gt;--name&lt;/code&gt; is used to discover a container within an user-defined docker network. The embedded DNS server maintains the mapping between the container name and its IP address (on the network the container is connected to).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How does Embedded DNS resolve unqualified names?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://collabnix.com/wp-content/uploads/2016/07/Pic22.png&#34;&gt;&lt;img src=&#34;http://collabnix.com/wp-content/uploads/2016/07/Pic22.png&#34; alt=&#34;Pic22&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;With Docker 1.12 release, a new API called “service” is being included which clearly talks about the functionality of service discovery.  It is important to note that Service discovery is scoped within the network. What it really means is –  If you have redis application and web client as two separate services , you combine into single application and put them into same network.If you try build your application in such a way that you are trying to reach to redis through name “redis”,it will always resolve to name “redis”. Reason – both of these services are part of the same network. You don’t need to be inside the application trying to resolve this service using FQDN. Reason – FQDN name is not going to be portable which in turn, makes your application non-portable.&lt;/p&gt;

&lt;p&gt;Internally, there is a listener opened inside the container itself. If we try to enter into the container which is providing a service discovery and look at /etc/resolv.conf, we will find that the nameserver entry holds something really different like 127.0.0.11.This is nothing but a loopback address. So, whenever resolver tried to resolve, it will resolve to 127.0.0.11 and this request is rightly trapped.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://collabnix.com/wp-content/uploads/2016/07/Pic-12.png&#34;&gt;&lt;img src=&#34;http://collabnix.com/wp-content/uploads/2016/07/Pic-12.png&#34; alt=&#34;Pic-12&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Once this request is trapped, it is sent to particular random UDP / TCP port currently being listened under the docker daemon. Consequently, the socket is to be created inside the namespace. When DNS server and daemon gets the request, it knows that this is coming from which specific network, hence gets aware of  the context of from where it is coming from.Once it knows the context, it can generate the appropriate DNS response.&lt;/p&gt;

&lt;p&gt;To demonstrate Service Discovery  under Docker 1.12, I have upgraded Docker 1.12.rc5 to 1.12.0 GA version. The swarm cluster look like:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://collabnix.com/wp-content/uploads/2016/07/Pico01.png&#34;&gt;&lt;img src=&#34;http://collabnix.com/wp-content/uploads/2016/07/Pico01.png&#34; alt=&#34;Pico01&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I have created a network called “collabnet” for the new services as shown below:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://collabnix.com/wp-content/uploads/2016/07/Pic-2.jpg&#34;&gt;&lt;img src=&#34;http://collabnix.com/wp-content/uploads/2016/07/Pic-2.jpg&#34; alt=&#34;Pic-2&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Let’s create a service called “wordpressdb” under collabnet network :&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://collabnix.com/wp-content/uploads/2016/07/pico-mysql.png&#34;&gt;&lt;img src=&#34;http://collabnix.com/wp-content/uploads/2016/07/pico-mysql.png&#34; alt=&#34;pico-mysql&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You can list the running tasks(containers) and the node on which these containers are running on:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://collabnix.com/wp-content/uploads/2016/07/Pic-4.png&#34;&gt;&lt;img src=&#34;http://collabnix.com/wp-content/uploads/2016/07/Pic-4.png&#34; alt=&#34;Pic-4&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Let’s create another service called “wordpressapp” under the same network:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://collabnix.com/wp-content/uploads/2016/07/pico-app.png&#34;&gt;&lt;img src=&#34;http://collabnix.com/wp-content/uploads/2016/07/pico-app.png&#34; alt=&#34;pico-app&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Now, we can list out the number of services running on our swarm cluster as shown below.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://collabnix.com/wp-content/uploads/2016/07/pico-2.png&#34;&gt;&lt;img src=&#34;http://collabnix.com/wp-content/uploads/2016/07/pico-2.png&#34; alt=&#34;pico-2&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I have scaled out the number of wordpressapp and wordpressdb just for demonstration purpose.&lt;/p&gt;

&lt;p&gt;Let’s consider my master node where I have two of the containers running as shown below:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://collabnix.com/wp-content/uploads/2016/07/Pico-1.png&#34;&gt;&lt;img src=&#34;http://collabnix.com/wp-content/uploads/2016/07/Pico-1.png&#34; alt=&#34;Pico-1&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I can reach out one service(wordpressapp) from another service(wordpressapp) through just service-name as shown below:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://collabnix.com/wp-content/uploads/2016/07/pico-last.png&#34;&gt;&lt;img src=&#34;http://collabnix.com/wp-content/uploads/2016/07/pico-last.png&#34; alt=&#34;pico-last&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Also, I can reach out to particular container by its name from other container running different service but on the same network. As shown below, I can reach out to wordpressapp.3.6f8bthp container via wordpressdb.7.e62jl57qqu running wordpressdb.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://collabnix.com/wp-content/uploads/2016/07/pico-tasktoo.png&#34;&gt;&lt;img src=&#34;http://collabnix.com/wp-content/uploads/2016/07/pico-tasktoo.png&#34; alt=&#34;pico-tasktoo&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The below picture depicts the Service Discovery in a nutshell:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;img src=&#34;http://collabnix.com/wp-content/uploads/2016/07/Pic23.png&#34; alt=&#34;Pic23&#34; /&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Every service has Virtual IP(VIP) associated which can be derived as shown below:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://collabnix.com/wp-content/uploads/2016/07/pic-list.png&#34;&gt;&lt;img src=&#34;http://collabnix.com/wp-content/uploads/2016/07/pic-list.png&#34; alt=&#34;pic-list&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As shown above, each service has an IP address and this IP address maps to multiple container IP address associated with that service. It is important to note that service IP associated with a service does not change even though containers associated with the service dies/ restarts.&lt;/p&gt;

&lt;p&gt;Few important points to remember:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;VIP based services use Linux IPVS load balancing to route to the backend containers. This works only for TCP/UDP protocols. When you use DNS-RR mode services don’t have a VIP allocated. Instead service names resolves to one of the backend container IPs randomly.&lt;/li&gt;
&lt;li&gt;Ping not working for VIP is as designed. Technically, IPVS is a TCP/UDP load-balancer, while ping uses ICMP and hence IPVS is not going to load-balance the ping request.&lt;/li&gt;
&lt;li&gt;For VIP based services the reason ping works on the local node is because the VIP is added a 2nd IP address on the overlay network interface&lt;/li&gt;
&lt;li&gt;You can any of the tools like  dig, nslookup or wget -O- &lt;service name&gt; to demonstrate the service discovery functionality&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Below picture depicts that the network is the scope of service discoverability which means that when you have a service running on one network , it is scoped to that network and won’t be able to reach out to different service running on different network(unless it is part of that network).&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://collabnix.com/wp-content/uploads/2016/07/SD.png&#34;&gt;&lt;img src=&#34;http://collabnix.com/wp-content/uploads/2016/07/SD.png&#34; alt=&#34;SD&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Let’s dig little further introducing Load-balancing aspect too. To see what is basically enabling the load-balancing functionality, we can go into sandbox of each containers and see how it has been resolved.&lt;/p&gt;

&lt;p&gt;Let’s pick up the two containers running on the master node. We can see the sandbox running through the following command:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://collabnix.com/wp-content/uploads/2016/07/pico-namespace.png&#34;&gt;&lt;img src=&#34;http://collabnix.com/wp-content/uploads/2016/07/pico-namespace.png&#34; alt=&#34;pico-namespace&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Under /var/run/docker/netns, you will find various namespaces. The namespaces marked with x-{id} represents network namespace managed by the overlay network driver for its operation (such as creating a bridge, terminating vxlan tunnel, etc…). They don’t represent the container network namespace. Since it is managed by the driver, it is not recommended to manipulate anything within this namespace. But if you are curious on the deep dive, then you can use the “nsenter” tool to understand more about this internal namespace.&lt;/p&gt;

&lt;p&gt;We can enter into sandbox through the nsenter utility:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://collabnix.com/wp-content/uploads/2016/07/pico-mangle.png&#34;&gt;&lt;img src=&#34;http://collabnix.com/wp-content/uploads/2016/07/pico-mangle.png&#34; alt=&#34;pico-mangle&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In case you faced an error stating “nsenter: reassociate to namespace ‘ns/net’ failed: Invalid argument”, I suggest to look at &lt;a href=&#34;http://tinyurl.com/gu5rsw9&#34;&gt;this&lt;/a&gt; workaround.&lt;/p&gt;

&lt;p&gt;10.0.3.4 service IP is marked 0x108 using iptables OUTPUT chain. ipvs uses this marking and load balances it to containers 10.0.3.5 and 10.0.3.6 as shown below:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://collabnix.com/wp-content/uploads/2016/07/ipvs.png&#34;&gt;&lt;img src=&#34;http://collabnix.com/wp-content/uploads/2016/07/ipvs.png&#34; alt=&#34;ipvs&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here are key takeaways from this entire post:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://collabnix.com/wp-content/uploads/2016/07/Pic34.png&#34;&gt;&lt;img src=&#34;http://collabnix.com/wp-content/uploads/2016/07/Pic34.png&#34; alt=&#34;Pic34&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;From &lt;a href=&#34;http://collabnix.com/archives/1504&#34;&gt;http://collabnix.com/archives/1504&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>