<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on Jimmy&#39;s blog</title>
    <link>http://rootsongjc.github.io/blogs/index.xml</link>
    <description>Recent content in Blogs on Jimmy&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 30 Mar 2017 20:44:20 +0800</lastBuildDate>
    <atom:link href="http://rootsongjc.github.io/blogs/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>在CentOS上安装kubernetes详细指南</title>
      <link>http://rootsongjc.github.io/blogs/kubernetes-installation-on-centos/</link>
      <pubDate>Thu, 30 Mar 2017 20:44:20 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/kubernetes-installation-on-centos/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/2014082501.jpg&#34; alt=&#34;圆明园&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：北京圆明园 Aug 25,2014）&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;作者：&lt;a href=&#34;rootsongjc.github.io/about&#34;&gt;Jimmy Song&lt;/a&gt;，&lt;a href=&#34;https://godliness.github.io/&#34;&gt;Peter Ma&lt;/a&gt;，2017年3月30日&lt;/p&gt;

&lt;p&gt;最近决定从Docker Swarm Mode投入到Kubernetes的怀抱，对Docker的战略和企业化发展前景比较堪忧，而Kubernetes是&lt;a href=&#34;https://www.cncf.io/&#34;&gt;CNCF&lt;/a&gt;的成员之一。&lt;/p&gt;

&lt;p&gt;这篇是根据&lt;a href=&#34;https://kubernetes.io/docs/getting-started-guides/centos/centos_manual_config/#prerequisites&#34;&gt;官方安装文档&lt;/a&gt;实践整理的，操作系统是纯净的CentOS7.2。&lt;/p&gt;

&lt;p&gt;另外还有一个Peter Ma写的&lt;a href=&#34;https://godliness.github.io/2017/03/29/%E5%9C%A8CentOS7%E4%B8%8A%E6%89%8B%E5%8A%A8%E5%AE%89%E8%A3%85Kubernetes/&#34;&gt;在CentOS上手动安装kubernetes的文档&lt;/a&gt;可以参考。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;角色分配&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;下面以在三台主机上安装Kubernetes为例。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;172.20.0.113 master/node kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy etcd flannel
172.20.0.114 node kubectl kube-proxy flannel
172.20.0.115 node kubectl kube-proxy flannel
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第一台主机既作为master也作为node。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;系统环境&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Centos 7.2.1511&lt;/li&gt;
&lt;li&gt;docker 1.11.2&lt;/li&gt;
&lt;li&gt;etcd 3.1.5&lt;/li&gt;
&lt;li&gt;kubernetes 1.6.0&lt;/li&gt;
&lt;li&gt;flannel 0.7.0-1&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;安装&#34;&gt;安装&lt;/h1&gt;

&lt;p&gt;下面给出两种安装方式：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;配置yum源后，使用yum安装，好处是简单，坏处也很明显，需要google更新yum源才能获得最新版本的软件，而所有软件的依赖又不能自己指定，尤其是你的操作系统版本如果低的话，使用yum源安装的kubernetes的版本也会受到限制。&lt;/li&gt;
&lt;li&gt;使用二进制文件安装，好处是可以安装任意版本的kubernetes，坏处是配置比较复杂。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们最终选择使用第二种方式安装。&lt;/p&gt;

&lt;h2 id=&#34;第一种方式-centos系统中直接使用yum安装&#34;&gt;第一种方式：CentOS系统中直接使用yum安装&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;给yum源增加一个Repo&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[virt7-docker-common-release]
name=virt7-docker-common-release
baseurl=http://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/
gpgcheck=0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;安装docker、kubernetes、etcd、flannel一步到位&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum -y install --enablerepo=virt7-docker-common-release kubernetes etcd flannel
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;安装好了之后需要修改一系列配置文件。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;如果你使用的是CentOS7.2的话，会自动下载安装Kubernetes1.5（Till March 30,2017），如果使用的是CentOS7.2的化，会自动下载安装Kubernentes1.1。我们现在要安装目前的最新版本Kubernetes1.6，而使用的又是CentOS7.2，所以我们不使用yum安装。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;第二种方式-使用二进制文件安装&#34;&gt;第二种方式：使用二进制文件安装&lt;/h2&gt;

&lt;p&gt;这种方式安装的话，需要自己一个一个组件的安装。&lt;/p&gt;

&lt;h3 id=&#34;安装docker&#34;&gt;安装Docker&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;下载安装包&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://yum.dockerproject.org/repo/main/centos/7/Packages/docker-engine-${DOCKER_VERSION}-1.el7.centos.x86_64.rpm&#34;&gt;https://yum.dockerproject.org/repo/main/centos/7/Packages/docker-engine-${DOCKER_VERSION}-1.el7.centos.x86_64.rpm&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://yum.dockerproject.org/repo/main/centos/7/Packages/docker-engine-selinux-${DOCKER_VERSION}-1.el7.centos.noarch.rpm&#34;&gt;https://yum.dockerproject.org/repo/main/centos/7/Packages/docker-engine-selinux-${DOCKER_VERSION}-1.el7.centos.noarch.rpm&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;安装&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;yum localinstall ./docker-engine*&lt;/p&gt;

&lt;h3 id=&#34;安装etcd&#34;&gt;安装etcd&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;下载二进制文件&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;DOWNLOAD_URL=https://storage.googleapis.com/etcd  #etcd存储地址
ETCD_VER=v3.1.5  #设置etcd版本号
wget ${DOWNLOAD_URL}/${ETCD_VER}/etcd-${ETCD_VER}-linux-amd64.tar.gz
tar xvf etcd-${ETCD_VER}-linux-amd64.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;部署文件&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;将如下内容写入文件 /etc/etcd/etcd.conf 中：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;# [member]
ETCD_NAME=default
ETCD_DATA_DIR=&amp;quot;/var/lib/etcd/default.etcd&amp;quot;
# ETCD_WAL_DIR=&amp;quot;&amp;quot;
# ETCD_SNAPSHOT_COUNT=&amp;quot;10000&amp;quot;
# ETCD_HEARTBEAT_INTERVAL=&amp;quot;100&amp;quot;
# ETCD_ELECTION_TIMEOUT=&amp;quot;1000&amp;quot;
# ETCD_LISTEN_PEER_URLS=&amp;quot;http://localhost:2380&amp;quot;
ETCD_LISTEN_CLIENT_URLS=&amp;quot;http://0.0.0.0:2379&amp;quot;
# ETCD_MAX_SNAPSHOTS=&amp;quot;5&amp;quot;
# ETCD_MAX_WALS=&amp;quot;5&amp;quot;
# ETCD_CORS=&amp;quot;&amp;quot;
#
# [cluster]
# ETCD_INITIAL_ADVERTISE_PEER_URLS=&amp;quot;http://localhost:2380&amp;quot;
# if you use different ETCD_NAME (e.g. test), set ETCD_INITIAL_CLUSTER value for this name, i.e. &amp;quot;test=http://...&amp;quot;
# ETCD_INITIAL_CLUSTER=&amp;quot;default=http://localhost:2380&amp;quot;
# ETCD_INITIAL_CLUSTER_STATE=&amp;quot;new&amp;quot;
# ETCD_INITIAL_CLUSTER_TOKEN=&amp;quot;etcd-cluster&amp;quot;
ETCD_ADVERTISE_CLIENT_URLS=&amp;quot;http://0.0.0.0:2379&amp;quot;
# ETCD_DISCOVERY=&amp;quot;&amp;quot;
# ETCD_DISCOVERY_SRV=&amp;quot;&amp;quot;
# ETCD_DISCOVERY_FALLBACK=&amp;quot;proxy&amp;quot;
# ETCD_DISCOVERY_PROXY=&amp;quot;&amp;quot;
#
# [proxy]
# ETCD_PROXY=&amp;quot;off&amp;quot;
# ETCD_PROXY_FAILURE_WAIT=&amp;quot;5000&amp;quot;
# ETCD_PROXY_REFRESH_INTERVAL=&amp;quot;30000&amp;quot;
# ETCD_PROXY_DIAL_TIMEOUT=&amp;quot;1000&amp;quot;
# ETCD_PROXY_WRITE_TIMEOUT=&amp;quot;5000&amp;quot;
# ETCD_PROXY_READ_TIMEOUT=&amp;quot;0&amp;quot;
#
# [security]
# ETCD_CERT_FILE=&amp;quot;&amp;quot;
# ETCD_KEY_FILE=&amp;quot;&amp;quot;
# ETCD_CLIENT_CERT_AUTH=&amp;quot;false&amp;quot;
# ETCD_TRUSTED_CA_FILE=&amp;quot;&amp;quot;
# ETCD_PEER_CERT_FILE=&amp;quot;&amp;quot;
# ETCD_PEER_KEY_FILE=&amp;quot;&amp;quot;
# ETCD_PEER_CLIENT_CERT_AUTH=&amp;quot;false&amp;quot;
# ETCD_PEER_TRUSTED_CA_FILE=&amp;quot;&amp;quot;
# [logging]
# ETCD_DEBUG=&amp;quot;false&amp;quot;
# examples for -log-package-levels etcdserver=WARNING,security=DEBUG
# ETCD_LOG_PACKAGE_LEVELS=&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;将 etcd, etcdctl放入 /usr/bin/下，并将如下内容写进/usr/lib/systemd/system/etcd.service文件&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Ini&#34;&gt;[Unit]
Description=Etcd Server
After=network.target
After=network-online.target
Wants=network-online.target

[Service]
Type=notify
WorkingDirectory=/var/lib/etcd/
EnvironmentFile=-/etc/etcd/etcd.conf
User=etcd
# set GOMAXPROCS to number of processors
ExecStart=/bin/bash -c &amp;quot;GOMAXPROCS=$(nproc) /usr/bin/etcd --name=\&amp;quot;${ETCD_NAME}\&amp;quot; --data-dir=\&amp;quot;${ETCD_DATA_DIR}\&amp;quot; --listen-client-urls=\&amp;quot;${ETCD_LISTEN_CLIENT_URLS}\&amp;quot;&amp;quot;
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;启动并校验&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;systemctl start etcd
systemctl enable etcd
systemctl status etcd
etcdctl ls
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;集群&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;若要部署多节点集群也比较简单，只要更改etcd.conf文件以及etcd.service添加相应配置即可&lt;/p&gt;

&lt;p&gt;可以参考链接：&lt;a href=&#34;https://github.com/coreos/etcd/blob/master/Documentation/op-guide/clustering.md&#34;&gt;https://github.com/coreos/etcd/blob/master/Documentation/op-guide/clustering.md&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;安装flannel&#34;&gt;安装flannel&lt;/h3&gt;

&lt;p&gt;可以直接使用&lt;code&gt;yum install flannel&lt;/code&gt;安装。&lt;/p&gt;

&lt;h3 id=&#34;安装kubernetes&#34;&gt;安装Kubernetes&lt;/h3&gt;

&lt;p&gt;根据《Kubernetes权威指南（第二版）》中的介绍，直接使用GitHub上的release里的二进制文件安装。&lt;/p&gt;

&lt;p&gt;执行下面的命令安装。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;wget https://github.com/kubernetes/kubernetes/releases/download/v1.6.0/kubernetes.tar.gz
tar kubernetes.tar.gz
cd kubernetes
./cluster/get-kube-binaries.sh
cd server
tar xvf kubernetes-server-linux-amd64.tar.gz
rm -f *_tag *.tar
chmod 755 *
mv * /usr/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实际下载kubernetes-server-linux-amd64.tar.gz from &lt;a href=&#34;https://storage.googleapis.com/kubernetes-release/release/v1.6.0&#34;&gt;https://storage.googleapis.com/kubernetes-release/release/v1.6.0&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;解压完后获得的二进制文件有：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cloud-controller-manager
hyperkube
kubeadm
kube-aggregator
kube-apiserver
kube-controller-manager
kubectl
kubefed
kubelet
kube-proxy
kube-scheduler
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在&lt;code&gt;cluster/juju/layers/kubernetes-master/templates&lt;/code&gt;目录下有service和环境变量配置文件的模板，这个模板本来是为了使用&lt;a href=&#34;https://jujucharms.com/&#34;&gt;juju&lt;/a&gt;安装写的。&lt;/p&gt;

&lt;h4 id=&#34;master节点的配置&#34;&gt;Master节点的配置&lt;/h4&gt;

&lt;p&gt;Master节点需要配置的kubernetes的组件有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;kube-apiserver&lt;/li&gt;
&lt;li&gt;kube-controller-manager&lt;/li&gt;
&lt;li&gt;kube-scheduler&lt;/li&gt;
&lt;li&gt;kube-proxy&lt;/li&gt;
&lt;li&gt;kubectl&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;配置kube-apiserver&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;编写&lt;code&gt;/usr/lib/systemd/system/kube-apiserver.service&lt;/code&gt;文件。&lt;a href=&#34;http://blog.csdn.net/yuesichiu/article/details/51485147&#34;&gt;CentOS中的service配置文件参考&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;[Unit]
Description=Kubernetes API Service
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=network.target
After=etcd.service

[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/apiserver
ExecStart=/usr/bin/kube-apiserver \
	    $KUBE_LOGTOSTDERR \
	    $KUBE_LOG_LEVEL \
	    $KUBE_ETCD_SERVERS \
	    $KUBE_API_ADDRESS \
	    $KUBE_API_PORT \
	    $KUBELET_PORT \
	    $KUBE_ALLOW_PRIV \
	    $KUBE_SERVICE_ADDRESSES \
	    $KUBE_ADMISSION_CONTROL \
	    $KUBE_API_ARGS
Restart=on-failure
Type=notify
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;创建kubernetes的配置文件目录&lt;code&gt;/etc/kubernetes&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;添加&lt;code&gt;config&lt;/code&gt;配置文件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;###
# kubernetes system config
#
# The following values are used to configure various aspects of all
# kubernetes services, including
#
#   kube-apiserver.service
#   kube-controller-manager.service
#   kube-scheduler.service
#   kubelet.service
#   kube-proxy.service
# logging to stderr means we get it in the systemd journal
KUBE_LOGTOSTDERR=&amp;quot;--logtostderr=true&amp;quot;

# journal message level, 0 is debug
KUBE_LOG_LEVEL=&amp;quot;--v=0&amp;quot;

# Should this cluster be allowed to run privileged docker containers
KUBE_ALLOW_PRIV=&amp;quot;--allow-privileged=false&amp;quot;

# How the controller-manager, scheduler, and proxy find the apiserver
KUBE_MASTER=&amp;quot;--master=http://sz-pg-oam-docker-test-001.tendcloud.com:8080&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;添加&lt;code&gt;apiserver&lt;/code&gt;配置文件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;###
## kubernetes system config
##
## The following values are used to configure the kube-apiserver
##
#
## The address on the local server to listen to.
KUBE_API_ADDRESS=&amp;quot;--address=sz-pg-oam-docker-test-001.tendcloud.com&amp;quot;
#
## The port on the local server to listen on.
KUBE_API_PORT=&amp;quot;--port=8080&amp;quot;
#
## Port minions listen on
KUBELET_PORT=&amp;quot;--kubelet-port=10250&amp;quot;
#
## Comma separated list of nodes in the etcd cluster
KUBE_ETCD_SERVERS=&amp;quot;--etcd-servers=http://127.0.0.1:2379&amp;quot;
#
## Address range to use for services
KUBE_SERVICE_ADDRESSES=&amp;quot;--service-cluster-ip-range=10.254.0.0/16&amp;quot;
#
## default admission control policies
KUBE_ADMISSION_CONTROL=&amp;quot;--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ResourceQuota&amp;quot;
#
## Add your own!
#KUBE_API_ARGS=&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;配置kube-controller-manager&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;编写&lt;code&gt;/usr/lib/systemd/system/kube-controller.service&lt;/code&gt;文件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Ini&#34;&gt;Description=Kubernetes Controller Manager
Documentation=https://github.com/GoogleCloudPlatform/kubernetes

[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/controller-manager
User=kube
ExecStart=/usr/bin/kube-controller-manager \
	    $KUBE_LOGTOSTDERR \
	    $KUBE_LOG_LEVEL \
	    $KUBE_MASTER \
	    $KUBE_CONTROLLER_MANAGER_ARGS
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在&lt;code&gt;/etc/kubernetes&lt;/code&gt;目录下添加&lt;code&gt;controller-manager&lt;/code&gt;配置文件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;###
# The following values are used to configure the kubernetes controller-manager

# defaults from config and apiserver should be adequate

# Add your own!
KUBE_CONTROLLER_MANAGER_ARGS=&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;配置kube-scheduler&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;编写&lt;code&gt;/usr/lib/systemd/system/kube-scheduler.service&lt;/code&gt;文件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;[Unit]
Description=Kubernetes Scheduler Plugin
Documentation=https://github.com/GoogleCloudPlatform/kubernetes

[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/scheduler
User=kube
ExecStart=/usr/bin/kube-scheduler \
	    $KUBE_LOGTOSTDERR \
	    $KUBE_LOG_LEVEL \
	    $KUBE_MASTER \
	    $KUBE_SCHEDULER_ARGS
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在&lt;code&gt;/etc/kubernetes&lt;/code&gt;目录下添加&lt;code&gt;scheduler&lt;/code&gt;文件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;###
# kubernetes scheduler config

# default config should be adequate

# Add your own!
KUBE_SCHEDULER_ARGS=&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;配置kube-proxy&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;编写&lt;code&gt;/usr/lib/systemd/system/kube-proxy.service&lt;/code&gt;文件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;[Unit]
Description=Kubernetes Kube-Proxy Server
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=network.target

[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/proxy
ExecStart=/usr/bin/kube-proxy \
	    $KUBE_LOGTOSTDERR \
	    $KUBE_LOG_LEVEL \
	    $KUBE_MASTER \
	    $KUBE_PROXY_ARGS
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在&lt;code&gt;/etc/kubernetes&lt;/code&gt;目录下添加&lt;code&gt;proxy&lt;/code&gt;配置文件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;###
# kubernetes proxy config

# default config should be adequate

# Add your own!
KUBE_PROXY_ARGS=&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;配置kubelet&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;编写&lt;code&gt;/usr/lib/systemd/system/kubelet.service&lt;/code&gt;文件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;[Unit]
Description=Kubernetes Kubelet Server
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=docker.service
Requires=docker.service

[Service]
WorkingDirectory=/var/lib/kubelet
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/kubelet
ExecStart=/usr/bin/kubelet \
	    $KUBE_LOGTOSTDERR \
	    $KUBE_LOG_LEVEL \
	    $KUBELET_API_SERVER \
	    $KUBELET_ADDRESS \
	    $KUBELET_PORT \
	    $KUBELET_HOSTNAME \
	    $KUBE_ALLOW_PRIV \
	    $KUBELET_POD_INFRA_CONTAINER \
	    $KUBELET_ARGS
Restart=on-failure

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在&lt;code&gt;/etc/kubernetes&lt;/code&gt;目录下添加&lt;code&gt;kubelet&lt;/code&gt;配置文件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;###
## kubernetes kubelet (minion) config
#
## The address for the info server to serve on (set to 0.0.0.0 or &amp;quot;&amp;quot; for all interfaces)
KUBELET_ADDRESS=&amp;quot;--address=0.0.0.0&amp;quot;
#
## The port for the info server to serve on
KUBELET_PORT=&amp;quot;--port=10250&amp;quot;
#
## You may leave this blank to use the actual hostname
KUBELET_HOSTNAME=&amp;quot;--hostname-override=sz-pg-oam-docker-test-001.tendcloud.com&amp;quot;
#
## location of the api-server
KUBELET_API_SERVER=&amp;quot;--api-servers=http://sz-pg-oam-docker-test-001.tendcloud.com:8080&amp;quot;
#
## pod infrastructure container
KUBELET_POD_INFRA_CONTAINER=&amp;quot;--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest&amp;quot;
#
## Add your own!
KUBELET_ARGS=&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;node节点配置&#34;&gt;Node节点配置&lt;/h4&gt;

&lt;p&gt;Node节点需要配置：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;kube-proxy&lt;/li&gt;
&lt;li&gt;kubectl&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;kube-proxy&lt;/code&gt;的配置与master节点的kube-proxy配置相同。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl&lt;/code&gt;的配置需要修改&lt;code&gt;KUBELET_HOST&lt;/code&gt;为本机的hostname，其它配置相同。&lt;/p&gt;

&lt;h1 id=&#34;启动&#34;&gt;启动&lt;/h1&gt;

&lt;p&gt;在&lt;strong&gt;Master&lt;/strong&gt;节点上执行：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;for SERVICES in etcd kube-apiserver kube-controller-manager kube-scheduler kube-proxy kubelet flanneld; do
    systemctl restart $SERVICES
    systemctl enable $SERVICES
    systemctl status $SERVICES
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在Node节点上执行：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;for SERVICES in kube-proxy kubelet flanneld; do
    systemctl restart $SERVICES
    systemctl enable $SERVICES
    systemctl status $SERVICES
done
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;验证&#34;&gt;验证&lt;/h1&gt;

&lt;p&gt;在Master节点上运行&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$kubectl get all
NAME             CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
svc/kubernetes   10.254.0.1   &amp;lt;none&amp;gt;        443/TCP   1h
$kubectl get nodes
NAME                                      STATUS    AGE       VERSION
sz-pg-oam-docker-test-001.tendcloud.com   Ready     7m        v1.6.0
sz-pg-oam-docker-test-002.tendcloud.com   Ready     4m        v1.6.0
sz-pg-oam-docker-test-003.tendcloud.com   Ready     10s       v1.6.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在可以正常使用啦。&lt;/p&gt;

&lt;h3 id=&#34;后记&#34;&gt;后记&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;时隔一年重新捡起kubernetes，正好现在KubeCon正在德国柏林举行，IDC 发布的报告显示，2017年大数据全球市场规模将达324亿美元，年复合增长率为27%，其中市场增长最快的领域是数据存储领域（53.4%）&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pivotal Cloud foundry快速开始指南</title>
      <link>http://rootsongjc.github.io/blogs/cloud-foundry-tryout/</link>
      <pubDate>Thu, 23 Mar 2017 22:54:18 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/cloud-foundry-tryout/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/2013100302.jpg&#34; alt=&#34;黄山日出&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：黄山日出后的云海 Oct 3,2013）&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;最近研究了下&lt;strong&gt;Pivotal&lt;/strong&gt;的&lt;strong&gt;Cloud foundry&lt;/strong&gt;，CF本身是一款开源软件，很多PAAS厂商都加入了CF，我们用的是的&lt;strong&gt;PCF Dev&lt;/strong&gt;（PCF Dev是一款可以在工作站上运行的轻量级PCF安装）来试用的，因为它可以部署在自己的环境里，而&lt;strong&gt;Pivotal Web Services&lt;/strong&gt;只免费两个月，之后就要收费。&lt;a href=&#34;https://pivotal.io/cn/platform/pcf-tutorials/getting-started-with-pivotal-cloud-foundry-dev/introduction&#34;&gt;这里&lt;/a&gt;有官方的详细教程。&lt;/p&gt;

&lt;h2 id=&#34;开始&#34;&gt;开始&lt;/h2&gt;

&lt;p&gt;根据官网的示例，我们将运行一个Java程序示例。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;安装命令行终端&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://pivotal.io/cn/platform/pcf-tutorials/getting-started-with-pivotal-cloud-foundry-dev/install-the-cf-cli&#34;&gt;下载&lt;/a&gt;后双击安装即可，然后执行&lt;code&gt;cf help&lt;/code&gt;能够看到帮助。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;安装PCF Dev&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;先&lt;a href=&#34;https://network.pivotal.io/products/pcfdev&#34;&gt;下载&lt;/a&gt;，如果你没有Pivotal network账号的话，还需要注册个用户，然后用以下命令安装：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;
$./pcfdev-VERSION-osx &amp;amp;&amp;amp; \
cf dev start
Less than 4096 MB of free memory detected, continue (y/N): &amp;gt; y
Please sign in with your Pivotal Network account.
Need an account? Join Pivotal Network: https://network.pivotal.io

Email&amp;gt; 849122844@qq.com

Password&amp;gt; 
Downloading VM...
Progress: |+++++++++++++=======&amp;gt;| 100% 
VM downloaded.
Allocating 4096 MB out of 16384 MB total system memory (3514 MB free).
Importing VM...
Starting VM...
Provisioning VM...
Waiting for services to start...
8 out of 57 running
8 out of 57 running
8 out of 57 running
46 out of 57 running
57 out of 57 running
 _______  _______  _______    ______   _______  __   __
|       ||       ||       |  |      | |       ||  | |  |
|    _  ||       ||    ___|  |  _    ||    ___||  |_|  |
|   |_| ||       ||   |___   | | |   ||   |___ |       |
|    ___||      _||    ___|  | |_|   ||    ___||       |
|   |    |     |_ |   |      |       ||   |___  |     |
|___|    |_______||___|      |______| |_______|  |___|
is now running.
To begin using PCF Dev, please run:
   cf login -a https://api.local.pcfdev.io --skip-ssl-validation
Apps Manager URL: https://local.pcfdev.io
Admin user =&amp;gt; Email: admin / Password: admin
Regular user =&amp;gt; Email: user / Password: pass
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;启动过程中还需要&lt;strong&gt;Sign In&lt;/strong&gt;，所以注册完后要记住用户名（邮箱地址）和密码（必须超过8位要有特殊字符和大写字母）。这个过程中还要下载VM，对内存要求至少4G。而且下载速度比较慢，我下载的了大概3个多小时吧。&lt;/p&gt;

&lt;p&gt;下面部署一个应用到PCF Dev上试一试。&lt;/p&gt;

&lt;h2 id=&#34;部署应用&#34;&gt;部署应用&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;下载代码&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$git clone https://github.com/cloudfoundry-samples/spring-music
$cd ./spring-music
$cf login -a api.local.pcfdev.io --skip-ssl-validation
API endpoint: api.local.pcfdev.io

Email&amp;gt; user

Password&amp;gt; pass
Authenticating...
OK

Targeted org pcfdev-org

Targeted space pcfdev-space


                
API endpoint:   https://api.local.pcfdev.io (API version: 2.65.0)
User:           user
Org:            pcfdev-org
Space:          pcfdev-space
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;编译应用&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;使用gradle来编译。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$./gradlew assemble
:compileJava UP-TO-DATE
:processResources UP-TO-DATE
:classes UP-TO-DATE
:findMainClass
:jar
:bootRepackage
Download https://repo1.maven.org/maven2/com/sun/jersey/jersey-client/1.13/jersey-client-1.13.jar
Download https://repo1.maven.org/maven2/com/sun/jersey/jersey-json/1.13/jersey-json-1.13.jar
Download https://repo1.maven.org/maven2/org/apache/httpcomponents/httpcore/4.4.5/httpcore-4.4.5.jar
Download https://repo1.maven.org/maven2/com/nimbusds/oauth2-oidc-sdk/4.5/oauth2-oidc-sdk-4.5.jar
Download https://repo1.maven.org/maven2/com/google/code/gson/gson/2.3.1/gson-2.3.1.jar
Download https://repo1.maven.org/maven2/com/sun/jersey/jersey-core/1.13/jersey-core-1.13.jar
Download https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.9.2/jackson-core-asl-1.9.2.jar
Download https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-mapper-asl/1.9.2/jackson-mapper-asl-1.9.2.jar
Download https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-jaxrs/1.9.2/jackson-jaxrs-1.9.2.jar
Download https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar
Download https://repo1.maven.org/maven2/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar
Download https://repo1.maven.org/maven2/org/apache/commons/commons-lang3/3.3.1/commons-lang3-3.3.1.jar
Download https://repo1.maven.org/maven2/net/minidev/json-smart/1.1.1/json-smart-1.1.1.jar
Download https://repo1.maven.org/maven2/com/nimbusds/lang-tag/1.4/lang-tag-1.4.jar
Download https://repo1.maven.org/maven2/com/nimbusds/nimbus-jose-jwt/3.1.2/nimbus-jose-jwt-3.1.2.jar
Download https://repo1.maven.org/maven2/stax/stax-api/1.0.1/stax-api-1.0.1.jar
Download https://repo1.maven.org/maven2/org/bouncycastle/bcprov-jdk15on/1.51/bcprov-jdk15on-1.51.jar
Download https://repo1.maven.org/maven2/javax/mail/mail/1.4.7/mail-1.4.7.jar
:assemble

BUILD SUCCESSFUL

Total time: 1 mins 25.649 secs

This build could be faster, please consider using the Gradle Daemon: https://docs.gradle.org/2.14/userguide/gradle_daemon.html
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;上传应用&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;设置应用的主机名为spring-music。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$cf push --hostname spring-music
Using manifest file /Users/jimmy/Workspace/github/cloudfoundry-samples/spring-music/manifest.yml

Creating app spring-music in org pcfdev-org / space pcfdev-space as user...
OK

Creating route spring-music.local.pcfdev.io...
OK

Binding spring-music.local.pcfdev.io to spring-music...
OK

Uploading spring-music...
Uploading app files from: /var/folders/61/f7mqkyjn1nz5mfmfvdztgzjw0000gn/T/unzipped-app139680305
Uploading 38.9M, 234 files
Done uploading               
OK

Starting app spring-music in org pcfdev-org / space pcfdev-space as user...
Downloading dotnet-core_buildpack...
Downloading go_buildpack...
Downloading python_buildpack...
Downloading php_buildpack...
Downloading staticfile_buildpack...
Downloaded staticfile_buildpack
Downloading binary_buildpack...
Downloaded binary_buildpack (9.3K)
Downloading java_buildpack...
Downloaded java_buildpack (249.1M)
Downloaded dotnet-core_buildpack (169.3M)
Downloading ruby_buildpack...
Downloading nodejs_buildpack...
Downloaded python_buildpack (255.3M)
Downloaded nodejs_buildpack (109.4M)
Downloaded go_buildpack (392M)
Downloaded php_buildpack (310.4M)
Downloaded ruby_buildpack (260.8M)
Creating container
Successfully created container
Downloading app package...
Downloaded app package (38.8M)
Staging...
-----&amp;gt; Java Buildpack Version: v3.10 (offline) | https://github.com/cloudfoundry/java-buildpack.git#193d6b7
-----&amp;gt; Downloading Open Jdk JRE 1.8.0_111 from https://java-buildpack.cloudfoundry.org/openjdk/trusty/x86_64/openjdk-1.8.0_111.tar.gz (found in cache)
       Expanding Open Jdk JRE to .java-buildpack/open_jdk_jre (1.4s)
-----&amp;gt; Downloading Open JDK Like Memory Calculator 2.0.2_RELEASE from https://java-buildpack.cloudfoundry.org/memory-calculator/trusty/x86_64/memory-calculator-2.0.2_RELEASE.tar.gz (found in cache)
       Memory Settings: -Xss349K -Xmx681574K -XX:MaxMetaspaceSize=104857K -Xms681574K -XX:MetaspaceSize=104857K
-----&amp;gt; Downloading Spring Auto Reconfiguration 1.10.0_RELEASE from https://java-buildpack.cloudfoundry.org/auto-reconfiguration/auto-reconfiguration-1.10.0_RELEASE.jar (found in cache)
Exit status 0
Staging complete
Uploading droplet, build artifacts cache...
Uploading build artifacts cache...
Uploading droplet...
Uploaded build artifacts cache (108B)
Uploaded droplet (83.9M)
Uploading complete
Destroying container
Successfully destroyed container

0 of 1 instances running, 1 starting
0 of 1 instances running, 1 starting
0 of 1 instances running, 1 starting
0 of 1 instances running, 1 starting
1 of 1 instances running

App started


OK

App spring-music was started using this command `CALCULATED_MEMORY=$($PWD/.java-buildpack/open_jdk_jre/bin/java-buildpack-memory-calculator-2.0.2_RELEASE -memorySizes=metaspace:64m..,stack:228k.. -memoryWeights=heap:65,metaspace:10,native:15,stack:10 -memoryInitials=heap:100%,metaspace:100% -stackThreads=300 -totMemory=$MEMORY_LIMIT) &amp;amp;&amp;amp; JAVA_OPTS=&amp;quot;-Djava.io.tmpdir=$TMPDIR -XX:OnOutOfMemoryError=$PWD/.java-buildpack/open_jdk_jre/bin/killjava.sh $CALCULATED_MEMORY&amp;quot; &amp;amp;&amp;amp; SERVER_PORT=$PORT eval exec $PWD/.java-buildpack/open_jdk_jre/bin/java $JAVA_OPTS -cp $PWD/. org.springframework.boot.loader.JarLauncher`

Showing health and status for app spring-music in org pcfdev-org / space pcfdev-space as user...
OK

requested state: started
instances: 1/1
usage: 1G x 1 instances
urls: spring-music.local.pcfdev.io
last uploaded: Thu Mar 23 14:29:46 UTC 2017
stack: cflinuxfs2
buildpack: java-buildpack=v3.10-offline-https://github.com/cloudfoundry/java-buildpack.git#193d6b7 java-main open-jdk-like-jre=1.8.0_111 open-jdk-like-memory-calculator=2.0.2_RELEASE spring-auto-reconfiguration=1.10.0_RELEASE

     state     since                    cpu      memory       disk             details
#0   running   2017-03-23 10:31:36 PM   160.7%   442M of 1G   165.6M of 512M
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;在浏览器中访问app&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;spring-music.local.pcfdev.io&#34;&gt;spring-music.local.pcfdev.io&lt;/a&gt;页面如图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/pivotal-cloudfoundry-spring-music.jpg&#34; alt=&#34;spring-music&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;requested state: started
instances: 1/1
usage: 512M x 1 instances
urls: spring-music.local.pcfdev.io
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;查看日志&#34;&gt;查看日志&lt;/h2&gt;

&lt;p&gt;PCF提供应用的日志聚合功能，你可以查看HTTP请求、对应用操作时候的output，如扩容、重启等。&lt;/p&gt;

&lt;p&gt;每行日志中都包括如下信息：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Timestamp&lt;/li&gt;
&lt;li&gt;Log type&lt;/li&gt;
&lt;li&gt;Channel&lt;/li&gt;
&lt;li&gt;Message&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;查看刚才那个应用的日志信息：&lt;/p&gt;

&lt;p&gt;查看最近输出：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$cf logs spring-music --recent
2017-03-23T22:34:05.17+0800 [RTR/0]      OUT spring-music.local.pcfdev.io - [23/03/2017:14:34:05.163 +0000] &amp;quot;GET /templates/albumForm.html HTTP/1.1&amp;quot; 200 0 2518 &amp;quot;http://spring-music.local.pcfdev.io/&amp;quot; &amp;quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.98 Safari/537.36&amp;quot; 192.168.11.1:52097 10.0.2.15:60012 x_forwarded_for:&amp;quot;-&amp;quot; x_forwarded_proto:&amp;quot;http&amp;quot; vcap_request_id:c6b5f34d-bc5a-4c66-77aa-cb768b273f21 response_time:0.007390127 app_id:fdc7a43e-61b8-40e9-b1dc-38b858037da9 app_index:0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看实时输出流：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$cf logs spring-music
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;连接数据库&#34;&gt;连接数据库&lt;/h2&gt;

&lt;p&gt;在上面的那个例子中用的是内存数据库。我们可以改用mysql数据库。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;查看可用的数据&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$cf marketplace -s p-mysql
Getting service plan information for service p-mysql as user...
OK

service plan   description            free or paid
512mb          PCF Dev MySQL Server   free
1gb            PCF Dev MySQL Server   free
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;创建数据库&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$cf create-service p-mysql 512mb my-spring-db
Creating service instance my-spring-db in org pcfdev-org / space pcfdev-space as user...
OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;将它与我们上面的示例应用程序绑定。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$cf bind-service spring-music my-spring-db
Binding service my-spring-db to app spring-music in org pcfdev-org / space pcfdev-space as user...
OK
TIP: Use &#39;cf restage spring-music&#39; to ensure your env variable changes take effect
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;重启app&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$cf restart spring-music
Stopping app spring-music in org pcfdev-org / space pcfdev-space as user...
OK

Starting app spring-music in org pcfdev-org / space pcfdev-space as user...

0 of 1 instances running, 1 starting
0 of 1 instances running, 1 starting
0 of 1 instances running, 1 starting
0 of 1 instances running, 1 starting
0 of 1 instances running, 1 starting
1 of 1 instances running

App started


OK

App spring-music was started using this command `CALCULATED_MEMORY=$($PWD/.java-buildpack/open_jdk_jre/bin/java-buildpack-memory-calculator-2.0.2_RELEASE -memorySizes=metaspace:64m..,stack:228k.. -memoryWeights=heap:65,metaspace:10,native:15,stack:10 -memoryInitials=heap:100%,metaspace:100% -stackThreads=300 -totMemory=$MEMORY_LIMIT) &amp;amp;&amp;amp; JAVA_OPTS=&amp;quot;-Djava.io.tmpdir=$TMPDIR -XX:OnOutOfMemoryError=$PWD/.java-buildpack/open_jdk_jre/bin/killjava.sh $CALCULATED_MEMORY&amp;quot; &amp;amp;&amp;amp; SERVER_PORT=$PORT eval exec $PWD/.java-buildpack/open_jdk_jre/bin/java $JAVA_OPTS -cp $PWD/. org.springframework.boot.loader.JarLauncher`

Showing health and status for app spring-music in org pcfdev-org / space pcfdev-space as user...
OK

requested state: started
instances: 1/1
usage: 1G x 1 instances
urls: spring-music.local.pcfdev.io
last uploaded: Thu Mar 23 14:29:46 UTC 2017
stack: cflinuxfs2
buildpack: java-buildpack=v3.10-offline-https://github.com/cloudfoundry/java-buildpack.git#193d6b7 java-main open-jdk-like-jre=1.8.0_111 open-jdk-like-memory-calculator=2.0.2_RELEASE spring-auto-reconfiguration=1.10.0_RELEASE

     state     since                    cpu      memory         disk             details
#0   running   2017-03-23 10:44:18 PM   150.4%   461.6M of 1G   165.6M of 512M
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在我们再查看下自己的service。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$cf services
Getting services in org pcfdev-org / space pcfdev-space as user...
OK

name           service   plan    bound apps     last operation
my-spring-db   p-mysql   512mb   spring-music   create succeeded
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;应用扩容&#34;&gt;应用扩容&lt;/h2&gt;

&lt;p&gt;扩展应用的示例数。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$cf scale spring-music -i 2
Scaling app spring-music in org pcfdev-org / space pcfdev-space as user...
OK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再查看下&lt;code&gt;spring-music&lt;/code&gt;应用的信息。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$cf app spring-music
Showing health and status for app spring-music in org pcfdev-org / space pcfdev-space as user...
OK

requested state: started
instances: 2/2
usage: 1G x 2 instances
urls: spring-music.local.pcfdev.io
last uploaded: Thu Mar 23 14:29:46 UTC 2017
stack: cflinuxfs2
buildpack: java-buildpack=v3.10-offline-https://github.com/cloudfoundry/java-buildpack.git#193d6b7 java-main open-jdk-like-jre=1.8.0_111 open-jdk-like-memory-calculator=2.0.2_RELEASE spring-auto-reconfiguration=1.10.0_RELEASE

     state      since                    cpu    memory         disk             details
#0   running    2017-03-23 10:44:18 PM   0.5%   451.4M of 1G   165.6M of 512M
#1   starting   2017-03-23 10:46:19 PM   0.0%   348.3M of 1G   165.6M of 512M

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;还可以对内存进行扩容。这个操作会重启应用。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$cf scale spring-music -m 1G
0 of 2 instances running, 1 starting, 1 down
0 of 2 instances running, 1 starting, 1 down
0 of 2 instances running, 1 starting, 1 down
0 of 2 instances running, 1 starting, 1 down
0 of 2 instances running, 1 starting, 1 down
0 of 2 instances running, 1 starting, 1 down
1 of 2 instances running, 1 down

App started


OK

App spring-music was started using this command `CALCULATED_MEMORY=$($PWD/.java-buildpack/open_jdk_jre/bin/java-buildpack-memory-calculator-2.0.2_RELEASE -memorySizes=metaspace:64m..,stack:228k.. -memoryWeights=heap:65,metaspace:10,native:15,stack:10 -memoryInitials=heap:100%,metaspace:100% -stackThreads=300 -totMemory=$MEMORY_LIMIT) &amp;amp;&amp;amp; JAVA_OPTS=&amp;quot;-Djava.io.tmpdir=$TMPDIR -XX:OnOutOfMemoryError=$PWD/.java-buildpack/open_jdk_jre/bin/killjava.sh $CALCULATED_MEMORY&amp;quot; &amp;amp;&amp;amp; SERVER_PORT=$PORT eval exec $PWD/.java-buildpack/open_jdk_jre/bin/java $JAVA_OPTS -cp $PWD/. org.springframework.boot.loader.JarLauncher`

Showing health and status for app spring-music in org pcfdev-org / space pcfdev-space as user...
OK

requested state: started
instances: 1/2
usage: 1G x 2 instances
urls: spring-music.local.pcfdev.io
last uploaded: Thu Mar 23 14:29:46 UTC 2017
stack: cflinuxfs2
buildpack: java-buildpack=v3.10-offline-https://github.com/cloudfoundry/java-buildpack.git#193d6b7 java-main open-jdk-like-jre=1.8.0_111 open-jdk-like-memory-calculator=2.0.2_RELEASE spring-auto-reconfiguration=1.10.0_RELEASE

     state     since                    cpu      memory         disk             details
#0   running   2017-03-23 10:48:43 PM   145.1%   412.2M of 1G   165.6M of 512M
#1   down      2017-03-23 10:48:14 PM   0.7%     436.2M of 1G   165.6M of 512M   insufficient resources: memory
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;还可以增加应用的磁盘大小。这个操作也会重启应用。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$cf scale spring-music -k 512M
This will cause the app to restart. Are you sure you want to scale spring-music?&amp;gt; y

Scaling app spring-music in org pcfdev-org / space pcfdev-space as user...
OK
Stopping app spring-music in org pcfdev-org / space pcfdev-space as user...
OK

Starting app spring-music in org pcfdev-org / space pcfdev-space as user...

0 of 2 instances running, 1 starting, 1 down
0 of 2 instances running, 1 starting, 1 down
0 of 2 instances running, 1 starting, 1 down
0 of 2 instances running, 1 starting, 1 down
0 of 2 instances running, 1 starting, 1 down
1 of 2 instances running, 1 down

App started


OK

App spring-music was started using this command `CALCULATED_MEMORY=$($PWD/.java-buildpack/open_jdk_jre/bin/java-buildpack-memory-calculator-2.0.2_RELEASE -memorySizes=metaspace:64m..,stack:228k.. -memoryWeights=heap:65,metaspace:10,native:15,stack:10 -memoryInitials=heap:100%,metaspace:100% -stackThreads=300 -totMemory=$MEMORY_LIMIT) &amp;amp;&amp;amp; JAVA_OPTS=&amp;quot;-Djava.io.tmpdir=$TMPDIR -XX:OnOutOfMemoryError=$PWD/.java-buildpack/open_jdk_jre/bin/killjava.sh $CALCULATED_MEMORY&amp;quot; &amp;amp;&amp;amp; SERVER_PORT=$PORT eval exec $PWD/.java-buildpack/open_jdk_jre/bin/java $JAVA_OPTS -cp $PWD/. org.springframework.boot.loader.JarLauncher`

Showing health and status for app spring-music in org pcfdev-org / space pcfdev-space as user...
OK

requested state: started
instances: 1/2
usage: 1G x 2 instances
urls: spring-music.local.pcfdev.io
last uploaded: Thu Mar 23 14:29:46 UTC 2017
stack: cflinuxfs2
buildpack: java-buildpack=v3.10-offline-https://github.com/cloudfoundry/java-buildpack.git#193d6b7 java-main open-jdk-like-jre=1.8.0_111 open-jdk-like-memory-calculator=2.0.2_RELEASE spring-auto-reconfiguration=1.10.0_RELEASE

     state     since                    cpu      memory         disk             details
#0   running   2017-03-23 10:50:57 PM   130.8%   376.2M of 1G   165.6M of 512M
#1   down      2017-03-23 10:50:32 PM   0.6%     438.5M of 1G   165.6M of 512M   insufficient resources: memory
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从上面的操作中可以看到，连续性特别强，所有的操作都可以在几秒钟内完成，特别适合&lt;strong&gt;微服务&lt;/strong&gt;的部署和&lt;strong&gt;Cloud Native&lt;/strong&gt; APP。&lt;/p&gt;

&lt;p&gt;关于&lt;strong&gt;Pivotal Cloud Foundry&lt;/strong&gt;的更多文档可以访问：&lt;a href=&#34;https://pivotal.io/cn/platform/pcf-tutorials/getting-started-with-pivotal-cloud-foundry-dev/next-steps&#34;&gt;https://pivotal.io/cn/platform/pcf-tutorials/getting-started-with-pivotal-cloud-foundry-dev/next-steps&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>TensorFlow实战（才云郑泽宇著）读书笔记——第三章TensorFlow入门</title>
      <link>http://rootsongjc.github.io/blogs/tensorflow-practice-03/</link>
      <pubDate>Thu, 23 Mar 2017 19:34:33 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/tensorflow-practice-03/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/2015052401.jpg&#34; alt=&#34;扬州东关&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：扬州东关 May 24,2015）&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;这是我阅读&lt;a href=&#34;caicloud.io&#34;&gt;才云科技&lt;/a&gt;郑泽宇的《TensorFlow实战Google深度学习框架》的读书笔记系列文章，按照文章的章节顺序来写的。整本书的笔记归档在&lt;a href=&#34;http://rootsongjc.github.io/tags/tensorflow-practice-reading-notes/&#34;&gt;这里&lt;/a&gt;。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;P.S 本书的&lt;strong&gt;官方读者交流微信群（作者也在群里）&lt;/strong&gt;已经超过100人，您可以先加我微信后我拉您进去，我的二维码在&lt;a href=&#34;rootsongjc.github.io/about&#34;&gt;这里&lt;/a&gt;，或者直接搜索我的微信号jimmysong。&lt;/p&gt;

&lt;p&gt;这一章从三个角度带大家入门。&lt;/p&gt;

&lt;p&gt;分别是TensorFlow的&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;计算模型&lt;/li&gt;
&lt;li&gt;数据模型&lt;/li&gt;
&lt;li&gt;运行模型&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;3-1-tensorflow的计算模型-图计算&#34;&gt;3.1 TensorFlow的计算模型——图计算&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;计算图&lt;/strong&gt;是TensorFlow中的一个最基本的概念，&lt;u&gt;TensorFlow中的所有计算都会转化成计算图上的节点&lt;/u&gt;。&lt;/p&gt;

&lt;p&gt;其实TensorFlow的名字已经暗示了它的实现方式了，&lt;strong&gt;Tensor&lt;/strong&gt;表示的是数据结构——张量，&lt;strong&gt;Flow&lt;/strong&gt;表示数据流——Tensor通过数据流相互转化。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;常用的方法&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;在python中导入tensorflow：import tensorflow as tf&lt;/li&gt;
&lt;li&gt;获取当前默认的计算图：tf.get_default_graph()&lt;/li&gt;
&lt;li&gt;生成新的计算图：tf.Graph()&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;书中这里都有例子讲解，可以从Github中&lt;a href=&#34;https://github.com/caicloud/tensorflow-tutorial&#34;&gt;下载代码&lt;/a&gt;，或者如果你使用才云提供的docker镜像的方式安装的话，在jupyter中可以看到各个章节的代码。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;定义两个不同的图&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import tensorflow as tf

g1 = tf.Graph()
with g1.as_default():
    v = tf.get_variable(&amp;quot;v&amp;quot;, [1], initializer = tf.zeros_initializer) # 设置初始值为0

g2 = tf.Graph()
with g2.as_default():
    v = tf.get_variable(&amp;quot;v&amp;quot;, [1], initializer = tf.ones_initializer())  # 设置初始值为1
    
with tf.Session(graph = g1) as sess:
    tf.global_variables_initializer().run()
    with tf.variable_scope(&amp;quot;&amp;quot;, reuse=True):
        print(sess.run(tf.get_variable(&amp;quot;v&amp;quot;)))

with tf.Session(graph = g2) as sess:
    tf.global_variables_initializer().run()
    with tf.variable_scope(&amp;quot;&amp;quot;, reuse=True):
        print(sess.run(tf.get_variable(&amp;quot;v&amp;quot;)))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To be continued…&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>TensorFlow实战（才云郑泽宇著）读书笔记——第二章TensorFlow环境搭建</title>
      <link>http://rootsongjc.github.io/blogs/tensorflow-practice-02/</link>
      <pubDate>Thu, 23 Mar 2017 19:34:33 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/tensorflow-practice-02/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20140810002.jpg&#34; alt=&#34;广州海珠桥&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：广州海珠桥 Aug 10,2014）&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;这是我阅读&lt;a href=&#34;caicloud.io&#34;&gt;才云科技&lt;/a&gt;郑泽宇的《TensorFlow实战Google深度学习框架》的读书笔记系列文章，按照文章的章节顺序来写的。整本书的笔记归档在&lt;a href=&#34;http://rootsongjc.github.io/tags/tensorflow-practice-reading-notes/&#34;&gt;这里&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;P.S 本书的&lt;strong&gt;官方读者交流微信群（作者也在群里）&lt;/strong&gt;已经超过100人，您可以先加我微信后我拉您进去，我的二维码在&lt;a href=&#34;rootsongjc.github.io/about&#34;&gt;这里&lt;/a&gt;，或者直接搜索我的微信号jimmysong。&lt;/p&gt;

&lt;p&gt;睇完这一章后应该就可以自己搭建出一个TensorFlow的环境，我之前在docker里玩过，镜像比较大，下载慢一点，不过用起来很方便，如果你仅仅是想试用一下TensorFlow，看看它能干什么的话，可以直接在docker里试用一下。在Mac上安装的详细步骤，&lt;a href=&#34;https://www.tensorflow.org/install/install_mac&#34;&gt;官方安装说明文档&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;2-1-tensorflow的主要依赖包&#34;&gt;2.1 TensorFlow的主要依赖包&lt;/h2&gt;

&lt;p&gt;TensorFlow主要用到以下两个依赖：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://developers.google.com/protocol-buffers/&#34;&gt;Protocol buffer&lt;/a&gt;：数据结构化工具。Google开源的结构化数据格式，用于网络传输数据时候的序列化和反序列化，使用的时候需要先定义schema，github地址&lt;a href=&#34;https://github.com/google/protobuf。分布式TensorFlow使用到额gRPC也是使用Protocol&#34;&gt;https://github.com/google/protobuf。分布式TensorFlow使用到额gRPC也是使用Protocol&lt;/a&gt; Buffer来组织的，&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bazel.build/&#34;&gt;Bazel&lt;/a&gt;:自动化编译构建工具。Google开源的，github地址&lt;a href=&#34;https://github.com/bazelbuild/bazel，它支持多语言、多平台、可重复编译和可伸缩，构建大型软件速度也是很快的。Bazel使用**项目空间**的形式管理编译的，每个项目空间需要包含[BUILD文件](https://github.com/tensorflow/tensorflow/blob/master/bower.BUILD)（定义编译目标）和[WORKSPACE](https://github.com/tensorflow/tensorflow/blob/master/WORKSPACE)文件（定义编译的依赖环境）。这两个文件都有点类似python语法。&#34;&gt;https://github.com/bazelbuild/bazel，它支持多语言、多平台、可重复编译和可伸缩，构建大型软件速度也是很快的。Bazel使用**项目空间**的形式管理编译的，每个项目空间需要包含[BUILD文件](https://github.com/tensorflow/tensorflow/blob/master/bower.BUILD)（定义编译目标）和[WORKSPACE](https://github.com/tensorflow/tensorflow/blob/master/WORKSPACE)文件（定义编译的依赖环境）。这两个文件都有点类似python语法。&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;2-2-tensorflow安装&#34;&gt;2.2 TensorFlow安装&lt;/h2&gt;

&lt;p&gt;TensorFlow的安装方式包括docker镜像、pip安装、源码编译安装。&lt;/p&gt;

&lt;p&gt;&lt;u&gt;我选择最方便的docker镜像方式&lt;/u&gt;，其他方式对本地环境做很多配置，折腾起来比较麻烦。&lt;/p&gt;

&lt;p&gt;我早就在docker中安装过TensorFlow0.9小试过牛刀。现在&lt;a href=&#34;https://github.com/tensorflow/tensorflow/releases&#34;&gt;1.0.1版本&lt;/a&gt;已经released了。TensorFlow的所有版本都有对应的docker镜像发布在&lt;a href=&#34;https://hub.docker.com/r/tensorflow/tensorflow/tags/&#34;&gt;docker hub&lt;/a&gt;，可以直接&lt;code&gt;docker pull&lt;/code&gt;安装。&lt;/p&gt;

&lt;p&gt;为了和书中所用的镜像保持统一，我将使用caicloud提供的镜像，基于TensorFlow0.12.0（这个版本是2016年12月20日发布的），他们增加了一些其他机器学习工具包和TensorFlow可视化工具TensorBoard。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;docker镜像方式安装&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;首先下载镜像，这个image比较大，下载下来比较费时间，我用了差不多15分钟吧。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker pull cargo.caicloud.io/tensorflow/tensorflow:0.12.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下载下来后我们再check下这个大小为&lt;strong&gt;1.41GB&lt;/strong&gt;镜像的layers。&lt;/p&gt;

&lt;p&gt;另外还有个&lt;a href=&#34;https://github.com/NVIDIA/nvidia-docker&#34;&gt;&lt;strong&gt;nvidia&lt;/strong&gt;版本的docker&lt;/a&gt;，可以将你电脑的&lt;strong&gt;GPU&lt;/strong&gt;派山用场，我暂时没用到GPU，我电脑装的是&lt;code&gt;docker17.03-ce&lt;/code&gt;，就不折腾GPU版本的TensorFlow了。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT
c8a8409297f2        5 weeks ago         /bin/sh -c #(nop)  CMD [&amp;quot;/run_tf.sh&amp;quot;]           0 B                 
&amp;lt;missing&amp;gt;           5 weeks ago         /bin/sh -c #(nop) COPY file:78332d36244852...   122 B               
&amp;lt;missing&amp;gt;           5 weeks ago         /bin/sh -c #(nop) COPY dir:8b6ab7d235e3975...   21 MB               
&amp;lt;missing&amp;gt;           5 weeks ago         /bin/sh -c #(nop) COPY dir:fca915671040399...   360 MB              
&amp;lt;missing&amp;gt;           5 weeks ago         /bin/sh -c #(nop) COPY dir:69314aa937be649...   89.9 kB             
&amp;lt;missing&amp;gt;           5 weeks ago         /bin/sh -c rm -rf /notebooks/*                  0 B                 
&amp;lt;missing&amp;gt;           5 weeks ago         /bin/sh -c pip install caicloud.tensorflow      21.4 MB             
&amp;lt;missing&amp;gt;           5 weeks ago         /bin/sh -c pip install -U scikit-learn          39.9 kB             
&amp;lt;missing&amp;gt;           5 weeks ago         /bin/sh -c apt-get update &amp;amp;&amp;amp; apt-get insta...   23.9 MB             
&amp;lt;missing&amp;gt;           5 weeks ago         /bin/sh -c #(nop)  ENV LANG=C.UTF-8             0 B                 
&amp;lt;missing&amp;gt;           3 months ago        /bin/sh -c #(nop)  CMD [&amp;quot;/run_jupyter.sh&amp;quot;]      0 B                 
&amp;lt;missing&amp;gt;           3 months ago        /bin/sh -c #(nop)  WORKDIR /notebooks           0 B                 
&amp;lt;missing&amp;gt;           3 months ago        /bin/sh -c #(nop)  EXPOSE 8888/tcp              0 B                 
&amp;lt;missing&amp;gt;           3 months ago        /bin/sh -c #(nop)  EXPOSE 6006/tcp              0 B                 
&amp;lt;missing&amp;gt;           3 months ago        /bin/sh -c #(nop) COPY file:5485384c641ba7...   733 B               
&amp;lt;missing&amp;gt;           3 months ago        /bin/sh -c #(nop) COPY dir:388d24701b3b5bc...   400 kB              
&amp;lt;missing&amp;gt;           3 months ago        /bin/sh -c #(nop) COPY file:822af972b63c44...   1.06 kB             
&amp;lt;missing&amp;gt;           3 months ago        /bin/sh -c pip --no-cache-dir install http...   191 MB              
&amp;lt;missing&amp;gt;           3 months ago        /bin/sh -c pip --no-cache-dir install     ...   379 MB              
&amp;lt;missing&amp;gt;           3 months ago        /bin/sh -c curl -O https://bootstrap.pypa....   11.4 MB             
&amp;lt;missing&amp;gt;           3 months ago        /bin/sh -c apt-get update &amp;amp;&amp;amp; apt-get insta...   212 MB              
&amp;lt;missing&amp;gt;           3 months ago        /bin/sh -c #(nop)  MAINTAINER Craig Citro ...   0 B                 
&amp;lt;missing&amp;gt;           9 months ago        /bin/sh -c #(nop) CMD [&amp;quot;/bin/bash&amp;quot;]             0 B                 
&amp;lt;missing&amp;gt;           9 months ago        /bin/sh -c sed -i &#39;s/^#\s*\(deb.*universe\...   1.9 kB              
&amp;lt;missing&amp;gt;           9 months ago        /bin/sh -c rm -rf /var/lib/apt/lists/*          0 B                 
&amp;lt;missing&amp;gt;           9 months ago        /bin/sh -c set -xe   &amp;amp;&amp;amp; echo &#39;#!/bin/sh&#39; &amp;gt;...   195 kB              
&amp;lt;missing&amp;gt;           9 months ago        /bin/sh -c #(nop) ADD file:aca501360d0937b...   188 MB 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到这是一个基于&lt;strong&gt;Ubuntu&lt;/strong&gt;的docker image，这其中还包含了一个&lt;strong&gt;Jupyter notebook&lt;/strong&gt;和一些python packages。&lt;/p&gt;

&lt;p&gt;使用&lt;code&gt;docker image history —no-trunc $IMAGE_ID&lt;/code&gt;命令可以看到每一层的详细信息。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;启动TensorFlow&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;直接在docker中启动。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;docker run -it -d -p 8888:8888 -p 6006:6006 --name tf-dev cargo.caicloud.io/tensorflow/tensorflow:0.12.0 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;启动后进入&lt;code&gt;localhost:8888&lt;/code&gt;页面，发现登陆jupyter居然还要输入密码，书中没说要输入密码啊，也没说密码是什么，密码在哪里呢？&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;如何获取Jupyter的登录密码书中没有介绍。其实没必要修改镜像活着进入容器中需钙jupyter的配置，直接查看刚启动的&lt;code&gt;tf-dev&lt;/code&gt;容器的日志即可，里面包含了登录密码。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;docker logs tf-dev
[I 10:52:46.200 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret
[W 10:52:46.244 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.
[I 10:52:46.267 NotebookApp] Serving notebooks from local directory: /notebooks
[I 10:52:46.267 NotebookApp] 0 active kernels 
[I 10:52:46.267 NotebookApp] The Jupyter Notebook is running at: http://[all ip addresses on your system]:8888/?token=e64afc31eec843717733d6e4527aecf833ce18383214dc47
[I 10:52:46.267 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
Starting TensorBoard 39 on port 6006
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看到了吗，&lt;code&gt;tf-dev&lt;/code&gt;容器的日志输出里就包括了密码，我的容器的jupyter的密码是&lt;strong&gt;token后面的那个字符串&lt;/strong&gt;e64afc31eec843717733d6e4527aecf833ce18383214dc47。&lt;/p&gt;

&lt;p&gt;现在用刚才从日志里看到的密码就可以登录了，Jupyter页面上可以看到本书所有章节的代码了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/tensorflow-practice-chapter2-jupyter-web.jpg&#34; alt=&#34;jupyter页面&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;使用pip安装&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;另外我在mac上也用pip方式安装了。我安装的是最新版的1.0.1的CPU-only，加上&lt;code&gt;—user -U&lt;/code&gt;是为了规避mac上的各种权限问题。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;pip install --upgrade tensorflow --user -U
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下载的整个软件包只有39.3MB，速度还是很快的。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>TensorFlow实战（才云郑泽宇著）读书笔记——第一章深度学习简介</title>
      <link>http://rootsongjc.github.io/blogs/tensorflow-practice-01/</link>
      <pubDate>Mon, 20 Mar 2017 22:04:33 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/tensorflow-practice-01/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/tensorflow-book-page.jpg&#34; alt=&#34;tensorflow实战图书封面&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：TensofFlow实战图书封面）&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;🙏电子工业出版社编辑赠书，能够这么快的拿到这本书，也🙏&lt;a href=&#34;www.caicloud.io&#34;&gt;才云科技&lt;/a&gt;的郑泽宇大哥耐心的写了这本书，能够让我等小白一窥深度学习的真容。另外要强烈推荐下这本书，这是本TensorFlow深度学习很好的入门书。书中提供的代码&lt;a href=&#34;https://github.com/caicloud/tensorflow-tutorial&#34;&gt;下载地址&lt;/a&gt;，整本书的笔记归档在&lt;a href=&#34;http://rootsongjc.github.io/tags/tensorflow-practice-reading-notes&#34;&gt;这里&lt;/a&gt;。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;P.S 本书的&lt;strong&gt;官方读者交流微信群（作者也在群里）&lt;/strong&gt;已经超过100人，您可以先加我微信后我拉您进去，我的二维码在&lt;a href=&#34;rootsongjc.github.io/about&#34;&gt;这里&lt;/a&gt;，或者直接搜索我的微信号jimmysong。&lt;/p&gt;

&lt;h2 id=&#34;1-1-人工智能-机器学习与深度学习&#34;&gt;1.1 人工智能、机器学习与深度学习&lt;/h2&gt;

&lt;p&gt;这一节是讲解三者之间的关系。&lt;/p&gt;

&lt;p&gt;首先以&lt;strong&gt;垃圾邮件分类问题&lt;/strong&gt;引入机器学习的&lt;strong&gt;逻辑回归算法&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;逻辑回归算法的准确性取决于训练数据中的特征的提取，以及训练的数据数量。&lt;/p&gt;

&lt;p&gt;文章中又提了一个从实体中提取特征的例子：通过笛卡尔坐标系活极角坐标系来表示不同颜色的点，看看能否用一条直线划分。这个例子用来说明&lt;strong&gt;一旦解决了数据表达和特征提取，很多人工智能的问题就能迎刃而解&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;深度学习是机器学习的一个分支，除了能够学习特征和任务之间的关联之外，还能&lt;strong&gt;自动从简单特征中提取更加复杂的特征&lt;/strong&gt;，这是其区别于机器学习的关键点。&lt;/p&gt;

&lt;p&gt;总的来说，人工智能&amp;gt;机器学习&amp;gt;深度学习。&lt;/p&gt;

&lt;h2 id=&#34;1-2深度学习的发展历程&#34;&gt;1.2深度学习的发展历程&lt;/h2&gt;

&lt;p&gt;本节介绍了深度网络历史的三个发展阶段。&lt;/p&gt;

&lt;p&gt;2012年的&lt;strong&gt;ImageNet&lt;/strong&gt;图像分类竞赛上，深度学习系统&lt;strong&gt;AlexNet&lt;/strong&gt;赢得冠军，自此深度学习作为深层神经网络的代名词而被人熟知。&lt;/p&gt;

&lt;h2 id=&#34;1-3深度学习的应用&#34;&gt;1.3深度学习的应用&lt;/h2&gt;

&lt;p&gt;这一节讲的是深度学习的应用，首先还是从ImageNet的图像识别开始，应用到了OCR（提到了卷积神经网络）、语音识别（提到了混合搞高斯模型）、自然语言处理（提到了语料库、单词向量、机器翻译、情感分析）、人机对弈（提到了AlphaGO）。&lt;/p&gt;

&lt;h2 id=&#34;1-4-深度学习工具介绍与对比&#34;&gt;1.4 深度学习工具介绍与对比&lt;/h2&gt;

&lt;p&gt;TensorFlow的渊源是Google大脑团队在2011年开发，在内部使用的&lt;strong&gt;DistBelief&lt;/strong&gt;，并赢得了ImageNet 2014年的比赛，TF是其开源版本，还发表了一篇论文&lt;code&gt;TensorFlow: Large-Scale Machine Learning on Heteogeneous Distributed systems&lt;/code&gt;，这就跟当年的&lt;strong&gt;HDFS&lt;/strong&gt;、&lt;strong&gt;MapReduce&lt;/strong&gt;一个套路啊。&lt;/p&gt;

&lt;p&gt;Google还把它用来做&lt;strong&gt;RankBrain&lt;/strong&gt;和很多其他的产品线上使用。&lt;/p&gt;

&lt;p&gt;当然，还有很多其他的深度学习工具，比如&lt;strong&gt;Caffe&lt;/strong&gt;、&lt;strong&gt;Deeplearning4j&lt;/strong&gt;、&lt;strong&gt;Torch&lt;/strong&gt;等不一而足。从各种指标来看，TensorFlow都是目前最受关注的深度学习框架。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker源码分析第一篇——代码结构</title>
      <link>http://rootsongjc.github.io/blogs/docker-source-code-analysis-code-structure/</link>
      <pubDate>Sun, 19 Mar 2017 23:00:29 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/docker-source-code-analysis-code-structure/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20151001042.jpg&#34; alt=&#34;八达岭长城&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(题图：北京八达岭长城  Oct 1,2015)&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;之前陆陆续续看过一点&lt;strong&gt;docker&lt;/strong&gt;的源码，都未成体系，最近在研究&lt;strong&gt;Docker-17.03-CE&lt;/strong&gt;，趁此机会研究下docker的源码，在网上找到一些相关资料，都比较过时了，发现*孙宏亮*大哥写过一本书叫《Docker源码分析》，而且之前也在&lt;strong&gt;InfoQ&lt;/strong&gt;上陆续发过一些文章，虽然文章都比较老了，基于老的docker版本，但我认为依然有阅读的价值。起码能有这三方面收获：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一是培养阅读源码的思维方式，为自己阅读docker源码提供借鉴。&lt;/li&gt;
&lt;li&gt;二是可以了解docker版本的来龙去脉。&lt;/li&gt;
&lt;li&gt;三还可以作为Go语言项目开发作为借鉴。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;下载地址&#34;&gt;下载地址&lt;/h3&gt;

&lt;p&gt;鉴于这本书已经发行一年半了了，基于的docker版本还是&lt;strong&gt;1.2.0&lt;/strong&gt;，而如今都到了&lt;strong&gt;1.13.0&lt;/strong&gt;（docker17.03的老版本号），应该很少有人买了吧，可以说这本书的纸质版本的生命周期也差不多了吧。如果有人感兴趣可以下载pdf版本看看，&lt;a href=&#34;http://olz1di9xf.bkt.clouddn.com/Docker%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%AD%99%E5%AE%8F%E4%BA%AE%E8%91%97.pdf&#34;&gt;Docker源码解析-机械工业出版社-孙宏亮著-2015年8月&lt;/a&gt;（完整文字版，大小25.86M），&lt;a href=&#34;http://olz1di9xf.bkt.clouddn.com/Docker%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%AD%99%E5%AE%8F%E4%BA%AE-%E7%9C%8B%E4%BA%91%E7%89%88.pdf&#34;&gt;Docker源码解析-看云整理版&lt;/a&gt;（文字版，有缩略，大小7.62M）。&lt;/p&gt;

&lt;h2 id=&#34;out-of-date&#34;&gt;Out-of-date&lt;/h2&gt;

&lt;p&gt;有一点必须再次强调一下，这本书中的docker源码分析是基于&lt;strong&gt;docker1.2.0&lt;/strong&gt;，而这个版本的docker源码在github上已经无法下载到了，github上available的最低版本的docker源码是&lt;strong&gt;1.4.1&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;顺便感叹一句，科技行业发展实在太快了，尤其是互联网，一本书能连续用上三年都不过时，如果这样的话那么这门技术恐怕都就要被淘汰了吧？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;总体架构&#34;&gt;总体架构&lt;/h2&gt;

&lt;p&gt;Docker总体上是用的是&lt;strong&gt;Client/Server&lt;/strong&gt;模式，所有的命令都可以通过RESTful接口传递。&lt;/p&gt;

&lt;p&gt;整个Docker软件的架构中可以分成三个角色：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Daemon&lt;/strong&gt;：常驻后台运行的进程，接收客户端请求，管理docker容器。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clien&lt;/strong&gt;t：命令行终端，包装命令发送API请求。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;：真正处理客户端请求的后端程序。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;代码结构&#34;&gt;代码结构&lt;/h2&gt;

&lt;p&gt;Docker的代码结构比较清晰，分成的目录比较多，有以下这些：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;api&lt;/strong&gt;：定义API，使用了&lt;strong&gt;Swagger2.0&lt;/strong&gt;这个工具来生成API，配置文件在&lt;code&gt;api/swagger.yaml&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;builder&lt;/strong&gt;：用来build docker镜像的包，看来历史比较悠久了&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bundles&lt;/strong&gt;：这个包是在进行&lt;a href=&#34;http://rootsongjc.github.io/blogs/docker-dev-env/&#34;&gt;docker源码编译和开发环境搭建&lt;/a&gt;的时候用到的，编译生成的二进制文件都在这里。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;cli&lt;/strong&gt;：使用&lt;a href=&#34;http://www.github.com/spf13/cobra&#34;&gt;cobra&lt;/a&gt;工具生成的docker客户端命令行解析器。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;client&lt;/strong&gt;：接收&lt;code&gt;cli&lt;/code&gt;的请求，调用RESTful API中的接口，向server端发送http请求。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;cmd&lt;/strong&gt;：其中包括&lt;code&gt;docker&lt;/code&gt;和&lt;code&gt;dockerd&lt;/code&gt;两个包，他们分别包含了客户端和服务端的main函数入口。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;container&lt;/strong&gt;：容器的配置管理，对不同的platform适配。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;contrib&lt;/strong&gt;：这个目录包括一些有用的脚本、镜像和其他非docker core中的部分。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;daemon&lt;/strong&gt;：这个包中将docker deamon运行时状态expose出来。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;distribution&lt;/strong&gt;：负责docker镜像的pull、push和镜像仓库的维护。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;dockerversion&lt;/strong&gt;：编译的时候自动生成的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;docs&lt;/strong&gt;：文档。这个目录已经不再维护，文档在另一个仓库里&lt;a href=&#34;https://github.com/docker/docker.github.io/。&#34;&gt;https://github.com/docker/docker.github.io/。&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;experimental&lt;/strong&gt;：从docker1.13.0版本起开始增加了实验特性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;hack&lt;/strong&gt;：创建docker开发环境和编译打包时用到的脚本和配置文件。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;image&lt;/strong&gt;：用于构建docker镜像的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;integration-cli&lt;/strong&gt;：集成测试&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;layer&lt;/strong&gt;：管理 union file system driver上的read-only和read-write mounts。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;libcontainerd&lt;/strong&gt;：访问内核中的容器系统调用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;man&lt;/strong&gt;：生成man pages。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;migrate&lt;/strong&gt;：将老版本的graph目录转换成新的metadata。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;oci&lt;/strong&gt;：Open Container Interface库&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;opts&lt;/strong&gt;：命令行的选项库。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pkg&lt;/strong&gt;：&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;plugin&lt;/strong&gt;：docker插件后端实现包。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;profiles&lt;/strong&gt;：里面有apparmor和seccomp两个目录。用于内核访问控制。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;project&lt;/strong&gt;：项目管理的一些说明文档。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;reference&lt;/strong&gt;：处理docker store中镜像的reference。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;registry&lt;/strong&gt;：docker registry的实现。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;restartmanager&lt;/strong&gt;：处理重启后的动作。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;runconfig&lt;/strong&gt;：配置格式解码和校验。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;vendor&lt;/strong&gt;：各种依赖包。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;volume&lt;/strong&gt;：docker volume的实现。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下一篇将讲解docker的各个功能模块和原理。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Contiv Ultimate-Docker17.03CE下思科docker网络插件contiv趟坑终极版（持续更新中）</title>
      <link>http://rootsongjc.github.io/blogs/contiv-ultimate/</link>
      <pubDate>Fri, 17 Mar 2017 17:52:37 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/contiv-ultimate/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20140810001.jpg&#34; alt=&#34;广州石牌桥&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：广州石牌桥 Aug 10,2014）&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;前几天写的几篇&lt;a href=&#34;http://rootsongjc.github.io/tags/contiv/&#34;&gt;关于Contiv的文章&lt;/a&gt;已经把引入坑了😂&lt;/p&gt;

&lt;p&gt;今天这篇文章将带领大家用正确的姿势编译和打包一个&lt;strong&gt;contiv netplugin&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;请一定要在&lt;strong&gt;Linux&lt;/strong&gt;环境中编译。docker中编译也会报错，最好还是搞个虚拟🐔吧，最好还有VPN能翻墙。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;环境准备&#34;&gt;环境准备&lt;/h2&gt;

&lt;p&gt;我使用的是docker17.03-CE、安装了open vSwitch(这个包redhat的源里没有，需要自己的编译安装)，如果你懒得编译可以用我编译的rpm包，&lt;a href=&#34;http://olz1di9xf.bkt.clouddn.com/openvswitch-2.5.0-2.el7.x86_64.rpm&#34;&gt;点这里下载&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;编译&#34;&gt;编译&lt;/h2&gt;

&lt;p&gt;这一步是很容易失败的，有人提过&lt;a href=&#34;https://github.com/contiv/netplugin/issues/779&#34;&gt;issue-779&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;具体步骤&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;创建一个link &lt;strong&gt;/go&lt;/strong&gt;链接到你的GOPATH目录，下面编译的时候要用。&lt;/li&gt;
&lt;li&gt;将源码的&lt;strong&gt;vender&lt;/strong&gt;目录下的文件拷贝到$GOPATH/src目录。&lt;/li&gt;
&lt;li&gt;执行编译&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在netplugin目录下执行以下命令能够编译出二进制文件。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;NET_CONTAINER_BUILD=1 make build
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在你的&lt;strong&gt;/$GOPATH/bin&lt;/strong&gt;目录下应该会有如下几个文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;contivk8s  github-release  godep  golint  misspell  modelgen  netcontiv  netctl  netmaster  netplugin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;⚠️编译过程中可能会遇到 有些包不存在或者需要翻墙下载。&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;打包&#34;&gt;打包&lt;/h2&gt;

&lt;p&gt;我们将其打包为docker plugin。&lt;/p&gt;

&lt;p&gt;Makefile里用于创建plugin rootfs的命令是：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Makefile&#34;&gt;host-pluginfs-create:
        @echo dev: creating a docker v2plugin rootfs ...
        sh scripts/v2plugin_rootfs.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;v2plugin_rootfs.sh&lt;/strong&gt;这个脚本的内容：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;#!/bin/bash
# Script to create the docker v2 plugin
# run this script from contiv/netplugin directory

echo &amp;quot;Creating rootfs for v2plugin &amp;quot;, ${CONTIV_V2PLUGIN_NAME}
cat install/v2plugin/config.template | grep -v &amp;quot;##&amp;quot; &amp;gt; install/v2plugin/config.json
sed -i &amp;quot;s%PluginName%${CONTIV_V2PLUGIN_NAME}%&amp;quot; install/v2plugin/config.json
cp bin/netplugin bin/netmaster bin/netctl install/v2plugin
docker build -t contivrootfs install/v2plugin
id=$(docker create contivrootfs true)
mkdir -p install/v2plugin/rootfs
sudo docker export &amp;quot;${id}&amp;quot; | sudo tar -x -C install/v2plugin/rootfs
docker rm -vf &amp;quot;${id}&amp;quot;
docker rmi contivrootfs
rm install/v2plugin/netplugin install/v2plugin/netmaster install/v2plugin/netctl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;先把&lt;code&gt;$GOPATH/bin&lt;/code&gt;下生成的&lt;code&gt;netplugin&lt;/code&gt;、&lt;code&gt;netmaster&lt;/code&gt;、&lt;code&gt;netctl&lt;/code&gt;、&lt;code&gt;netplugin&lt;/code&gt;这几个二进制文件拷贝到netplugin源码的bin目录下。&lt;/p&gt;

&lt;p&gt;这里面用语创建contivrootfs镜像的Dockerfile内容：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Dockerfile&#34;&gt;# Docker v2plugin container with OVS / netplugin / netmaster 

FROM alpine:3.5
MAINTAINER Cisco Contiv (http://contiv.github.io/)

RUN mkdir -p /run/docker/plugins /etc/openvswitch /var/run/contiv/log \
    &amp;amp;&amp;amp; echo &#39;http://dl-cdn.alpinelinux.org/alpine/v3.4/main&#39; &amp;gt;&amp;gt; /etc/apk/repositories \
    &amp;amp;&amp;amp; apk update &amp;amp;&amp;amp; apk add openvswitch=2.5.0-r0 iptables

COPY netplugin netmaster netctl startcontiv.sh /

ENTRYPOINT [&amp;quot;/startcontiv.sh&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行&lt;code&gt;make host-pluginfs-create&lt;/code&gt;创建rootfs。&lt;/p&gt;

&lt;p&gt;创建出了rootfs后，然后执行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;docker plugin create localhost:5000/contiv/netplugin .
docker push localhost:5000/contiv/netplugin
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;注：我们将插件push到docker registry的镜像仓库中，当前&lt;a href=&#34;www.github.com/vmware/harbor&#34;&gt;Harbor&lt;/a&gt;还不支持docker插件的push。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Install plugin&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;下面是编译和安装我自己生成v2plugin的过程。&lt;/p&gt;

&lt;p&gt;修改&lt;strong&gt;config.json&lt;/strong&gt;文件中的&lt;code&gt;plugin_name&lt;/code&gt;字段的值为插件的名称。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$docker plugin install localhost:5000/contiv/v2plugin 
Plugin &amp;quot;localhost:5000/contiv/v2plugin&amp;quot; is requesting the following privileges:
 - network: [host]
 - mount: [/etc/openvswitch]
 - mount: [/var/log/openvswitch]
 - mount: [/var/run]
 - mount: [/lib/modules]
 - capabilities: [CAP_SYS_ADMIN CAP_NET_ADMIN CAP_SYS_MODULE]
Do you grant the above permissions? [y/N] y
latest: Pulling from contiv/v2plugin
fd87a71d9090: Download complete 
Digest: sha256:b13ad7930f771c9602acf562c2ae147482466f4d94e708692a215935663215a6
Status: Downloaded newer image for localhost:5000/contiv/v2plugin:latest
Installed plugin localhost:5000/contiv/v2plugin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;自己create的插件enable的时候从docker daemon的日志中依然可以看到之前看到找不到socket的错误，实际上也确实是没有生成。如果直接使用&lt;code&gt;docker plugin install store/contiv/v2plugin:1.0.0-beta.3&lt;/code&gt;的方式安装插件是没有问题的。&lt;/p&gt;

&lt;h2 id=&#34;docker17-03-ce中插件机制存在的问题&#34;&gt;Docker17.03-CE中插件机制存在的问题&lt;/h2&gt;

&lt;p&gt;Docker17.03的插件机制是为了docker公司的商业化策略而实行的，所有的docker插件都运行在自己的namespace和rootfs中，插件接口&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Plugin backend接口&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;// Backend for Plugin
type Backend interface {
	Disable(name string, config *enginetypes.PluginDisableConfig) error
	Enable(name string, config *enginetypes.PluginEnableConfig) error
	List(filters.Args) ([]enginetypes.Plugin, error)
	Inspect(name string) (*enginetypes.Plugin, error)
	Remove(name string, config *enginetypes.PluginRmConfig) error
	Set(name string, args []string) error
	Privileges(ctx context.Context, ref reference.Named, metaHeaders http.Header, authConfig *enginetypes.AuthConfig) (enginetypes.PluginPrivileges, error)
	Pull(ctx context.Context, ref reference.Named, name string, metaHeaders http.Header, authConfig *enginetypes.AuthConfig, privileges enginetypes.PluginPrivileges, outStream io.Writer) error
	Push(ctx context.Context, name string, metaHeaders http.Header, authConfig *enginetypes.AuthConfig, outStream io.Writer) error
	Upgrade(ctx context.Context, ref reference.Named, name string, metaHeaders http.Header, authConfig *enginetypes.AuthConfig, privileges enginetypes.PluginPrivileges, outStream io.Writer) error
	CreateFromContext(ctx context.Context, tarCtx io.ReadCloser, options *enginetypes.PluginCreateOptions) error
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从Plugin的后端接口中可以看到，没有像镜像一样的两个常用方法：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;没有修改plugin名字的方法，因为没有这个方法，就无法push plugin到自己的镜像仓库，另外&lt;strong&gt;Harbor&lt;/strong&gt;还是不支持&lt;code&gt;docker plugin push&lt;/code&gt; &lt;a href=&#34;https://github.com/vmware/harbor/issues/1532&#34;&gt;Issue-1532&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;没有导出plugin的方法，这样就只能在联网的主机上安装docker plugin了，对于无法联网的主机只好束手无策了。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;估计docker官方也不会开放这两个接口吧。毕竟这是&lt;strong&gt;Docker EE&lt;/strong&gt; 的一个重要卖点：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Docker EE&amp;rsquo;s Certified Plugins&lt;/strong&gt; provide networking and volume plugins and easy to download and install containers to the Docker EE environment.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;疑问&#34;&gt;疑问&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;为什么一定要使用docker plugin install&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;因为&lt;code&gt;docker plugin install&lt;/code&gt;的时候会申请一些访问权限。&lt;/p&gt;

&lt;p&gt;这一块在上面的步骤中可以看到。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;为什么docker plugin不能改名字？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们看下Plugin的结构体（在api/types/plugin.go中定义）：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// Plugin A plugin for the Engine API
// swagger:model Plugin
type Plugin struct {

	// config
	// Required: true
	Config PluginConfig `json:&amp;quot;Config&amp;quot;`

	// True when the plugin is running. False when the plugin is not running, only installed.
	// Required: true
	Enabled bool `json:&amp;quot;Enabled&amp;quot;`

	// Id
	ID string `json:&amp;quot;Id,omitempty&amp;quot;`

	// name
	// Required: true
	Name string `json:&amp;quot;Name&amp;quot;`

	// plugin remote reference used to push/pull the plugin
	PluginReference string `json:&amp;quot;PluginReference,omitempty&amp;quot;`

	// settings
	// Required: true
	Settings PluginSettings `json:&amp;quot;Settings&amp;quot;`
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意其中有一个&lt;code&gt;PluginReference&lt;/code&gt;结构体，它的方法有：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;type pluginReference struct {
	name     reference.Named
	pluginID digest.Digest
}

func (r *pluginReference) References(id digest.Digest) []reference.Named {
	if r.pluginID != id {
		return nil
	}
	return []reference.Named{r.name}
}

func (r *pluginReference) ReferencesByName(ref reference.Named) []refstore.Association {
	return []refstore.Association{
		{
			Ref: r.name,
			ID:  r.pluginID,
		},
	}
}

func (r *pluginReference) Get(ref reference.Named) (digest.Digest, error) {
	if r.name.String() != ref.String() {
		return digest.Digest(&amp;quot;&amp;quot;), refstore.ErrDoesNotExist
	}
	return r.pluginID, nil
}

func (r *pluginReference) AddTag(ref reference.Named, id digest.Digest, force bool) error {
	// Read only, ignore
	return nil
}
func (r *pluginReference) AddDigest(ref reference.Canonical, id digest.Digest, force bool) error {
	// Read only, ignore
	return nil
}
func (r *pluginReference) Delete(ref reference.Named) (bool, error) {
	// Read only, ignore
	return false, nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意其中有三个方法&lt;code&gt;AddTag&lt;/code&gt;、&lt;code&gt;AddDigest&lt;/code&gt;、&lt;code&gt;Delete&lt;/code&gt;方法都是只读的。在&lt;code&gt;migrate/v1/migratev1.go&lt;/code&gt;中有引用到了这个。&lt;/p&gt;

&lt;p&gt;再看下&lt;strong&gt;Reference&lt;/strong&gt;的的定义（vendor/github.com/docker/distribution/reference/reference.go）&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;// Package reference provides a general type to represent any way of referencing images within the registry.
// Its main purpose is to abstract tags and digests (content-addressable hash).
//
// Grammar
//
// 	reference                       := name [ &amp;quot;:&amp;quot; tag ] [ &amp;quot;@&amp;quot; digest ]
//	name                            := [domain &#39;/&#39;] path-component [&#39;/&#39; path-component]*
//	domain                          := domain-component [&#39;.&#39; domain-component]* [&#39;:&#39; port-number]
//	domain-component                := /([a-zA-Z0-9]|[a-zA-Z0-9][a-zA-Z0-9-]*[a-zA-Z0-9])/
//	port-number                     := /[0-9]+/
//	path-component                  := alpha-numeric [separator alpha-numeric]*
// 	alpha-numeric                   := /[a-z0-9]+/
//	separator                       := /[_.]|__|[-]*/
//
//	tag                             := /[\w][\w.-]{0,127}/
//
//	digest                          := digest-algorithm &amp;quot;:&amp;quot; digest-hex
//	digest-algorithm                := digest-algorithm-component [ digest-algorithm-separator digest-algorithm-component ]
//	digest-algorithm-separator      := /[+.-_]/
//	digest-algorithm-component      := /[A-Za-z][A-Za-z0-9]*/
//	digest-hex                      := /[0-9a-fA-F]{32,}/ ; At least 128 bit digest value
//
//	identifier                      := /[a-f0-9]{64}/
//	short-identifier                := /[a-f0-9]{6,64}/
// Reference is an opaque object reference identifier that may include
// modifiers such as a hostname, name, tag, and digest.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;修改plugin的名字的方法是不是还没实现？&lt;/p&gt;

&lt;h2 id=&#34;解决方法&#34;&gt;解决方法&lt;/h2&gt;

&lt;p&gt;在代码存在bug的情况下，可以先用下面的方法暂时创建plugin。&lt;/p&gt;

&lt;p&gt;虽然docker代码里没有提供&lt;strong&gt;rename plugin&lt;/strong&gt;的接口，但是使用&lt;strong&gt;docker install&lt;/strong&gt;命令安装的plugin会存储在&lt;code&gt;/var/lib/docker/plugins/${PLUGIN_ID}&lt;/code&gt;目录下。&lt;/p&gt;

&lt;p&gt;可以在这个目录下使用&lt;strong&gt;docker plugin create&lt;/strong&gt;命令创建你自己想要的名称的docker plugin。&lt;/p&gt;

&lt;p&gt;使用&lt;code&gt;docker plugin set&lt;/code&gt;命令修改plugin中的属性:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;cluster_store&lt;/li&gt;
&lt;li&gt;plugin_role&lt;/li&gt;
&lt;li&gt;plugin_name&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;插件调试&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;日志地址&lt;code&gt;/run/contiv/log/&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;从非master节点的netplugin启动日志&lt;code&gt;netplugin_bootup.log&lt;/code&gt;中可以看到：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;V2 Plugin logs
Loading OVS
Starting OVS
Starting Netplugin 
/netplugin -debug -plugin-mode docker -vlan-if  -cluster-store etcd://172.20.0.113:2379  
Not starting netmaster as plugin role is none
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Netplugin启动的时候是正确的解析了&lt;strong&gt;etcd&lt;/strong&gt;的配置了。&lt;/p&gt;

&lt;p&gt;但是我们再看一下&lt;code&gt;netplugin.log&lt;/code&gt;的日志后就会发现，启动还是失败了。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;time=&amp;quot;Mar 21 03:20:37.537954358&amp;quot; level=debug msg=&amp;quot;Got link list(16): [0xc4203fe200 0xc4203fe300 0xc4203fe400 0xc4203fe500 0xc420420000 0xc420420090 0xc420420120 0xc4204201b0 0xc420420240 0xc4204202d0 0xc420420360 0xc4204203f0 0xc420420480 0xc420420510 0xc4203feb80 0xc4203fec80]&amp;quot;
time=&amp;quot;Mar 21 03:20:37.538576647&amp;quot; level=error msg=&amp;quot;Failed to connect to etcd. Err: client: etcd cluster is unavailable or misconfigured&amp;quot;
time=&amp;quot;Mar 21 03:20:37.538599827&amp;quot; level=error msg=&amp;quot;Error creating client etcd to url 127.0.0.1:2379. Err: client: etcd cluster is unavailable or misconfigured&amp;quot;
time=&amp;quot;Mar 21 03:20:37.538612813&amp;quot; level=fatal msg=&amp;quot;Error initializing cluster. Err: client: etcd cluster is unavailable or misconfigured&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;netplugin&lt;/code&gt;没有正确的解析etcd的地址。这到底是为什么呢？bootup的日志里不是写的解析到了吗？这个问题还得研究下源码，也许是一个bug。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker17.03-CE插件开发-举个🌰</title>
      <link>http://rootsongjc.github.io/blogs/docker-plugin-develop/</link>
      <pubDate>Wed, 15 Mar 2017 13:57:26 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/docker-plugin-develop/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20161016022.jpg&#34; alt=&#34;杭州吴山&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：杭州吴山步道旁的墙壁 Oct 16,2016）&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;当你看到这篇文章时，如果你也正在进行docker1.13+版本下的plugin开发，恭喜你也入坑了，如果你趟出坑，麻烦告诉你的方法，感恩不尽🙏&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;看了文章后你可能会觉得，官网上的可能是个假🌰。&lt;strong&gt;虽然官网上的文档写的有点不对，不过你使用docker-ssh-volume的开源代码自己去构建plugin的还是可以成功的！&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;docker-plugin开发文档&#34;&gt;Docker plugin开发文档&lt;/h3&gt;

&lt;p&gt;首先docker官方给出了一个&lt;a href=&#34;https://docs.docker.com/engine/extend/legacy_plugins/&#34;&gt;docker legacy plugin文档&lt;/a&gt;，这篇文章基本就是告诉你docker目前支持哪些插件，罗列了一系列连接，不过对不起，这些不是docker官方插件，有问题去找它们的开发者去吧😂&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Docker plugin貌似开始使用了新的v2 plugin了，legacy版本的plugin可以能在后期被废弃。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;从docker的源码&lt;strong&gt;plugin/store.go&lt;/strong&gt;中可以看到：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;/* allowV1PluginsFallback determines daemon&#39;s support for V1 plugins.
 * When the time comes to remove support for V1 plugins, flipping
 * this bool is all that will be needed.
 */
const allowV1PluginsFallback bool = true

/* defaultAPIVersion is the version of the plugin API for volume, network,
   IPAM and authz. This is a very stable API. When we update this API, then
   pluginType should include a version. e.g. &amp;quot;networkdriver/2.0&amp;quot;.
*/
const defaultAPIVersion string = &amp;quot;1.0&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;随着docker公司是的战略调整，推出了docker-CE和docker-EE之后，未来有些插件就可能要收费了，v2版本的插件都是在docker store中下载了，而这种插件在创建的时候都是打包成docker image，如果不开放源码的话，你即使pull下来插件也无法修改和导出的，&lt;strong&gt;docker plugin目前没有导出接口&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;真正要开发一个docker plugin还是得看&lt;a href=&#34;https://docs.docker.com/engine/extend/plugin_api/&#34;&gt;docker plugin API&lt;/a&gt;，这篇文档告诉我们：&lt;/p&gt;

&lt;h4 id=&#34;插件发现&#34;&gt;插件发现&lt;/h4&gt;

&lt;p&gt;当你开发好一个插件&lt;strong&gt;docker engine&lt;/strong&gt;怎么才能发现它们呢？有三种方式：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;.sock&lt;/strong&gt;，linux下放在/run/docker/plugins目录下，或该目录下的子目录比如&lt;a href=&#34;https://github.com/ClusterHQ/flocker&#34;&gt;flocker&lt;/a&gt;插件的&lt;code&gt;.sock&lt;/code&gt;文件放在&lt;code&gt;/run/docker/plugins/flocker/flocker.sock&lt;/code&gt;下&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;.spec&lt;/strong&gt;，比如&lt;strong&gt;convoy&lt;/strong&gt;插件在&lt;code&gt;/etc/docker/plugins/convoy.spec&lt;/code&gt;定义，内容为&lt;code&gt;unix:///var/run/convoy/convoy.sock&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;.json&lt;/strong&gt;，比如&lt;strong&gt;infinit&lt;/strong&gt;插件在&lt;code&gt;/usr/lib/docker/plugins/infinit.json&lt;/code&gt;定义，内容为&lt;code&gt;{&amp;quot;Addr&amp;quot;:&amp;quot;https://infinit.sh&amp;quot;,&amp;quot;Name&amp;quot;:&amp;quot;infinit&amp;quot;}&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;文章中的其它部分&lt;strong&gt;貌似都过时&lt;/strong&gt;了，新的插件不是作为&lt;strong&gt;systemd&lt;/strong&gt;进程运行的，而是完全通过&lt;strong&gt;docker plugin&lt;/strong&gt;命令来管理的。&lt;/p&gt;

&lt;p&gt;当你使用&lt;strong&gt;docker plugin enable &lt;plugin_name&gt;&lt;/strong&gt;来激活了插件后，理应在&lt;code&gt;/run/docker/plugins&lt;/code&gt;目录下生成插件的&lt;code&gt;.sock&lt;/code&gt;文件，但是现在只有一个以runc ID命名的目录，这个问题下面有详细的叙述过程，你也可以跳过，直接看&lt;a href=&#34;https://github.com/docker/docker/issues/31723&#34;&gt;issue-31723&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/engine/extend/&#34;&gt;docker plugin管理&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;创建sshfs-volume-plugin&#34;&gt;创建sshfs volume plugin&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/docker/docker/blob/17.03.x/docs/extend/index.md#developing-a-plugin&#34;&gt;官方示例文档&lt;/a&gt;（这个文档有问题）&lt;a href=&#34;https://github.com/docker/docker/issues/29886&#34;&gt;docker-issue29886&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;官方以开发一个&lt;strong&gt;sshfs&lt;/strong&gt;的volume plugin为例。&lt;/p&gt;

&lt;p&gt;执行&lt;code&gt;docker plugin create&lt;/code&gt;命令的目录下必须包含以下内容：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;config.json&lt;/strong&gt;文件，里面是插件的配置信息，&lt;a href=&#34;https://github.com/docker/docker/blob/17.03.x/docs/extend/config.md&#34;&gt;plugin config参考文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;rootfs&lt;/strong&gt;目录，插件镜像解压后的目录。v2版本的docker plugin都是以docker镜像的方式包装的。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/vieux/docker-volume-sshfs
$ cd docker-volume-sshfs
$ go get github.com/docker/go-plugins-helpers/volume
$ go build -o docker-volume-sshfs main.go  
$ docker build -t rootfsimage .
$ id=$(docker create rootfsimage true) # id was cd851ce43a403 when the image was created
$ sudo mkdir -p myplugin/rootfs
$ sudo docker export &amp;quot;$id&amp;quot; | sudo tar -x -C myplugin/rootfs
$ docker rm -vf &amp;quot;$id&amp;quot;
$ docker rmi rootfsimage
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们可以看到&lt;strong&gt;sshfs&lt;/strong&gt;的Dockerfile是这样的：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Dockerfile&#34;&gt;FROM alpine

RUN apk update &amp;amp;&amp;amp; apk add sshfs

RUN mkdir -p /run/docker/plugins /mnt/state /mnt/volumes

COPY docker-volume-sshfs docker-volume-sshfs

CMD [&amp;quot;docker-volume-sshfs&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实际上是编译好的可执行文件复制到alpine linux容器中运行。&lt;/p&gt;

&lt;p&gt;编译rootfsimage镜像的过程。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker build -t rootfsimage .
Sending build context to Docker daemon 11.71 MB
Step 1/5 : FROM alpine
 ---&amp;gt; 4a415e366388
Step 2/5 : RUN apk update &amp;amp;&amp;amp; apk add sshfs
 ---&amp;gt; Running in 1551ecc1c847
fetch http://dl-cdn.alpinelinux.org/alpine/v3.5/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.5/community/x86_64/APKINDEX.tar.gz
v3.5.2-2-ge626ce8c3c [http://dl-cdn.alpinelinux.org/alpine/v3.5/main]
v3.5.1-71-gc7bb9a04f0 [http://dl-cdn.alpinelinux.org/alpine/v3.5/community]
OK: 7959 distinct packages available
(1/10) Installing openssh-client (7.4_p1-r0)
(2/10) Installing fuse (2.9.7-r0)
(3/10) Installing libffi (3.2.1-r2)
(4/10) Installing libintl (0.19.8.1-r0)
(5/10) Installing libuuid (2.28.2-r1)
(6/10) Installing libblkid (2.28.2-r1)
(7/10) Installing libmount (2.28.2-r1)
(8/10) Installing pcre (8.39-r0)
(9/10) Installing glib (2.50.2-r0)
(10/10) Installing sshfs (2.8-r0)
Executing busybox-1.25.1-r0.trigger
Executing glib-2.50.2-r0.trigger
OK: 11 MiB in 21 packages
 ---&amp;gt; 1a73c501f431
Removing intermediate container 1551ecc1c847
Step 3/5 : RUN mkdir -p /run/docker/plugins /mnt/state /mnt/volumes
 ---&amp;gt; Running in 032af3b2595a
 ---&amp;gt; 30c7e8463e96
Removing intermediate container 032af3b2595a
Step 4/5 : COPY docker-volume-sshfs docker-volume-sshfs
 ---&amp;gt; a924c6fcc1e4
Removing intermediate container ffc5e3c97707
Step 5/5 : CMD docker-volume-sshfs
 ---&amp;gt; Running in 0dc938fe4f4e
 ---&amp;gt; 0fd2e3d94860
Removing intermediate container 0dc938fe4f4e
Successfully built 0fd2e3d94860
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;编写&lt;code&gt;config.json&lt;/code&gt;文档&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Json&#34;&gt;{
    &amp;quot;description&amp;quot;: &amp;quot;sshFS plugin for Docker&amp;quot;,
    &amp;quot;documentation&amp;quot;: &amp;quot;https://docs.docker.com/engine/extend/plugins/&amp;quot;,
    &amp;quot;entrypoint&amp;quot;: [
        &amp;quot;/docker-volume-sshfs&amp;quot;
    ],
    &amp;quot;env&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;DEBUG&amp;quot;,
            &amp;quot;settable&amp;quot;: [
                &amp;quot;value&amp;quot;
            ],
            &amp;quot;value&amp;quot;: &amp;quot;0&amp;quot;
        }
    ],
    &amp;quot;interface&amp;quot;: {
        &amp;quot;socket&amp;quot;: &amp;quot;sshfs.sock&amp;quot;,
        &amp;quot;types&amp;quot;: [
            &amp;quot;docker.volumedriver/1.0&amp;quot;
        ]
    },
    &amp;quot;linux&amp;quot;: {
        &amp;quot;capabilities&amp;quot;: [
            &amp;quot;CAP_SYS_ADMIN&amp;quot;
        ],
        &amp;quot;devices&amp;quot;: [
            {
                &amp;quot;path&amp;quot;: &amp;quot;/dev/fuse&amp;quot;
            }
        ]
    },
    &amp;quot;mounts&amp;quot;: [
        {
            &amp;quot;destination&amp;quot;: &amp;quot;/mnt/state&amp;quot;,
            &amp;quot;options&amp;quot;: [
                &amp;quot;rbind&amp;quot;
            ],
            &amp;quot;source&amp;quot;: &amp;quot;/var/lib/docker/plugins/&amp;quot;,
            &amp;quot;type&amp;quot;: &amp;quot;bind&amp;quot;
        }
    ],
    &amp;quot;network&amp;quot;: {
        &amp;quot;type&amp;quot;: &amp;quot;host&amp;quot;
    },
    &amp;quot;propagatedmount&amp;quot;: &amp;quot;/mnt/volumes&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该插件使用host网络类型，使用/run/docker/plugins/sshfs.sock接口与docker engine通信。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注意官网上的这个文档有问题，config.json与代码里的不符，尤其是Entrypoint的二进制文件的位置不对。&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;注意&lt;strong&gt;socket&lt;/strong&gt;配置的地址不要写详细地址，默认会在/run/docker/plugins目录下生成socket文件。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;创建plugin&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;使用&lt;code&gt;docker plugin create &amp;lt;plugin_name&amp;gt; /path/to/plugin/data/&lt;/code&gt;命令创建插件。&lt;/p&gt;

&lt;p&gt;具体到sshfs插件，在myplugin目录下使用如下命令创建插件：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker plugin create jimmmysong/sshfs:latest .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在就可以看到刚创建的插件了&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker plugin ls
ID                  NAME                 DESCRIPTION               ENABLED
8aa1f6098fca        jimmysong/sshfs:latest   sshFS plugin for Docker   true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;push plugin&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;先登录你的docker hub账户，然后使用&lt;code&gt;docker plugin push jimmysong/sshfs:latest&lt;/code&gt;即可以推送docker plugin到docker hub中。&lt;/p&gt;

&lt;p&gt;目前推送到&lt;strong&gt;harbor&lt;/strong&gt;镜像仓库有问题，报错信息：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c08c951b53b7: Preparing 
denied: requested access to the resource is denied
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;已给harbor提&lt;a href=&#34;https://github.com/vmware/harbor/issues/1532&#34;&gt;issue-1532&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;plugin的使用&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;有发现了个问题&lt;a href=&#34;https://github.com/docker/docker/issues/31723&#34;&gt;docker issue-31723&lt;/a&gt;，使用plugin创建volume的时候居然找不到&lt;code&gt;sshfs.sock&lt;/code&gt;文件！😢刚开始手动创建plugin的时候测试了下是正常的，不知道为啥弄到这台测试机器上出问题了。&lt;/p&gt;

&lt;h3 id=&#34;关于docker-plugin-enable失败的问题&#34;&gt;关于docker plugin enable失败的问题&lt;/h3&gt;

&lt;p&gt;当docker  plugin创建成功并enable的时候docker并没有报错，这与docker plugin的&lt;strong&gt;activate&lt;/strong&gt;机制有关，只有当你最终使用该plugin的时候才会激活它。&lt;/p&gt;

&lt;p&gt;使用&lt;strong&gt;sshfs&lt;/strong&gt;插件创建volume。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker volume create -d jimmysong/sshfs --name sshvolume -o sshcmd=1.2.3.4:/remote -o password=password
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;报错如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error response from daemon: create sshvolume: Post http://%2Frun%2Fdocker%2Fplugins%2F8f7b8f931b38a4ef53d0e4f8d738e26e8f10ef8bd26c8244f4b8dcc7276b685f%2Fsshfs.sock/VolumeDriver.Create: dial unix /run/docker/plugins/8f7b8f931b38a4ef53d0e4f8d738e26e8f10ef8bd26c8244f4b8dcc7276b685f/sshfs.sock: connect: no such file or directory
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Docker daemon在enable这个插件的时候会寻找这个&lt;strong&gt;.sock&lt;/strong&gt;文件，然后在自己的plugindb中注册它，相关代码在这个文件里：&lt;a href=&#34;https://github.com/docker/docker/blob/17.03.x/plugin/manager_linux.go&#34;&gt;https://github.com/docker/docker/blob/17.03.x/plugin/manager_linux.go&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;相关代码片段：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;func (pm *Manager) enable(p *v2.Plugin, c *controller, force bool) error {
	...
	return pm.pluginPostStart(p, c)
}

func (pm *Manager) pluginPostStart(p *v2.Plugin, c *controller) error {
    //这里需要获取.sock文件的地址 
    //pm.conifg.ExecRoot就是/run/docker/plugins
    //p.GetID()返回的就是很长的那串plugin ID
	sockAddr := filepath.Join(pm.config.ExecRoot, p.GetID(), p.GetSocket())
	client, err := plugins.NewClientWithTimeout(&amp;quot;unix://&amp;quot;+sockAddr, nil, c.timeoutInSecs)
	if err != nil {
		c.restart = false
		shutdownPlugin(p, c, pm.containerdClient)
		return errors.WithStack(err)
	}

	p.SetPClient(client)

	maxRetries := 3
	var retries int
	for {
		time.Sleep(3 * time.Second)
		retries++

		if retries &amp;gt; maxRetries {
			logrus.Debugf(&amp;quot;error net dialing plugin: %v&amp;quot;, err)
			c.restart = false
			shutdownPlugin(p, c, pm.containerdClient)
			return err
		}

		// net dial into the unix socket to see if someone&#39;s listening.
		conn, err := net.Dial(&amp;quot;unix&amp;quot;, sockAddr)
		if err == nil {
			conn.Close()
			break
		}
	}
	pm.config.Store.SetState(p, true)
	pm.config.Store.CallHandler(p)

	return pm.save(p)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意这段代码里的&lt;strong&gt;sockAddr := filepath.Join(pm.config.ExecRoot, p.GetID(), p.GetSocket())&lt;/strong&gt;，我在上面添加了注释。&lt;/p&gt;

&lt;p&gt;这个&lt;strong&gt;.sock&lt;/strong&gt;文件应该有docker plugin来生成，具体怎样生成的呢？还以&lt;strong&gt;docker-volume-ssh&lt;/strong&gt;这个插件为例。&lt;/p&gt;

&lt;p&gt;整个项目就一个&lt;strong&gt;main.go&lt;/strong&gt;文件，里面最后一行生成了&lt;strong&gt;/run/docker/plugins/sshfs.sock&lt;/strong&gt;这个sock。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;logrus.Error(h.ServeUnix(socketAddress, 0))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这行代码调用&lt;strong&gt;docker/go-plugin-helpers/sdk/handler.go&lt;/strong&gt;中的:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;// ServeUnix makes the handler to listen for requests in a unix socket.
// It also creates the socket file on the right directory for docker to read.
func (h Handler) ServeUnix(addr string, gid int) error {
	l, spec, err := newUnixListener(addr, gid)
	if err != nil {
		return err
	}
	if spec != &amp;quot;&amp;quot; {
		defer os.Remove(spec)
	}
	return h.Serve(l)
}

// Serve sets up the handler to serve requests on the passed in listener
func (h Handler) Serve(l net.Listener) error {
	server := http.Server{
		Addr:    l.Addr().String(),
		Handler: h.mux,
	}
	return server.Serve(l)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;//unix_listener_unsupoorted.go
func newUnixListener(pluginName string, gid int) (net.Listener, string, error) {
	return nil, &amp;quot;&amp;quot;, errOnlySupportedOnLinuxAndFreeBSD
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看了上面这这些，你看出socket文件是怎么创建的吗？&lt;/p&gt;

&lt;p&gt;这又是一个&lt;a href=&#34;https://github.com/vieux/docker-volume-sshfs/issues/19&#34;&gt;issue-19&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;如果你修改&lt;strong&gt;config.json&lt;/strong&gt;文件，将其中的&lt;strong&gt;interfaces - socket&lt;/strong&gt;指定为&lt;code&gt;/run/docker/plugins/sshfs.sock&lt;/code&gt;然后创建plugin，则能成功生成socket文件，但是当你enable它的时候又会报错&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error response from daemon: Unix socket path &amp;quot;/run/docker/plugins/ac34f7b246ac6c029023b1ebd48e166eadcdd2c9d0cc682cadca0336951d72f7/run/docker/plugins/sshfs.sock&amp;quot; is too long
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从docker daemon的日志里可以看到详细报错：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Mar 13 17:15:20 sz-pg-oam-docker-test-001.tendcloud.com dockerd[51757]: time=&amp;quot;2017-03-13T17:15:20+08:00&amp;quot; level=info msg=&amp;quot;standard_init_linux.go:178: exec user process caused \&amp;quot;no such file or directory\&amp;quot;&amp;quot; plugin=ac34f7b246ac6c029023b1ebd48e166eadcdd2c9d0cc682cadca0336951d72f7
Mar 13 17:15:20 sz-pg-oam-docker-test-001.tendcloud.com dockerd[51757]: time=&amp;quot;2017-03-13T17:15:20.321277088+08:00&amp;quot; level=error msg=&amp;quot;Sending SIGTERM to plugin failed with error: rpc error: code = 2 desc = no such process&amp;quot;
Mar 13 17:15:20 sz-pg-oam-docker-test-001.tendcloud.com dockerd[51757]: time=&amp;quot;2017-03-13T17:15:20.321488680+08:00&amp;quot; level=error msg=&amp;quot;Handler for POST /v1.26/plugins/sshfs/enable returned error: Unix socket path \&amp;quot;/run/docker/plugins/ac34f7b246ac6c029023b1ebd48e166eadcdd2c9d0cc682cadca0336951d72f7/run/docker/plugins/sshfs.sock\&amp;quot; is too long\ngithub.com/docker/docker/plugin.(*Manager).pluginPostStart\n\t/root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/plugin/manager_linux.go:84\ngithub.com/docker/docker/plugin.(*Manager).enable\n\t/root/rpmbuild/BUILD/docker-
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正好验证了上面的&lt;strong&gt;enable&lt;/strong&gt;代码，docker默认是到&lt;code&gt;/run/docker/plugins&lt;/code&gt;目录下找&lt;strong&gt;sshfs.sock&lt;/strong&gt;这个文件的。&lt;/p&gt;

&lt;p&gt;我在docker daemon中发现一个很诡异的错误，&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Mar 13 17:29:41 sz-pg-oam-docker-test-001.tendcloud.com dockerd[51757]: time=&amp;quot;2017-03-13T17:29:41+08:00&amp;quot; level=info msg=&amp;quot;standard_init_linux.go:178: exec user process caused \&amp;quot;no such file or directory\&amp;quot;&amp;quot; plugin=85760810b4850009fc965f5c20d8534dc9aba085340a2ac0b4b9167a6fef7d53
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我查看了下&lt;code&gt;github.com/libnetwork/vendor/github.com/opencontainers/run/libcontainer/standard_init_linux.go&lt;/code&gt;文件，这个那个文件只有114行，见这里&lt;a href=&#34;https://github.com/docker/libnetwork/blob/master/vendor/github.com/opencontainers/runc/libcontainer/standard_init_linux.go&#34;&gt;https://github.com/docker/libnetwork/blob/master/vendor/github.com/opencontainers/runc/libcontainer/standard_init_linux.go&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;但是在&lt;strong&gt;opencontainers&lt;/strong&gt;的github项目里才有那么多行，见这里：&lt;a href=&#34;https://github.com/opencontainers/runc/blob/master/libcontainer/standard_init_linux.go&#34;&gt;https://github.com/opencontainers/runc/blob/master/libcontainer/standard_init_linux.go&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这个报错前后的函数是：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;// PR_SET_NO_NEW_PRIVS isn&#39;t exposed in Golang so we define it ourselves copying the value
// the kernel
const PR_SET_NO_NEW_PRIVS = 0x26

func (l *linuxStandardInit) Init() error {
	if !l.config.Config.NoNewKeyring {
		ringname, keepperms, newperms := l.getSessionRingParams()

		// do not inherit the parent&#39;s session keyring
		sessKeyId, err := keys.JoinSessionKeyring(ringname)
		if err != nil {
			return err
		}
		// make session keyring searcheable
		if err := keys.ModKeyringPerm(sessKeyId, keepperms, newperms); err != nil {
			return err
		}
	}

...
	}
	if l.config.Config.Seccomp != nil &amp;amp;&amp;amp; l.config.NoNewPrivileges {
         //下面这行是第178行
		if err := seccomp.InitSeccomp(l.config.Config.Seccomp); err != nil {
			return newSystemErrorWithCause(err, &amp;quot;init seccomp&amp;quot;)
		}
	}
	// close the statedir fd before exec because the kernel resets dumpable in the wrong order
	// https://github.com/torvalds/linux/blob/v4.9/fs/exec.c#L1290-L1318
	syscall.Close(l.stateDirFD)
	if err := syscall.Exec(name, l.config.Args[0:], os.Environ()); err != nil {
		return newSystemErrorWithCause(err, &amp;quot;exec user process&amp;quot;)
	}
	return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;结论&#34;&gt;&lt;del&gt;结论&lt;/del&gt;&lt;/h2&gt;

&lt;p&gt;&lt;del&gt;到此了问题还没解决。&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;问题的关键是执行&lt;strong&gt;docker create plugin&lt;/strong&gt;之后&lt;strong&gt;.sock&lt;/strong&gt;文件创建到哪里去了？为什么在&lt;strong&gt;config.json&lt;/strong&gt;指定成&lt;code&gt;/run/docker/plugins/sshfs.sock&lt;/code&gt;就可以在指定的目录下创建出.sock文件，说明&lt;strong&gt;创建socket的定义和get socket时寻找的路径不一样&lt;/strong&gt;，创建socket时就是固定在/run/docker/plugins目录下创建，而enable plugin的时候，Get socket的时候还要加上docker plugin的ID，可是按照官网的配置在本地create plugin后并没有在/run/docker/plugins目录下生成插件的socket文件，直到enable插件的时候才会生成以plugin ID命名的目录，但是socket文件没有！☹️&lt;/del&gt;&lt;/p&gt;

&lt;h2 id=&#34;问题解决&#34;&gt;问题解决&lt;/h2&gt;

&lt;p&gt;之所以出现上面的那些问题，是因为create docker plugin的时候有问题，也就是那个二进制文件有问题，我在&lt;strong&gt;Mac&lt;/strong&gt;上build的image，而且还没有用&lt;strong&gt;Dockerfile.dev&lt;/strong&gt;这个专门用来搭建二进制文件编译环境的Dockerfile来创建golang的编译环境，虽然docker plugin是创建成功了，但是当docker plugin enable的时候，这个热紧张文件不能正确的运行，所以就没能生成&lt;strong&gt;sshfs.sock&lt;/strong&gt;文件。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;请在Linux环境下使用&lt;strong&gt;make all&lt;/strong&gt;命令来创建plugin。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Docker 17.03-CE create plugin源码解析</title>
      <link>http://rootsongjc.github.io/blogs/docker-create-plugin/</link>
      <pubDate>Wed, 15 Mar 2017 12:09:26 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/docker-create-plugin/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20160403050.jpg&#34; alt=&#34;故宫博物院&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：故宫 Apr 3,2016）&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;继续上一篇&lt;a href=&#34;http://rootsongjc.github.io/blogs/docker-plugin-develop/&#34;&gt;Docker17.03-CE插件开发的🌰&lt;/a&gt;，今天来看下&lt;strong&gt;docker create plugin&lt;/strong&gt;的源码。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;cli/command/plugin/create.go&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Docker命令行&lt;code&gt;docker plugin create&lt;/code&gt;调用的，使用的是&lt;a href=&#34;http://github.com/spf13/cobra&#34;&gt;cobra&lt;/a&gt;，这个命令行工具开发包很好用，推荐下。&lt;/p&gt;

&lt;p&gt;执行这两个函数&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func newCreateCommand(dockerCli *command.DockerCli) *cobra.Command 
//调用下面的函数，拼装成URL调用RESTful API接口
func runCreate(dockerCli *command.DockerCli, options pluginCreateOptions) error {
  ...
  if err = dockerCli.Client().PluginCreate(ctx, createCtx, createOptions); err != nil {
		return err
	}
  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在&lt;strong&gt;api/server/router/plugin/plugin_routes.go&lt;/strong&gt;中&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (pr *pluginRouter) createPlugin(ctx context.Context, w http.ResponseWriter, r *http.Request, vars map[string]string) error {
  ...
  if err := pr.backend.CreateFromContext(ctx, r.Body, options); err != nil {
		return err
	}
  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;createPlugin&lt;/strong&gt;这个方法定义在api/server/route/plugin/backen.go的&lt;strong&gt;Backend&lt;/strong&gt;接口中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PluginCreate&lt;/strong&gt;这个方法定义在docker/docker/client/Interface.go的&lt;strong&gt;PluginAPIClient&lt;/strong&gt;接口中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;docker/client/plugin_create.go&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// PluginCreate creates a plugin
func (cli *Client) PluginCreate(ctx context.Context, createContext io.Reader, createOptions types.PluginCreateOptions) error {
	headers := http.Header(make(map[string][]string))
	headers.Set(&amp;quot;Content-Type&amp;quot;, &amp;quot;application/x-tar&amp;quot;)

	query := url.Values{}
	query.Set(&amp;quot;name&amp;quot;, createOptions.RepoName)

	resp, err := cli.postRaw(ctx, &amp;quot;/plugins/create&amp;quot;, query, createContext, headers)
	if err != nil {
		return err
	}
	ensureReaderClosed(resp)
	return err
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;plugin在后端接收到请求后会执行下面的方法。最终&lt;strong&gt;create plugin&lt;/strong&gt;的实现在plugin/backend_linux.go下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// CreateFromContext creates a plugin from the given pluginDir which contains
// both the rootfs and the config.json and a repoName with optional tag.
func (pm *Manager) CreateFromContext(ctx context.Context, tarCtx io.ReadCloser, options *types.PluginCreateOptions) (err error) {}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至于docker create plugin时docker后台究竟做了什么，就看👆那个文件。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker v.s Kubernetes part2</title>
      <link>http://rootsongjc.github.io/blogs/docker-vs-kubernetes-part2/</link>
      <pubDate>Fri, 10 Mar 2017 22:06:32 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/docker-vs-kubernetes-part2/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20160709044.jpg&#34; alt=&#34;承德兴隆星空&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：河北承德兴隆县雾灵山京郊最佳星空拍摄点 July 9,2016)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;本文是&lt;code&gt;Docker v.s Kubernetes&lt;/code&gt;第二篇，续接上文&lt;a href=&#34;http://rootsongjc.github.io/blogs/docker-vs-kubernetes-part1/&#34;&gt;Docker v.s Kuberntes Part1&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;Kubernetes是典型的&lt;strong&gt;Master/Slave&lt;/strong&gt;架构模式，本文简要的介绍kubenetes的架构和组件构成。&lt;/p&gt;

&lt;h2 id=&#34;kubernetes核心架构&#34;&gt;Kubernetes核心架构&lt;/h2&gt;

&lt;h3 id=&#34;master节点&#34;&gt;master节点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;apiserver：作为kubernetes系统的入口，封装了核心对象的增删改查操作，以RESTFul接口方式提供给外部客户和内部组件调用。它维护的REST对象将持久化到etcd（一个分布式强一致性的key/value存储）。&lt;/li&gt;
&lt;li&gt;scheduler：负责集群的资源调度，为新建的Pod分配机器。这部分工作分出来变成一个组件，意味着可以很方便地替换成其他的调度器。&lt;/li&gt;
&lt;li&gt;controller-manager：负责执行各种控制器，目前有两类：

&lt;ol&gt;
&lt;li&gt;endpoint-controller：定期关联service和Pod(关联信息由endpoint对象维护)，保证service到Pod的映射总是最新的。&lt;/li&gt;
&lt;li&gt;replication-controller：定期关联replicationController和Pod，保证replicationController定义的复制数量与实际运行Pod的数量总是一致的。&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;node节点&#34;&gt;node节点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;kubelet：负责管控docker容器，如启动/停止、监控运行状态等。它会定期从etcd获取分配到本机的Pod，并根据Pod信息启动或停止相应的容器。同时，它也会接收apiserver的HTTP请求，汇报Pod的运行状态。&lt;/li&gt;
&lt;li&gt;proxy：负责为Pod提供代理。它会定期从etcd获取所有的service，并根据service信息创建代理。当某个客户Pod要访问其他Pod时，访问请求会经过本机proxy做转发。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://valleylord.github.io/images/201601-kubernetes-concepts/kubernetes-masterslave.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;kubernetes组件详细介绍&#34;&gt;Kubernetes组件详细介绍&lt;/h2&gt;

&lt;h3 id=&#34;etcd&#34;&gt;etcd&lt;/h3&gt;

&lt;p&gt;虽然不是Kubernetes的组件但是有必要提一下，etcd是一个分布式协同数据库，基于Go语言开发，&lt;code&gt;CoreOS&lt;/code&gt;公司出品，使用&lt;a href=&#34;http://rootsongjc.github.io/blogs/raft/&#34;&gt;raft一致性算法&lt;/a&gt;协同。Kubernetes的主数据库，在安装kubernetes之前就要先安装它，很多开源下项目都用到，老版本的&lt;code&gt;docker swarm&lt;/code&gt;也用到了它。目前主要使用的是&lt;code&gt;2.7.x&lt;/code&gt;版本，&lt;code&gt;3.0+&lt;/code&gt;版本的API变化太大。&lt;/p&gt;

&lt;h3 id=&#34;apiserver&#34;&gt;APIServer&lt;/h3&gt;

&lt;p&gt;APIServer负责对外提供kubernetes API服务，它运行在master节点上。任何对资源的增删改查都要交给APIServer处理后才能提交给etcd。APIServer总体上由两部分组成：HTTP/HTTPS服务和一些功能性插件。这些功能性插件又分为两种：一部分与底层IaaS平台（Cloud Provide）相关；另一部分与资源管理控制（Admission Control）相关。&lt;/p&gt;

&lt;h3 id=&#34;scheduler&#34;&gt;Scheduler&lt;/h3&gt;

&lt;p&gt;Scheduler的作用是&lt;strong&gt;根据特定的调度算法将pod调度到node节点上&lt;/strong&gt;，这一过程也被称为绑定。Scheduler调度器的输入是待调度的pod和可用的工作节点列表，输出则是一个已经绑定了pod的节点，这个节点是通过调度算法在工作节点列表中选择的最优节点。&lt;/p&gt;

&lt;p&gt;工作节点从哪里来？工作节点并不是由Kubernetes创建，它是由IaaS平台创建，或者就是由用户管理的物理机或者虚拟机。但是Kubernetes会创建一个Node对象，用来描述这个工作节点。描述的具体信息由创建Node对象的配置文件给出。一旦用户创建节点的请求被成功处理，Kubernetes又会立即在内部创建一个node对象，再去检查该节点的健康状况。只有那些当前可用的node才会被认为是一个有效的节点并允许pod调度到上面运行。&lt;/p&gt;

&lt;p&gt;工作节点可以通过资源配置文件或者kubectl命令行工具来创建。Kubernetes主要维护工作节点的两个属性：spec和status来描述一个工作节点的期望状态和当前状态。其中，所谓的当前状态信息由3个信息组成：&lt;code&gt;HostIp&lt;/code&gt;、&lt;code&gt;NodePhase&lt;/code&gt;和&lt;code&gt;Node Condition&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;工作节点的动态维护过程依靠&lt;strong&gt;Node Controller&lt;/strong&gt;来完成，它是&lt;code&gt;Kubernetes Controller Manager&lt;/code&gt;下属的一个控制器。它会一直不断的检查Kubernetes已知的每台node节点是否正常工作，如果一个之前已经失败的节点在这个检查循环中被检查为可以工作的，那么Node Controller会把这个节点添加到工作节点中，Node Controller会从工作节点中删除这个节点。&lt;/p&gt;

&lt;h3 id=&#34;controller-manager&#34;&gt;Controller Manager&lt;/h3&gt;

&lt;p&gt;Controller Manager运行在集群的Master节点上，是基于pod API的一个独立服务，它&lt;strong&gt;重点实现service Endpoint（服务端点）的动态更新&lt;/strong&gt;。管理着Kubernetes集群中各种控制节点，包括&lt;strong&gt;replication Controller&lt;/strong&gt;和&lt;strong&gt;node Controller&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;与APIServer相比，APIServer负责接受用户请求并创建对应的资源，而Controller Manager在系统中扮演的角色是在一旁旁默默的管控这些资源，确保他们永远保持在预期的状态&lt;/strong&gt;。它采用各种管理器定时的对pod、节点等资源进行预设的检查，然后判断出于预期的是否一致，若不一致，则通知APIServer采取行动，比如重启、迁移、删除等。&lt;/p&gt;

&lt;h3 id=&#34;kubelet&#34;&gt;kubelet&lt;/h3&gt;

&lt;p&gt;kubelet组件工作在Kubernetes的node上，&lt;strong&gt;负责管理和维护在这台主机上运行着的所有容器&lt;/strong&gt;。 kubelet与cAdvisor交互来抓取docker容器和主机的资源信息。 kubelet垃圾回收机制，包括容器垃圾回收和镜像垃圾回收。 kubelet工作节点状态同步。&lt;/p&gt;

&lt;h3 id=&#34;kube-proxy&#34;&gt;kube-proxy&lt;/h3&gt;

&lt;p&gt;kube-proxy提供两种功能:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;提供算法将客服端流量负载均衡到service对应的一组后端pod。&lt;/li&gt;
&lt;li&gt;使用etcd的watch机制，实现服务发现功能，维护一张从service到endpoint的映射关系，从而保证后端pod的IP变化不会对访问者的访问造成影响。&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Docker v.s Kubernetes part1</title>
      <link>http://rootsongjc.github.io/blogs/docker-vs-kubernetes-part1/</link>
      <pubDate>Fri, 10 Mar 2017 21:09:47 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/docker-vs-kubernetes-part1/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20161016031.jpg&#34; alt=&#34;杭州西湖&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：杭州西湖 Oct 16,2016）&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;前言&#34;&gt;前言&lt;/h3&gt;

&lt;p&gt;这一系列文章是对比kubernetes 和docker两者之间的差异，鉴于我之前从docker1.10.3起开始使用docker，对原生docker的了解比较多，最近又正在看&lt;strong&gt;Kunernetes权威指南（第二版）&lt;/strong&gt;这本书（P.S感谢&lt;u&gt;电子工业出版社&lt;/u&gt;的编辑朋友赠送此书）。这系列文章不是为了比较孰优孰劣，&lt;strong&gt;适合自己的才是最好的&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;此系列文章中所说的&lt;strong&gt;docker&lt;/strong&gt;指的是*17.03-ce*版本。&lt;/p&gt;

&lt;h3 id=&#34;概念性的差别&#34;&gt;概念性的差别&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;了解一样东西首先要高屋建瓴的了解它的概念，kubernetes包括以下几种资源对象：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/abstractions/pod/&#34;&gt;Pod&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Service&lt;/li&gt;
&lt;li&gt;Volume&lt;/li&gt;
&lt;li&gt;Namespace&lt;/li&gt;
&lt;li&gt;ReplicaSet&lt;/li&gt;
&lt;li&gt;Deployment&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/abstractions/controllers/statefulsets/&#34;&gt;StatefulSet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;DaemonSet&lt;/li&gt;
&lt;li&gt;Job&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Docker&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Docker的资源对象相对于kubernetes来说就简单多了，只有以下几个：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Service&lt;/li&gt;
&lt;li&gt;Node&lt;/li&gt;
&lt;li&gt;Stack&lt;/li&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;就这么简单，使用一个*docker-compose.yml*即可以启动一系列服务。当然简单的好处是便于理解和管理，但是在功能方面就没有kubernetes那么强大了。&lt;/p&gt;

&lt;h3 id=&#34;功能性差别&#34;&gt;功能性差别&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Kubernetes 资源限制 CPU 100m千分之一核为单位，绝对值，requests 和limits，超过这个值可能被杀掉，资源限制力度比docker更细。&lt;/li&gt;
&lt;li&gt;Pod中有个最底层的pause 容器，其他业务容器共用他的IP，docker因为没有这层概念，所以没法共用IP，而是使用overlay网络同处于一个网络里来通信。&lt;/li&gt;
&lt;li&gt;Kubernetes在rc中使用环境变量传递配置（1.3版本是这样的，后续版本还没有研究过）&lt;/li&gt;
&lt;li&gt;Kuberentes Label 可以在开始和动态的添加修改，所有的资源对象都有，这一点docker也有，但是资源调度因为没有kubernetes那么层级，所有还是相对比较弱一些。&lt;/li&gt;
&lt;li&gt;Kubernetes对象选择机制继续通过label selector，用于对象调度。&lt;/li&gt;
&lt;li&gt;Kubernetes中有一个比较特别的镜像，叫做&lt;code&gt;google_containers/pause&lt;/code&gt;，这个镜像是用来实现Pod概念的。&lt;/li&gt;
&lt;li&gt;HPA horizontal pod autoscaling 横向移动扩容，也是一种资源对象，根据负载变化情况针对性的调整pod目标副本数。&lt;/li&gt;
&lt;li&gt;Kubernetes中有三个IP，Node,Pod,Cluster IP的关系比较复杂，docker中没有Cluster IP的概念。&lt;/li&gt;
&lt;li&gt;持久化存储，在Kubernetes中有Persistent volume 只能是网络存储，不属于任何node，独立于pod之外，而docker只能使用&lt;code&gt;volume plugin&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;多租户管理，kubernetes中有`Namespace，docker暂时没有多租户管理功能。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总体来说Docker架构更加简单，使用起来也没有那么多的配置，只需要每个结点都安装docker即可，调度和管理功能没kubernetes那么复杂。但是kubernetes本身就是一个通用的数据中心管理工具，不仅可以用来管理docker，*pod*这个概念里就可以运行不仅是docker了。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;以后的文章中将结合docker着重讲Kubernetes，基于1.3版本。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Contiv入坑指南-v2plugin</title>
      <link>http://rootsongjc.github.io/blogs/contiv-v2plugin/</link>
      <pubDate>Fri, 10 Mar 2017 11:51:09 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/contiv-v2plugin/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20161022082.jpg&#34; alt=&#34;上海交通大学&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(题图：上海交通大学 Oct 22,2016)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;继续趟昨天挖的坑。&lt;/p&gt;

&lt;p&gt;昨天的&lt;a href=&#34;https://github.com/contiv/netplugin/issues/776&#34;&gt;issue-776&lt;/a&gt;已经得到@gkvijay的回复，原来是因为没有安装contiv/v2plugin的缘故，所以create contiv network失败，我需要自己build一个&lt;strong&gt;docker plugin&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;查看下这个&lt;a href=&#34;https://github.com/contiv/netplugin/commit/8afd1b7718c8424a876760d18484124e0aad3557&#34;&gt;commit&lt;/a&gt;里面有build &lt;strong&gt;v2plugin&lt;/strong&gt;的脚本更改，所以直接调用以下命令就可以build自己的v2plugin。&lt;/p&gt;

&lt;p&gt;前提你需要先build出&lt;code&gt;netctl&lt;/code&gt;、&lt;code&gt;netmaster&lt;/code&gt;、&lt;code&gt;netplugin&lt;/code&gt;三个二进制文件并保存到&lt;strong&gt;bin&lt;/strong&gt;目录下，如果你没自己build直接下载&lt;strong&gt;release&lt;/strong&gt;里面的文件保存进去也行。&lt;/p&gt;

&lt;h3 id=&#34;编译v2plugin插件&#34;&gt;编译v2plugin插件&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;修改config.json插件配置文件&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Json&#34;&gt;{
    &amp;quot;manifestVersion&amp;quot;: &amp;quot;v0&amp;quot;,
    &amp;quot;description&amp;quot;: &amp;quot;Contiv network plugin for Docker&amp;quot;,
    &amp;quot;documentation&amp;quot;: &amp;quot;https://contiv.github.io&amp;quot;,
    &amp;quot;entrypoint&amp;quot;: [&amp;quot;/startcontiv.sh&amp;quot;],
    &amp;quot;network&amp;quot;: {
           &amp;quot;type&amp;quot;: &amp;quot;host&amp;quot;
    },
    &amp;quot;env&amp;quot;: [
       {
          &amp;quot;Description&amp;quot;: &amp;quot;To enable debug mode, set to &#39;-debug&#39;&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;dbg_flag&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;-debug&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;VLAN uplink interface used by OVS&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;iflist&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;Etcd or Consul cluster store url&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;cluster_store&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;etcd://172.20.0.113:2379&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;Local IP address to be used by netplugin for control communication&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;ctrl_ip&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;none&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;Local VTEP IP address to be used by netplugin&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;vtep_ip&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;none&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;In &#39;master&#39; role, plugin runs netmaster and netplugin&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;plugin_role&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;master&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;Netmaster url to listen http requests on&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;listen_url&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;172.20.0.113:9999&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;Network Driver name for requests to dockerd. Should be same as name:tag of the plugin&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;plugin_name&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;contiv/v2plugin:latest&amp;quot;
       }
    ],
    &amp;quot;mounts&amp;quot;: [
       {
          &amp;quot;type&amp;quot;: &amp;quot;bind&amp;quot;,
          &amp;quot;options&amp;quot;: [&amp;quot;rbind&amp;quot;],
          &amp;quot;source&amp;quot;: &amp;quot;/etc/openvswitch&amp;quot;,
          &amp;quot;destination&amp;quot;: &amp;quot;/etc/openvswitch&amp;quot;
       },
       {
          &amp;quot;type&amp;quot;: &amp;quot;bind&amp;quot;,
          &amp;quot;options&amp;quot;: [&amp;quot;rbind&amp;quot;],
          &amp;quot;source&amp;quot;: &amp;quot;/var/log/openvswitch&amp;quot;,
          &amp;quot;destination&amp;quot;: &amp;quot;/var/log/openvswitch&amp;quot;
       },
       {
          &amp;quot;type&amp;quot;: &amp;quot;bind&amp;quot;,
          &amp;quot;options&amp;quot;: [&amp;quot;rbind&amp;quot;],
          &amp;quot;source&amp;quot;: &amp;quot;/var/run&amp;quot;,
          &amp;quot;destination&amp;quot;: &amp;quot;/var/run&amp;quot;
       },
       {
          &amp;quot;type&amp;quot;: &amp;quot;bind&amp;quot;,
          &amp;quot;options&amp;quot;: [&amp;quot;rbind&amp;quot;],
          &amp;quot;source&amp;quot;: &amp;quot;/lib/modules&amp;quot;,
          &amp;quot;destination&amp;quot;: &amp;quot;/lib/modules&amp;quot;
       }
    ],
    &amp;quot;interface&amp;quot; : {
          &amp;quot;types&amp;quot;: [&amp;quot;docker.networkdriver/1.0&amp;quot;, &amp;quot;docker.ipamdriver/1.0&amp;quot;],
          &amp;quot;socket&amp;quot;: &amp;quot;netplugin.sock&amp;quot;
    },
    &amp;quot;Linux&amp;quot;: {
          &amp;quot;Capabilities&amp;quot;: [&amp;quot;CAP_SYS_ADMIN&amp;quot;, &amp;quot;CAP_NET_ADMIN&amp;quot;, &amp;quot;CAP_SYS_MODULE&amp;quot;]
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/docker/docker/blob/master/docs/extend/config.md&#34;&gt;关于&lt;strong&gt;docker plugin v2&lt;/strong&gt;配置文件的说明&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;方法一&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;自动化make&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$make host-pluginfs-create
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;方法二&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;直接调用Makefile里指定的那个shell脚本&lt;code&gt;scripts/v2plugin_rootfs.sh&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;$bash scripts/v2plugin_rootfs
Creating rootfs for v2plugin ,
sed: 1: &amp;quot;install/v2plugin/config ...&amp;quot;: command i expects \ followed by text
Sending build context to Docker daemon 73.94 MB
Step 1/5 : FROM alpine:3.5
 ---&amp;gt; 4a415e366388
Step 2/5 : MAINTAINER Cisco Contiv (http://contiv.github.io/)
 ---&amp;gt; Running in fada1677341b
 ---&amp;gt; f0440792dff6
Removing intermediate container fada1677341b
Step 3/5 : RUN mkdir -p /run/docker/plugins /etc/openvswitch /var/run/contiv/log     &amp;amp;&amp;amp; echo &#39;http://dl-cdn.alpinelinux.org/alpine/v3.4/main&#39; &amp;gt;&amp;gt; /etc/apk/repositories     &amp;amp;&amp;amp; apk update &amp;amp;&amp;amp; apk add openvswitch=2.5.0-r0 iptables
 ---&amp;gt; Running in 2ae2fbee6834
fetch http://dl-cdn.alpinelinux.org/alpine/v3.5/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.5/community/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.4/main/x86_64/APKINDEX.tar.gz
v3.5.2-3-g3649125268 [http://dl-cdn.alpinelinux.org/alpine/v3.5/main]
v3.5.1-71-gc7bb9a04f0 [http://dl-cdn.alpinelinux.org/alpine/v3.5/community]
v3.4.6-81-g1f1f409 [http://dl-cdn.alpinelinux.org/alpine/v3.4/main]
OK: 13194 distinct packages available
(1/6) Installing libmnl (1.0.4-r0)
(2/6) Installing libnftnl-libs (1.0.7-r0)
(3/6) Installing iptables (1.6.0-r0)
(4/6) Installing libcrypto1.0 (1.0.2k-r0)
(5/6) Installing libssl1.0 (1.0.2k-r0)
(6/6) Installing openvswitch (2.5.0-r0)
Executing busybox-1.25.1-r0.trigger
OK: 19 MiB in 17 packages
 ---&amp;gt; b130141ad660
Removing intermediate container 2ae2fbee6834
Step 4/5 : COPY netplugin netmaster netctl startcontiv.sh /
 ---&amp;gt; 2b88b2f8e5e7
Removing intermediate container d7580a394c64
Step 5/5 : ENTRYPOINT /startcontiv.sh
 ---&amp;gt; Running in e6fc5c887cb3
 ---&amp;gt; 1c569e4c633d
Removing intermediate container e6fc5c887cb3
Successfully built 1c569e4c633d
Password:
03d60dc01488362156f98a062d17af7a34e4b17569c2fe4f5d2048d619860314
Untagged: contivrootfs:latest
Deleted: sha256:1c569e4c633d27bd3e79d9d30b2825ce57452d30f90a3452304b932835331b13
Deleted: sha256:2b88b2f8e5e7bae348bf296f6254662c1d444760db5acd1764b9c955b106adad
Deleted: sha256:b60594671dc9312bf7ba73bf17abb9704d2b0d0e802c0d990315c5b4a5ca11fe
Deleted: sha256:b130141ad660d4ee291d9eb9a1e0704c4bc009fc91a73de28e8fd110aa45c481
Deleted: sha256:ab3c02d5a171681ba00d27f2c456cf8b63eeeaf408161dc84d9d89526d0399de
Deleted: sha256:f0440792dff6a89e321cc5d34ecaa21b4cb993f0c4e4df6c2b04eef8878bb471
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;创建镜像这一步需要输入你的docker hub密码。而且alpine下载软件需要翻墙的。打包v2plugin目录需要使用sudo，不然会报一个错。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;整个插件打包压缩后的大小是91M。现在&lt;code&gt;rootfs&lt;/code&gt;和&lt;code&gt;config.json&lt;/code&gt;都已经有了，就可以在你自己的系统上create docker plugin了。&lt;/p&gt;

&lt;h2 id=&#34;启动contiv-plugin&#34;&gt;启动contiv plugin&lt;/h2&gt;

&lt;p&gt;创建docker network plugin并enable。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;$docker plugin create contiv/v2plugin .
contiv/v2plugin
$docker plugin enable contiv/v2plugin
$docker plugin ls
ID                  NAME                     DESCRIPTION                        ENABLED
574d4a4d82a3        contiv/v2plugin:latest   Contiv network plugin for Docker   true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至此*contiv plugin*已经创建好了，enable后执行&lt;code&gt;ip addr&lt;/code&gt;命令可以看到多出一个网络*contivh0*。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;contivh0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UNKNOWN qlen 1000
link/ether 02:02:ac:13:ff:fe brd ff:ff:ff:ff:ff:ff
inet 172.19.255.254/16 scope global contivh0
	valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;且主机多了一个IP地址*172.19.255.254*。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;不需要再主机上安装&lt;code&gt;netctl&lt;/code&gt;、&lt;code&gt;netmaster&lt;/code&gt;、&lt;code&gt;netplugin&lt;/code&gt;这几个二进制文件了，只需要安装&lt;code&gt;docker plugin&lt;/code&gt;即可，这些都已经封装到plugin中了，如果你看下插件的目录结构就知道了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;因为插件安装的问题，目前我测试机上的自定义插件都无法使用，正在troubleshooting中，一旦有进展会及时更新该文档。&lt;/p&gt;

&lt;p&gt;另外正在同步跟开发者沟通中，因为时差问题，下周一才能有结果。😪&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Contiv入坑指南-试用全记录</title>
      <link>http://rootsongjc.github.io/blogs/contiv-tryout/</link>
      <pubDate>Thu, 09 Mar 2017 14:23:04 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/contiv-tryout/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/2017013129.jpg&#34; alt=&#34;黄昏&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(题图：山东荣成滨海风力发电场  Jan 31,2017）&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;关于contiv的介绍请看我的上一篇文章&lt;a href=&#34;http://rootsongjc.github.io/post/contiv_guide/&#34;&gt;Contiv Intro&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;开发环境使用&lt;strong&gt;Vagrant&lt;/strong&gt;搭建，昨天试用了下，真不知道它们是怎么想的，即然是docker插件为啥不直接在docker中开发呢，我有篇文章介绍&lt;a href=&#34;http://rootsongjc.github.io/post/docker-dev-env/&#34;&gt;如何搭建docker开发环境&lt;/a&gt;，可以在docker中开发docker，当然也可以用来开发contiv啊😄，只要下载一个docker镜像&lt;code&gt;dockercore/docker:latest&lt;/code&gt;即可，不过有点大2.31G，使用阿里云的mirror下载倒是也划算，总比你自己部署一个开发环境节省时间。&lt;/p&gt;

&lt;h3 id=&#34;contiv概念解析&#34;&gt;Contiv概念解析&lt;/h3&gt;

&lt;p&gt;Contiv用于给容器创建和分配网路，可以创建策略管理容器的安全、带宽、优先级等，相当于一个SDN。&lt;/p&gt;

&lt;h4 id=&#34;group&#34;&gt;Group&lt;/h4&gt;

&lt;p&gt;按容器或Pod的功能给容器分配策略组，通常是按照容器/Pod的&lt;code&gt;label&lt;/code&gt;来分组，应用组跟contiv的network不是一一对应的，可以很多应用组属于同一个network或IP subnet。&lt;/p&gt;

&lt;h4 id=&#34;polices&#34;&gt;Polices&lt;/h4&gt;

&lt;p&gt;用来限定group的行为，contiv支持两种类型的policy：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Bandwidth 限定应用组的资源使用上限&lt;/li&gt;
&lt;li&gt;Isolation 资源组的访问权限&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Group可以同时应用一个或多个policy，当有容器调度到该group里就会适用该group的policy。&lt;/p&gt;

&lt;h4 id=&#34;network&#34;&gt;Network&lt;/h4&gt;

&lt;p&gt;IPv4或IPv6网络，可以配置subnet和gateway。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Contiv中的网络&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在contiv中可以配置两种类型的网络&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;application network：容器使用的网络&lt;/li&gt;
&lt;li&gt;infrastructure network：host namespace的虚拟网络，比如基础设施监控网络&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;网络封装&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Contiv中有两种类型的网络封装&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Routed：overlay topology和L3-routed BGP topology&lt;/li&gt;
&lt;li&gt;Bridged：layer2 VLAN&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;tenant&#34;&gt;Tenant&lt;/h4&gt;

&lt;p&gt;Tenant提供contiv中的namespace隔离。一个tenant可以有很多个network，每个network都有个subnet。该tenant中的用户可以使用它的任意network和subnet的IP。&lt;/p&gt;

&lt;p&gt;物理网络中的tenant称作&lt;code&gt;虚拟路由转发(VRF)&lt;/code&gt;。Contiv使用VLAN和VXLAN ID来实现外部网络访问，这取决你使用的是layer2、layer3还是Cisco ACI。&lt;/p&gt;

&lt;h3 id=&#34;contiv下载&#34;&gt;Contiv下载&lt;/h3&gt;

&lt;p&gt;Contiv的编译安装比较复杂，我们直接下载github上的&lt;a href=&#34;[1.0.0-beta.3-03-08-2017.18-51-20.UTC](https://github.com/contiv/netplugin/releases/tag/1.0.0-beta.3-03-08-2017.18-51-20.UTC)&#34;&gt;release-1.0.0-beta.3-03-08-2017.18-51-20.UTC&lt;/a&gt;文件解压获得二进制文件安装。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/contiv/install/blob/master/README.md这个官方文档已经过时，不要看了。&#34;&gt;https://github.com/contiv/install/blob/master/README.md这个官方文档已经过时，不要看了。&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;如果试用可以的话，我会后续写contiv开发环境搭建的文章。&lt;/p&gt;

&lt;p&gt;这个release是2017年3月8日发布的，就在我写这篇文章的前一天。有个&lt;strong&gt;最重要的更新&lt;/strong&gt;是&lt;u&gt;支持docker1.13 swarm mode&lt;/u&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/contiv/netplugin/blob/master/install/HowtoSetupContiv.md&#34;&gt;官方安装文档&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;下载解压后会得到如下几个文件：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;contivk8s  k8s专用的&lt;/li&gt;
&lt;li&gt;contrib  文件夹，里面有个&lt;code&gt;netctl&lt;/code&gt;的bash脚本&lt;/li&gt;
&lt;li&gt;netcontiv  这个命令就一个-version选项用来查看contiv的版本😓&lt;/li&gt;
&lt;li&gt;netctl  contiv命令行工具，用来配置网络、策略、服务负载均衡，&lt;a href=&#34;http://contiv.github.io/documents/reference/netctlcli.html&#34;&gt;使用说明&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;netmaster  contiv的主节点服务&lt;/li&gt;
&lt;li&gt;netplugin&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面的安装中用到的只有netctl、netmaster和netplugin这三个二进制文件。&lt;/p&gt;

&lt;p&gt;我们将这三个文件都copy到/usr/bin目录下。&lt;/p&gt;

&lt;p&gt;我们在docker17.03-ce中安装contiv。&lt;/p&gt;

&lt;h3 id=&#34;contiv安装依赖&#34;&gt;Contiv安装依赖&lt;/h3&gt;

&lt;p&gt;Contiv依赖于consul或etcd，我们选择使用etcd，slack里的人说只支持2.3.x版本，可能不支持3.0+版本的吧，还没实际测过，先使用2.3.7。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;contiv master&lt;/code&gt;启动后自动向etcd中注册信息：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/contiv.io/oper
/contiv.io/oper/auto-vlan
/contiv.io/oper/auto-vlan/global
/contiv.io/oper/auto-vxlan
/contiv.io/oper/auto-vxlan/global
/contiv.io/oper/global
/contiv.io/oper/global/global
/contiv.io/oper/ovs-driver
/contiv.io/oper/ovs-driver/sz-pg-oam-docker-test-001.tendcloud.com
/contiv.io/master
/contiv.io/master/config
/contiv.io/master/config/global
/contiv.io/obj
/contiv.io/obj/modeldb
/contiv.io/obj/modeldb/global
/contiv.io/obj/modeldb/global/global
/contiv.io/obj/modeldb/tenant
/contiv.io/obj/modeldb/tenant/default
/contiv.io/lock
/contiv.io/lock/netmaster
/contiv.io/lock/netmaster/leader
/contiv.io/service
/contiv.io/service/netmaster
/contiv.io/service/netmaster/172.20.0.113:9999
/contiv.io/service/netmaster.rpc
/contiv.io/service/netmaster.rpc/172.20.0.113:9001
/contiv.io/state
/contiv.io/state/auto-vlan
/contiv.io/state/auto-vlan/global
/contiv.io/state/auto-vxlan
/contiv.io/state/auto-vxlan/global
/contiv.io/state/global
/contiv.io/state/global/global
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;contiv启动&#34;&gt;Contiv启动&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;启动netmaster&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$nohup netmaster -cluster-mode docker -cluster-store etcd://172.20.0.113:2379 -debug -listen-url 172.20.0.113:9999 -plugin-name netplugin &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为了突出netmaster命令的使用，我把所有可以使用默认值的参数都明确的写出。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;netmaster&lt;/code&gt;监听9999端口。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;查看已有的contiv网络&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$netctl --netmaster http://172.20.0.113:9999 network ls
Tenant  Network  Nw Type  Encap type  Packet tag  Subnet   Gateway  IPv6Subnet  IPv6Gateway
------  -------  -------  ----------  ----------  -------  ------   ----------  -----------
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为了以后执行命令方便，不用来回输入&lt;code&gt;$NETMASTER&lt;/code&gt;地址，可以将其设置为环境变量&lt;/p&gt;

&lt;p&gt;&lt;code&gt;export NETMASTER=&amp;quot;http://172.20.0.113:9999&amp;quot;&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;netplugin需要使用Open vSwitch，所以你需要先安装&lt;strong&gt;Open vSwitch&lt;/strong&gt;。否则你会遇到这个问题&lt;a href=&#34;https://github.com/contiv/netplugin/issues/760&#34;&gt;netplugin issue-760&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;open-vswitch安装&#34;&gt;Open vSwitch安装&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://supercomputing.caltech.edu/blog/index.php/2016/05/03/open-vswitch-installation-on-centos-7-2/&#34;&gt;Open vSwitch installation on CentOS7.2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;参考上面链接里的方法。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#!/bin/bash
yum -y install make gcc openssl-devel autoconf automake rpm-build redhat-rpm-config python-devel openssl-devel kernel-devel kernel-debug-devel libtool wget
mkdir -p ~/rpmbuild/SOURCES
cp openvswitch-2.5.1.tar.gz ~/rpmbuild/SOURCES/
tar xfz openvswitch-2.5.1.tar.gz
sed &#39;s/openvswitch-kmod, //g&#39; openvswitch-2.5.1/rhel/openvswitch.spec &amp;gt; openvswitch-2.5.1/rhel/openvswitch_no_kmod.spec
rpmbuild -bb --nocheck ~/openvswitch-2.5.1/rhel/openvswitch_no_kmod.spec
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;编译好的rpm包在&lt;code&gt;~/rpmbuild/RPMS/x86_64/openvswitch-2.5.1-1.x86_64.rpm&lt;/code&gt;目录下。&lt;/p&gt;

&lt;p&gt;安装好Open vSwitch后就可以启动&lt;strong&gt;netplugin&lt;/strong&gt;。&lt;/p&gt;

&lt;h3 id=&#34;创建contiv网络&#34;&gt;创建contiv网络&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;启动netplugin&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;nohup netplugin -cluster-store etcd://172.20.0.113:2379 &amp;amp;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;创建network&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;netctl --netmaster http://172.20.0.113:9999 network create --subnet=10.1.2.0/24 contiv-net&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;获得以下报错：&lt;/p&gt;

&lt;p&gt;ERRO[0000] Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&lt;/p&gt;

&lt;p&gt;但是执行第二次的时候居然成功了，不过当我查看docker network的时候根本就看不到刚刚创建的contiv-net网络。*这只是一场游戏一场梦。。。*😢&lt;/p&gt;

&lt;p&gt;Creating network default:contiv-net&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$netctl network ls
Tenant   Network     Nw Type  Encap type  Packet tag  Subnet       Gateway  IPv6Subnet  IPv6Gateway
------   -------     -------  ----------  ----------  -------      ------   ----------  -----------
default  contiv-net  data     vxlan       0           10.1.2.0/24  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看刚创建的contiv-net网络。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$netctl network inspect contiv-net
Inspeting network: contiv-net tenant: default
{
  &amp;quot;Config&amp;quot;: {
    &amp;quot;key&amp;quot;: &amp;quot;default:contiv-net&amp;quot;,
    &amp;quot;encap&amp;quot;: &amp;quot;vxlan&amp;quot;,
    &amp;quot;networkName&amp;quot;: &amp;quot;contiv-net&amp;quot;,
    &amp;quot;nwType&amp;quot;: &amp;quot;data&amp;quot;,
    &amp;quot;subnet&amp;quot;: &amp;quot;10.1.2.0/24&amp;quot;,
    &amp;quot;tenantName&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;link-sets&amp;quot;: {},
    &amp;quot;links&amp;quot;: {
      &amp;quot;Tenant&amp;quot;: {
        &amp;quot;type&amp;quot;: &amp;quot;tenant&amp;quot;,
        &amp;quot;key&amp;quot;: &amp;quot;default&amp;quot;
      }
    }
  },
  &amp;quot;Oper&amp;quot;: {
    &amp;quot;availableIPAddresses&amp;quot;: &amp;quot;10.1.2.1-10.1.2.254&amp;quot;,
    &amp;quot;externalPktTag&amp;quot;: 1,
    &amp;quot;pktTag&amp;quot;: 1
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从&lt;strong&gt;netmaster&lt;/strong&gt;日志中可以看到如下报错：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;time=&amp;quot;Mar  9 21:44:14.746627381&amp;quot; level=debug msg=&amp;quot;NwInfra type is default, no ACI&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.750278056&amp;quot; level=info msg=&amp;quot;Creating docker network: {CheckDuplicate:true Driver:netplugin EnableIPv6:false IPAM:0xc4204d8ea0 Internal:false Attachable:true Options:map[tenant:default encap:vxlan pkt-tag:1] Labels:map[]}&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.752034749&amp;quot; level=error msg=&amp;quot;Error creating network contiv-net. Err: Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.752067294&amp;quot; level=error msg=&amp;quot;Error creating network contiv-net.default in docker. Err: Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.752102735&amp;quot; level=error msg=&amp;quot;Error creating network {&amp;amp;{Key:default:contiv-net Encap:vxlan Gateway: Ipv6Gateway: Ipv6Subnet: NetworkName:contiv-net NwType:data PktTag:0 Subnet:10.1.2.0/24 TenantName:default LinkSets:{EndpointGroups:map[] Servicelbs:map[] Services:map[]} Links:{Tenant:{ObjType: ObjKey:}}}}. Err: Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.752129195&amp;quot; level=error msg=&amp;quot;NetworkCreate retruned error for: &amp;amp;{Key:default:contiv-net Encap:vxlan Gateway: Ipv6Gateway: Ipv6Subnet: NetworkName:contiv-net NwType:data PktTag:0 Subnet:10.1.2.0/24 TenantName:default LinkSets:{EndpointGroups:map[] Servicelbs:map[] Services:map[]} Links:{Tenant:{ObjType: ObjKey:}}}. Err: Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.752155973&amp;quot; level=error msg=&amp;quot;CreateNetwork error for: {Key:default:contiv-net Encap:vxlan Gateway: Ipv6Gateway: Ipv6Subnet: NetworkName:contiv-net NwType:data PktTag:0 Subnet:10.1.2.0/24 TenantName:default LinkSets:{EndpointGroups:map[] Servicelbs:map[] Services:map[]} Links:{Tenant:{ObjType: ObjKey:}}}. Err: Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.752172138&amp;quot; level=error msg=&amp;quot;Handler for POST /api/v1/networks/default:contiv-net/ returned error: Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&amp;quot; 
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;从日志中看到一个令人悲痛语句的话*legacy plugin netplugin of type NetworkDriver is not supported in swarm mode*，你们昨天不是刚发的版本说已经支持swarm mode吗？&lt;a href=&#34;https://github.com/contiv/netplugin/commit/8afd1b7718c8424a876760d18484124e0aad3557&#34;&gt;&lt;code&gt;commit-8afd1b7&lt;/code&gt;&lt;/a&gt;不是白纸黑字的写着吗？&lt;/p&gt;

&lt;p&gt;我提了个&lt;a href=&#34;https://github.com/contiv/netplugin/issues/776&#34;&gt;issue-776&lt;/a&gt;，看看怎样解决这个问题，另外netplugin命令怎么用，文档上没写啊？&lt;/p&gt;

&lt;p&gt;&lt;code&gt;netplugin -h&lt;/code&gt;可以中有两个选项我不明白，不知道怎么设置，有知道的人请告诉我一声。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  -vlan-if value
    	VLAN uplink interface
  -vtep-ip string
    	My VTEP ip address
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同时我会继续关注contiv的slack和github &lt;a href=&#34;https://github.com/contiv/netplugin/issues/776&#34;&gt;Issue-776&lt;/a&gt;的进展。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Contiv Intro</title>
      <link>http://rootsongjc.github.io/blogs/contiv-guide/</link>
      <pubDate>Thu, 09 Mar 2017 11:28:34 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/contiv-guide/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/2017021162.jpg&#34; alt=&#34;蓝色港湾&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(题图：北京蓝色港湾夜景 Feb 11,2017 元宵节)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Contiv&lt;/strong&gt;是思科开发的docker网络插件，从2015年就开源了，业界通常拿它和Calico比较。貌似Contiv以前还开发过volume plugin，现在销声匿迹了，只有netplugin仍在活跃开发。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://dockone.io/article/1935&#34;&gt;容器网络插件 Calico 与 Contiv Netplugin深入比较&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;还有篇文章讲解了&lt;a href=&#34;http://blog.dataman-inc.com/shurenyun-docker-133/&#34;&gt;docker网络方案的改进&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;contiv-netplugin-简介&#34;&gt;Contiv Netplugin 简介&lt;/h3&gt;

&lt;p&gt;Contiv Netplugin 是来自思科的解决方案。编程语言为 Go。它基于 OpenvSwitch，以插件化的形式支持容器访问网络，支持 VLAN，Vxlan，多租户，主机访问控制策略等。作为思科整体支持容器基础设施contiv项目的网络部分，最大的亮点在于容器被赋予了 SDN 能力，实现对容器更细粒度，更丰富的访问控制功能。另外，对 Docker CNM 网络模型的支持，并内置了 IPAM 接口，不仅仅提供了一容器一 IP，而且容器的网络信息被记录的容器配置中，伴随着容器的整个生命周期，减低因为状态不同步造成网络信息丢失的风险。有别于 CNI，这种内聚化的设计有利于减少对第三方模块的依赖。随着项目的发展，除了 Docker，还提供了对 Kubernetes 以及 Mesos 的支持，即 CNI 接口。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://dockerone.com/uploads/article/20161221/c737f78ce7c50c84e49648aaf771a6b4.png&#34;&gt;&lt;img src=&#34;http://dockerone.com/uploads/article/20161221/c737f78ce7c50c84e49648aaf771a6b4.png&#34; alt=&#34;9260E9B7-43C0-48B8-B5C7-CF8B952959D2.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Netmaster 后台进程负责记录所有节点状态，保存网络信息，分配 IP 地址&lt;/li&gt;
&lt;li&gt;Netplugin 后台进程作为每个宿主机上的 Agent 与 Docker 及 OVS 通信，处理来自 Docker 的请求，管理 OVS。Docker 方面接口为 remote driver，包括一系列 Docker 定义的 JSON-RPC(POST) 消息。OVS 方面接口为 remote ovsdb，也是 JSON-RPC 消息。以上消息都在 localhost 上处理。&lt;/li&gt;
&lt;li&gt;集群管理依赖 etcd/serf&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;http://dockerone.com/uploads/article/20161221/852b276222482c4740b690eb7f078409.png&#34;&gt;&lt;img src=&#34;http://dockerone.com/uploads/article/20161221/852b276222482c4740b690eb7f078409.png&#34; alt=&#34;580469BC-468C-49C8-B29E-8B88143AFE0A.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;netplugin的优势&#34;&gt;Netplugin的优势&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;较早支持CNM模型。与已有的网络基础设施兼容性较高，改造影响小。基于VLAN的平行扩展与现有网络结构地位对等&lt;/li&gt;
&lt;li&gt;SDN能力，能够对容器的网络访问做更精细的控制&lt;/li&gt;
&lt;li&gt;多租户支持，具备未来向混合云/公有云迁移的潜力&lt;/li&gt;
&lt;li&gt;代码规模不大，逻辑结构清晰，并发好，VLAN在公司内部有开发部署运维实践经验，稳定性经过生产环境验证&lt;/li&gt;
&lt;li&gt;&lt;u&gt;&lt;strong&gt;京东&lt;/strong&gt;基于相同的技术栈（OVS + VLAN）已支持10w+ 容器的运行。&lt;/u&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;next&#34;&gt;Next&lt;/h3&gt;

&lt;p&gt;后续文章会讲解contiv netplugin的环境配置和开发。目前还在1.0-beta版本。&lt;strong&gt;Docker store&lt;/strong&gt;上提供了contiv插件的&lt;a href=&#34;https://store.docker.com/plugins/803eecee-0780-401a-a454-e9523ccf86b3&#34;&gt;下载地址&lt;/a&gt;。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Packer Intro</title>
      <link>http://rootsongjc.github.io/blogs/packer-intro/</link>
      <pubDate>Thu, 09 Mar 2017 10:58:42 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/packer-intro/</guid>
      <description>&lt;p&gt;昨天研究了下&lt;a href=&#34;https://github.com/mitchellh/vagrant&#34;&gt;&lt;strong&gt;Vagrant&lt;/strong&gt;&lt;/a&gt;，感觉它的虚拟机ruby格式定义很麻烦，经人指点还有一个叫做&lt;a href=&#34;https://github.com/mitchellh/packer&#34;&gt;&lt;strong&gt;packer&lt;/strong&gt;&lt;/a&gt;的东西，也是Hashicorp这家公司出品的，今天看了下。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Packer&lt;/strong&gt;是一款开源轻量级的镜像定义工具，可以根据一份定义文件生成多个平台的镜像，支持的平台有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Amazon EC2 (AMI). Both EBS-backed and instance-store AMIs&lt;/li&gt;
&lt;li&gt;Azure&lt;/li&gt;
&lt;li&gt;DigitalOcean&lt;/li&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;li&gt;Google Compute Engine&lt;/li&gt;
&lt;li&gt;OpenStack&lt;/li&gt;
&lt;li&gt;Parallels&lt;/li&gt;
&lt;li&gt;QEMU. Both KVM and Xen images.&lt;/li&gt;
&lt;li&gt;VirtualBox&lt;/li&gt;
&lt;li&gt;VMware&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Packer创造的镜像也能转换成&lt;strong&gt;Vagrant boxes&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;Packer的镜像创建需要一个json格式的定义文件，例如&lt;code&gt;quick-start.json&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;variables&amp;quot;: {
    &amp;quot;access_key&amp;quot;: &amp;quot;{{env `AWS_ACCESS_KEY_ID`}}&amp;quot;,
    &amp;quot;secret_key&amp;quot;: &amp;quot;{{env `AWS_SECRET_ACCESS_KEY`}}&amp;quot;
  },
  &amp;quot;builders&amp;quot;: [{
    &amp;quot;type&amp;quot;: &amp;quot;amazon-ebs&amp;quot;,
    &amp;quot;access_key&amp;quot;: &amp;quot;{{user `access_key`}}&amp;quot;,
    &amp;quot;secret_key&amp;quot;: &amp;quot;{{user `secret_key`}}&amp;quot;,
    &amp;quot;region&amp;quot;: &amp;quot;us-east-1&amp;quot;,
    &amp;quot;source_ami&amp;quot;: &amp;quot;ami-af22d9b9&amp;quot;,
    &amp;quot;instance_type&amp;quot;: &amp;quot;t2.micro&amp;quot;,
    &amp;quot;ssh_username&amp;quot;: &amp;quot;ubuntu&amp;quot;,
    &amp;quot;ami_name&amp;quot;: &amp;quot;packer-example {{timestamp}}&amp;quot;
  }]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用&lt;code&gt;packer build quick-start.json&lt;/code&gt;可以在AWS上build一个AIM镜像。&lt;/p&gt;

&lt;p&gt;Packer的详细文档：&lt;a href=&#34;https://www.packer.io/docs/&#34;&gt;https://www.packer.io/docs/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>