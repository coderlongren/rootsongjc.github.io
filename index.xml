<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jimmy&#39;s blog</title>
    <link>http://rootsongjc.github.io/index.xml</link>
    <description>Recent content on Jimmy&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 16 Mar 2017 19:52:37 +0800</lastBuildDate>
    <atom:link href="http://rootsongjc.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Contiv Ultimate-思科docke网络插件contiv入坑终极版</title>
      <link>http://rootsongjc.github.io/blogs/contiv-ultimate/</link>
      <pubDate>Thu, 16 Mar 2017 19:52:37 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/contiv-ultimate/</guid>
      <description>

&lt;p&gt;&lt;em&gt;（题图：）&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;前几天写的几篇&lt;a href=&#34;http://rootsongjc.github.io/tags/contiv/&#34;&gt;关于Contiv的文章&lt;/a&gt;已经把引入坑了😂&lt;/p&gt;

&lt;p&gt;今天这篇文章将带领大家用正确的姿势编译和打包一个&lt;strong&gt;contiv netplugin&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;请一定要在&lt;strong&gt;Linux&lt;/strong&gt;环境中编译。docker中编译也会报错，最好还是搞个虚拟🐔吧，最好还有VPN能翻墙。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;编译&#34;&gt;编译&lt;/h2&gt;

&lt;p&gt;创建一个link &lt;strong&gt;/go&lt;/strong&gt;链接到你的GOPATH目录，下面编译的时候要用。&lt;/p&gt;

&lt;p&gt;在netplugin目录下执行以下命令能够编译出二进制文件。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;NET_CONTAINER_BUILD=1 make build
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;bin&lt;/strong&gt;目录下会生成如下几个文件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;contivk8s  github-release  godep  golint  misspell  modelgen  netcontiv  netctl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;⚠️编译过程中可能会遇到 有些包不存在或者需要翻墙下载。&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;打包&#34;&gt;打包&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Docker17.03-CE插件开发-举个🌰</title>
      <link>http://rootsongjc.github.io/blogs/docker-plugin-develop/</link>
      <pubDate>Wed, 15 Mar 2017 13:57:26 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/docker-plugin-develop/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20161016022.jpg&#34; alt=&#34;杭州吴山&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：杭州吴山步道旁的墙壁 Oct 16,2016）&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;当你看到这篇文章时，如果你也正在进行docker1.13+版本下的plugin开发，恭喜你也入坑了，如果你趟出坑，麻烦告诉你的方法，感恩不尽🙏&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;看了文章后你可能会觉得，官网上的可能是个假🌰。&lt;strong&gt;虽然官网上的文档写的有点不对，不过你使用docker-ssh-volume的开源代码自己去构建plugin的还是可以成功的！&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;docker-plugin开发文档&#34;&gt;Docker plugin开发文档&lt;/h3&gt;

&lt;p&gt;首先docker官方给出了一个&lt;a href=&#34;https://docs.docker.com/engine/extend/legacy_plugins/&#34;&gt;docker legacy plugin文档&lt;/a&gt;，这篇文章基本就是告诉你docker目前支持哪些插件，罗列了一系列连接，不过对不起，这些不是docker官方插件，有问题去找它们的开发者去吧😂&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Docker plugin貌似开始使用了新的v2 plugin了，legacy版本的plugin可以能在后期被废弃。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;从docker的源码&lt;strong&gt;plugin/store.go&lt;/strong&gt;中可以看到：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;/* allowV1PluginsFallback determines daemon&#39;s support for V1 plugins.
 * When the time comes to remove support for V1 plugins, flipping
 * this bool is all that will be needed.
 */
const allowV1PluginsFallback bool = true

/* defaultAPIVersion is the version of the plugin API for volume, network,
   IPAM and authz. This is a very stable API. When we update this API, then
   pluginType should include a version. e.g. &amp;quot;networkdriver/2.0&amp;quot;.
*/
const defaultAPIVersion string = &amp;quot;1.0&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;随着docker公司是的战略调整，推出了docker-CE和docker-EE之后，未来有些插件就可能要收费了，v2版本的插件都是在docker store中下载了，而这种插件在创建的时候都是打包成docker image，如果不开放源码的话，你即使pull下来插件也无法修改和导出的，&lt;strong&gt;docker plugin目前没有导出接口&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;真正要开发一个docker plugin还是得看&lt;a href=&#34;https://docs.docker.com/engine/extend/plugin_api/&#34;&gt;docker plugin API&lt;/a&gt;，这篇文档告诉我们：&lt;/p&gt;

&lt;h4 id=&#34;插件发现&#34;&gt;插件发现&lt;/h4&gt;

&lt;p&gt;当你开发好一个插件&lt;strong&gt;docker engine&lt;/strong&gt;怎么才能发现它们呢？有三种方式：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;.sock&lt;/strong&gt;，linux下放在/run/docker/plugins目录下，或该目录下的子目录比如&lt;a href=&#34;https://github.com/ClusterHQ/flocker&#34;&gt;flocker&lt;/a&gt;插件的&lt;code&gt;.sock&lt;/code&gt;文件放在&lt;code&gt;/run/docker/plugins/flocker/flocker.sock&lt;/code&gt;下&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;.spec&lt;/strong&gt;，比如&lt;strong&gt;convoy&lt;/strong&gt;插件在&lt;code&gt;/etc/docker/plugins/convoy.spec&lt;/code&gt;定义，内容为&lt;code&gt;unix:///var/run/convoy/convoy.sock&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;.json&lt;/strong&gt;，比如&lt;strong&gt;infinit&lt;/strong&gt;插件在&lt;code&gt;/usr/lib/docker/plugins/infinit.json&lt;/code&gt;定义，内容为&lt;code&gt;{&amp;quot;Addr&amp;quot;:&amp;quot;https://infinit.sh&amp;quot;,&amp;quot;Name&amp;quot;:&amp;quot;infinit&amp;quot;}&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;文章中的其它部分&lt;strong&gt;貌似都过时&lt;/strong&gt;了，新的插件不是作为&lt;strong&gt;systemd&lt;/strong&gt;进程运行的，而是完全通过&lt;strong&gt;docker plugin&lt;/strong&gt;命令来管理的。&lt;/p&gt;

&lt;p&gt;当你使用&lt;strong&gt;docker plugin enable &lt;plugin_name&gt;&lt;/strong&gt;来激活了插件后，理应在&lt;code&gt;/run/docker/plugins&lt;/code&gt;目录下生成插件的&lt;code&gt;.sock&lt;/code&gt;文件，但是现在只有一个以runc ID命名的目录，这个问题下面有详细的叙述过程，你也可以跳过，直接看&lt;a href=&#34;https://github.com/docker/docker/issues/31723&#34;&gt;issue-31723&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/engine/extend/&#34;&gt;docker plugin管理&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;创建sshfs-volume-plugin&#34;&gt;创建sshfs volume plugin&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/docker/docker/blob/17.03.x/docs/extend/index.md#developing-a-plugin&#34;&gt;官方示例文档&lt;/a&gt;（这个文档有问题）&lt;a href=&#34;https://github.com/docker/docker/issues/29886&#34;&gt;docker-issue29886&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;官方以开发一个&lt;strong&gt;sshfs&lt;/strong&gt;的volume plugin为例。&lt;/p&gt;

&lt;p&gt;执行&lt;code&gt;docker plugin create&lt;/code&gt;命令的目录下必须包含以下内容：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;config.json&lt;/strong&gt;文件，里面是插件的配置信息，&lt;a href=&#34;https://github.com/docker/docker/blob/17.03.x/docs/extend/config.md&#34;&gt;plugin config参考文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;rootfs&lt;/strong&gt;目录，插件镜像解压后的目录。v2版本的docker plugin都是以docker镜像的方式包装的。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/vieux/docker-volume-sshfs
$ cd docker-volume-sshfs
$ go get github.com/docker/go-plugins-helpers/volume
$ go build -o docker-volume-sshfs main.go  
$ docker build -t rootfsimage .
$ id=$(docker create rootfsimage true) # id was cd851ce43a403 when the image was created
$ sudo mkdir -p myplugin/rootfs
$ sudo docker export &amp;quot;$id&amp;quot; | sudo tar -x -C myplugin/rootfs
$ docker rm -vf &amp;quot;$id&amp;quot;
$ docker rmi rootfsimage
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们可以看到&lt;strong&gt;sshfs&lt;/strong&gt;的Dockerfile是这样的：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Dockerfile&#34;&gt;FROM alpine

RUN apk update &amp;amp;&amp;amp; apk add sshfs

RUN mkdir -p /run/docker/plugins /mnt/state /mnt/volumes

COPY docker-volume-sshfs docker-volume-sshfs

CMD [&amp;quot;docker-volume-sshfs&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;实际上是编译好的可执行文件复制到alpine linux容器中运行。&lt;/p&gt;

&lt;p&gt;编译rootfsimage镜像的过程。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker build -t rootfsimage .
Sending build context to Docker daemon 11.71 MB
Step 1/5 : FROM alpine
 ---&amp;gt; 4a415e366388
Step 2/5 : RUN apk update &amp;amp;&amp;amp; apk add sshfs
 ---&amp;gt; Running in 1551ecc1c847
fetch http://dl-cdn.alpinelinux.org/alpine/v3.5/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.5/community/x86_64/APKINDEX.tar.gz
v3.5.2-2-ge626ce8c3c [http://dl-cdn.alpinelinux.org/alpine/v3.5/main]
v3.5.1-71-gc7bb9a04f0 [http://dl-cdn.alpinelinux.org/alpine/v3.5/community]
OK: 7959 distinct packages available
(1/10) Installing openssh-client (7.4_p1-r0)
(2/10) Installing fuse (2.9.7-r0)
(3/10) Installing libffi (3.2.1-r2)
(4/10) Installing libintl (0.19.8.1-r0)
(5/10) Installing libuuid (2.28.2-r1)
(6/10) Installing libblkid (2.28.2-r1)
(7/10) Installing libmount (2.28.2-r1)
(8/10) Installing pcre (8.39-r0)
(9/10) Installing glib (2.50.2-r0)
(10/10) Installing sshfs (2.8-r0)
Executing busybox-1.25.1-r0.trigger
Executing glib-2.50.2-r0.trigger
OK: 11 MiB in 21 packages
 ---&amp;gt; 1a73c501f431
Removing intermediate container 1551ecc1c847
Step 3/5 : RUN mkdir -p /run/docker/plugins /mnt/state /mnt/volumes
 ---&amp;gt; Running in 032af3b2595a
 ---&amp;gt; 30c7e8463e96
Removing intermediate container 032af3b2595a
Step 4/5 : COPY docker-volume-sshfs docker-volume-sshfs
 ---&amp;gt; a924c6fcc1e4
Removing intermediate container ffc5e3c97707
Step 5/5 : CMD docker-volume-sshfs
 ---&amp;gt; Running in 0dc938fe4f4e
 ---&amp;gt; 0fd2e3d94860
Removing intermediate container 0dc938fe4f4e
Successfully built 0fd2e3d94860
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;编写&lt;code&gt;config.json&lt;/code&gt;文档&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Json&#34;&gt;{
    &amp;quot;description&amp;quot;: &amp;quot;sshFS plugin for Docker&amp;quot;,
    &amp;quot;documentation&amp;quot;: &amp;quot;https://docs.docker.com/engine/extend/plugins/&amp;quot;,
    &amp;quot;entrypoint&amp;quot;: [
        &amp;quot;/docker-volume-sshfs&amp;quot;
    ],
    &amp;quot;env&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;DEBUG&amp;quot;,
            &amp;quot;settable&amp;quot;: [
                &amp;quot;value&amp;quot;
            ],
            &amp;quot;value&amp;quot;: &amp;quot;0&amp;quot;
        }
    ],
    &amp;quot;interface&amp;quot;: {
        &amp;quot;socket&amp;quot;: &amp;quot;sshfs.sock&amp;quot;,
        &amp;quot;types&amp;quot;: [
            &amp;quot;docker.volumedriver/1.0&amp;quot;
        ]
    },
    &amp;quot;linux&amp;quot;: {
        &amp;quot;capabilities&amp;quot;: [
            &amp;quot;CAP_SYS_ADMIN&amp;quot;
        ],
        &amp;quot;devices&amp;quot;: [
            {
                &amp;quot;path&amp;quot;: &amp;quot;/dev/fuse&amp;quot;
            }
        ]
    },
    &amp;quot;mounts&amp;quot;: [
        {
            &amp;quot;destination&amp;quot;: &amp;quot;/mnt/state&amp;quot;,
            &amp;quot;options&amp;quot;: [
                &amp;quot;rbind&amp;quot;
            ],
            &amp;quot;source&amp;quot;: &amp;quot;/var/lib/docker/plugins/&amp;quot;,
            &amp;quot;type&amp;quot;: &amp;quot;bind&amp;quot;
        }
    ],
    &amp;quot;network&amp;quot;: {
        &amp;quot;type&amp;quot;: &amp;quot;host&amp;quot;
    },
    &amp;quot;propagatedmount&amp;quot;: &amp;quot;/mnt/volumes&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该插件使用host网络类型，使用/run/docker/plugins/sshfs.sock接口与docker engine通信。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注意官网上的这个文档有问题，config.json与代码里的不符，尤其是Entrypoint的二进制文件的位置不对。&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;注意&lt;strong&gt;socket&lt;/strong&gt;配置的地址不要写详细地址，默认会在/run/docker/plugins目录下生成socket文件。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;创建plugin&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;使用&lt;code&gt;docker plugin create &amp;lt;plugin_name&amp;gt; /path/to/plugin/data/&lt;/code&gt;命令创建插件。&lt;/p&gt;

&lt;p&gt;具体到sshfs插件，在myplugin目录下使用如下命令创建插件：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker plugin create jimmysong/sshfs:latest .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在就可以看到刚创建的插件了&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker plugin ls
ID                  NAME                 DESCRIPTION               ENABLED
8aa1f6098fca        vieux/sshfs:latest   sshFS plugin for Docker   true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;push plugin&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;先登录你的docker hub账户，然后使用&lt;code&gt;docker plugin push jimmysong/sshfs:latest&lt;/code&gt;即可以推送docker plugin到docker hub中。&lt;/p&gt;

&lt;p&gt;目前推送到&lt;strong&gt;harbor&lt;/strong&gt;镜像仓库有问题，报错信息：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c08c951b53b7: Preparing 
denied: requested access to the resource is denied
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;已给harbor提&lt;a href=&#34;https://github.com/vmware/harbor/issues/1532&#34;&gt;issue-1532&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;plugin的使用&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;有发现了个问题&lt;a href=&#34;https://github.com/docker/docker/issues/31723&#34;&gt;docker issue-31723&lt;/a&gt;，使用plugin创建volume的时候居然找不到&lt;code&gt;sshfs.sock&lt;/code&gt;文件！😢刚开始手动创建plugin的时候测试了下是正常的，不知道为啥弄到这台测试机器上出问题了。&lt;/p&gt;

&lt;h3 id=&#34;关于docker-plugin-enable失败的问题&#34;&gt;关于docker plugin enable失败的问题&lt;/h3&gt;

&lt;p&gt;当docker  plugin创建成功并enable的时候docker并没有报错，这与docker plugin的&lt;strong&gt;activate&lt;/strong&gt;机制有关，只有当你最终使用该plugin的时候才会激活它。&lt;/p&gt;

&lt;p&gt;使用&lt;strong&gt;sshfs&lt;/strong&gt;插件创建volume。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker volume create -d sshfs --name sshvolume -o sshcmd=1.2.3.4:/remote -o password=password
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;报错如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error response from daemon: create sshvolume: Post http://%2Frun%2Fdocker%2Fplugins%2F8f7b8f931b38a4ef53d0e4f8d738e26e8f10ef8bd26c8244f4b8dcc7276b685f%2Fsshfs.sock/VolumeDriver.Create: dial unix /run/docker/plugins/8f7b8f931b38a4ef53d0e4f8d738e26e8f10ef8bd26c8244f4b8dcc7276b685f/sshfs.sock: connect: no such file or directory
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Docker daemon在enable这个插件的时候会寻找这个&lt;strong&gt;.sock&lt;/strong&gt;文件，然后在自己的plugindb中注册它，相关代码在这个文件里：&lt;a href=&#34;https://github.com/docker/docker/blob/17.03.x/plugin/manager_linux.go&#34;&gt;https://github.com/docker/docker/blob/17.03.x/plugin/manager_linux.go&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;相关代码片段：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;func (pm *Manager) enable(p *v2.Plugin, c *controller, force bool) error {
	p.Rootfs = filepath.Join(pm.config.Root, p.PluginObj.ID, &amp;quot;rootfs&amp;quot;)
	if p.IsEnabled() &amp;amp;&amp;amp; !force {
		return fmt.Errorf(&amp;quot;plugin %s is already enabled&amp;quot;, p.Name())
	}
	spec, err := p.InitSpec(pm.config.ExecRoot)
	if err != nil {
		return err
	}

	c.restart = true
	c.exitChan = make(chan bool)

	pm.mu.Lock()
	pm.cMap[p] = c
	pm.mu.Unlock()

	var propRoot string
	if p.PropagatedMount != &amp;quot;&amp;quot; {
		propRoot = filepath.Join(filepath.Dir(p.Rootfs), &amp;quot;propagated-mount&amp;quot;)

		if err := os.MkdirAll(propRoot, 0755); err != nil {
			logrus.Errorf(&amp;quot;failed to create PropagatedMount directory at %s: %v&amp;quot;, propRoot, err)
		}

		if err := mount.MakeRShared(propRoot); err != nil {
			return errors.Wrap(err, &amp;quot;error setting up propagated mount dir&amp;quot;)
		}

		if err := mount.Mount(propRoot, p.PropagatedMount, &amp;quot;none&amp;quot;, &amp;quot;rbind&amp;quot;); err != nil {
			return errors.Wrap(err, &amp;quot;error creating mount for propagated mount&amp;quot;)
		}
	}

	if err := initlayer.Setup(filepath.Join(pm.config.Root, p.PluginObj.ID, rootFSFileName), 0, 0); err != nil {
		return errors.WithStack(err)
	}

	if err := pm.containerdClient.Create(p.GetID(), &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, specs.Spec(*spec), attachToLog(p.GetID())); err != nil {
		if p.PropagatedMount != &amp;quot;&amp;quot; {
			if err := mount.Unmount(p.PropagatedMount); err != nil {
				logrus.Warnf(&amp;quot;Could not unmount %s: %v&amp;quot;, p.PropagatedMount, err)
			}
			if err := mount.Unmount(propRoot); err != nil {
				logrus.Warnf(&amp;quot;Could not unmount %s: %v&amp;quot;, propRoot, err)
			}
		}
		return errors.WithStack(err)
	}

	return pm.pluginPostStart(p, c)
}

func (pm *Manager) pluginPostStart(p *v2.Plugin, c *controller) error {
    //这里需要获取.sock文件的地址 
    //pm.conifg.ExecRoot就是/run/docker/plugins
    //p.GetID()返回的就是很长的那串plugin ID
	sockAddr := filepath.Join(pm.config.ExecRoot, p.GetID(), p.GetSocket())
	client, err := plugins.NewClientWithTimeout(&amp;quot;unix://&amp;quot;+sockAddr, nil, c.timeoutInSecs)
	if err != nil {
		c.restart = false
		shutdownPlugin(p, c, pm.containerdClient)
		return errors.WithStack(err)
	}

	p.SetPClient(client)

	maxRetries := 3
	var retries int
	for {
		time.Sleep(3 * time.Second)
		retries++

		if retries &amp;gt; maxRetries {
			logrus.Debugf(&amp;quot;error net dialing plugin: %v&amp;quot;, err)
			c.restart = false
			shutdownPlugin(p, c, pm.containerdClient)
			return err
		}

		// net dial into the unix socket to see if someone&#39;s listening.
		conn, err := net.Dial(&amp;quot;unix&amp;quot;, sockAddr)
		if err == nil {
			conn.Close()
			break
		}
	}
	pm.config.Store.SetState(p, true)
	pm.config.Store.CallHandler(p)

	return pm.save(p)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意这段代码里的&lt;strong&gt;sockAddr := filepath.Join(pm.config.ExecRoot, p.GetID(), p.GetSocket())&lt;/strong&gt;，我在上面添加了注释。&lt;/p&gt;

&lt;p&gt;这个&lt;strong&gt;.sock&lt;/strong&gt;文件应该有docker plugin来生成，具体怎样生成的呢？还以&lt;strong&gt;docker-volume-ssh&lt;/strong&gt;这个插件为例。&lt;/p&gt;

&lt;p&gt;整个项目就一个&lt;strong&gt;main.go&lt;/strong&gt;文件，里面最后一行生成了&lt;strong&gt;/run/docker/plugins/sshfs.sock&lt;/strong&gt;这个sock。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;logrus.Error(h.ServeUnix(socketAddress, 0))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这行代码调用&lt;strong&gt;docker/go-plugin-helpers/sdk/handler.go&lt;/strong&gt;中的:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;// ServeUnix makes the handler to listen for requests in a unix socket.
// It also creates the socket file on the right directory for docker to read.
func (h Handler) ServeUnix(addr string, gid int) error {
	l, spec, err := newUnixListener(addr, gid)
	if err != nil {
		return err
	}
	if spec != &amp;quot;&amp;quot; {
		defer os.Remove(spec)
	}
	return h.Serve(l)
}

// Serve sets up the handler to serve requests on the passed in listener
func (h Handler) Serve(l net.Listener) error {
	server := http.Server{
		Addr:    l.Addr().String(),
		Handler: h.mux,
	}
	return server.Serve(l)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;//unix_listener_unsupoorted.go
func newUnixListener(pluginName string, gid int) (net.Listener, string, error) {
	return nil, &amp;quot;&amp;quot;, errOnlySupportedOnLinuxAndFreeBSD
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看了上面这这些，你看出socket文件是怎么创建的吗？&lt;/p&gt;

&lt;p&gt;这又是一个&lt;a href=&#34;https://github.com/vieux/docker-volume-sshfs/issues/19&#34;&gt;issue-19&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;如果你修改&lt;strong&gt;config.json&lt;/strong&gt;文件，将其中的&lt;strong&gt;interfaces - socket&lt;/strong&gt;指定为&lt;code&gt;/run/docker/plugins/sshfs.sock&lt;/code&gt;然后创建plugin，则能成功生成socket文件，但是当你enable它的时候又会报错&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error response from daemon: Unix socket path &amp;quot;/run/docker/plugins/ac34f7b246ac6c029023b1ebd48e166eadcdd2c9d0cc682cadca0336951d72f7/run/docker/plugins/sshfs.sock&amp;quot; is too long
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从docker daemon的日志里可以看到详细报错：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Mar 13 17:15:20 sz-pg-oam-docker-test-001.tendcloud.com dockerd[51757]: time=&amp;quot;2017-03-13T17:15:20+08:00&amp;quot; level=info msg=&amp;quot;standard_init_linux.go:178: exec user process caused \&amp;quot;no such file or directory\&amp;quot;&amp;quot; plugin=ac34f7b246ac6c029023b1ebd48e166eadcdd2c9d0cc682cadca0336951d72f7
Mar 13 17:15:20 sz-pg-oam-docker-test-001.tendcloud.com dockerd[51757]: time=&amp;quot;2017-03-13T17:15:20.321277088+08:00&amp;quot; level=error msg=&amp;quot;Sending SIGTERM to plugin failed with error: rpc error: code = 2 desc = no such process&amp;quot;
Mar 13 17:15:20 sz-pg-oam-docker-test-001.tendcloud.com dockerd[51757]: time=&amp;quot;2017-03-13T17:15:20.321488680+08:00&amp;quot; level=error msg=&amp;quot;Handler for POST /v1.26/plugins/sshfs/enable returned error: Unix socket path \&amp;quot;/run/docker/plugins/ac34f7b246ac6c029023b1ebd48e166eadcdd2c9d0cc682cadca0336951d72f7/run/docker/plugins/sshfs.sock\&amp;quot; is too long\ngithub.com/docker/docker/plugin.(*Manager).pluginPostStart\n\t/root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/plugin/manager_linux.go:84\ngithub.com/docker/docker/plugin.(*Manager).enable\n\t/root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/plugin/manager_linux.go:76\ngithub.com/docker/docker/plugin.(*Manager).Enable\n\t/root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/plugin/backend_linux.go:67\ngithub.com/docker/docker/api/server/router/plugin.(*pluginRouter).enablePlugin\n\t/root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/api/server/router/plugin/plugin_routes.go:241\ngithub.com/docker/docker/api/server/router/plugin.(*pluginRouter).(github.com/docker/docker/api/server/router/plugin.enablePlugin)-fm\n\t/root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/api/server/router/plugin/plugin.go:31\ngithub.com/docker/docker/api/server/middleware.ExperimentalMiddleware.WrapHandler.func1\n\t/root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/api/server/middleware/experimental.go:27\ngithub.com/docker/docker/api/server/middleware.VersionMiddleware.WrapHandler.func1\n\t/root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/api/server/middleware/version.go:47\ngithub.com/docker/docker/pkg/authorization.(*Middleware).WrapHandler.func1\n\t/root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/pkg/authorization/middleware.go:43\ngithub.com/docker/docker/api/server.(*Server).makeHTTPHandler.func1\n\t/root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/api/server/server.go:139\nnet/http.HandlerFunc.ServeHTTP\n\t/usr/local/go/src/net/http/server.go:1726\ngithub.com/docker/docker/vend
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正好验证了上面的&lt;strong&gt;enable&lt;/strong&gt;代码，docker默认是到&lt;code&gt;/run/docker/plugins&lt;/code&gt;目录下找&lt;strong&gt;sshfs.sock&lt;/strong&gt;这个文件的。&lt;/p&gt;

&lt;p&gt;我在docker daemon中发现一个很诡异的错误，&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Mar 13 17:29:41 sz-pg-oam-docker-test-001.tendcloud.com dockerd[51757]: time=&amp;quot;2017-03-13T17:29:41+08:00&amp;quot; level=info msg=&amp;quot;standard_init_linux.go:178: exec user process caused \&amp;quot;no such file or directory\&amp;quot;&amp;quot; plugin=85760810b4850009fc965f5c20d8534dc9aba085340a2ac0b4b9167a6fef7d53
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我查看了下&lt;code&gt;github.com/libnetwork/vendor/github.com/opencontainers/run/libcontainer/standard_init_linux.go&lt;/code&gt;文件，这个那个文件只有114行，见这里&lt;a href=&#34;https://github.com/docker/libnetwork/blob/master/vendor/github.com/opencontainers/runc/libcontainer/standard_init_linux.go&#34;&gt;https://github.com/docker/libnetwork/blob/master/vendor/github.com/opencontainers/runc/libcontainer/standard_init_linux.go&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;但是在&lt;strong&gt;opencontainers&lt;/strong&gt;的github项目里才有那么多行，见这里：&lt;a href=&#34;https://github.com/opencontainers/runc/blob/master/libcontainer/standard_init_linux.go&#34;&gt;https://github.com/opencontainers/runc/blob/master/libcontainer/standard_init_linux.go&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这个报错前后的函数是：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;// PR_SET_NO_NEW_PRIVS isn&#39;t exposed in Golang so we define it ourselves copying the value
// the kernel
const PR_SET_NO_NEW_PRIVS = 0x26

func (l *linuxStandardInit) Init() error {
	if !l.config.Config.NoNewKeyring {
		ringname, keepperms, newperms := l.getSessionRingParams()

		// do not inherit the parent&#39;s session keyring
		sessKeyId, err := keys.JoinSessionKeyring(ringname)
		if err != nil {
			return err
		}
		// make session keyring searcheable
		if err := keys.ModKeyringPerm(sessKeyId, keepperms, newperms); err != nil {
			return err
		}
	}

	if err := setupNetwork(l.config); err != nil {
		return err
	}
	if err := setupRoute(l.config.Config); err != nil {
		return err
	}

	label.Init()

	// prepareRootfs() can be executed only for a new mount namespace.
	if l.config.Config.Namespaces.Contains(configs.NEWNS) {
		if err := prepareRootfs(l.pipe, l.config.Config); err != nil {
			return err
		}
	}

	// Set up the console. This has to be done *before* we finalize the rootfs,
	// but *after* we&#39;ve given the user the chance to set up all of the mounts
	// they wanted.
	if l.config.CreateConsole {
		if err := setupConsole(l.pipe, l.config, true); err != nil {
			return err
		}
		if err := system.Setctty(); err != nil {
			return err
		}
	}

	// Finish the rootfs setup.
	if l.config.Config.Namespaces.Contains(configs.NEWNS) {
		if err := finalizeRootfs(l.config.Config); err != nil {
			return err
		}
	}

	if hostname := l.config.Config.Hostname; hostname != &amp;quot;&amp;quot; {
		if err := syscall.Sethostname([]byte(hostname)); err != nil {
			return err
		}
	}
	if err := apparmor.ApplyProfile(l.config.AppArmorProfile); err != nil {
		return err
	}
	if err := label.SetProcessLabel(l.config.ProcessLabel); err != nil {
		return err
	}

	for key, value := range l.config.Config.Sysctl {
		if err := writeSystemProperty(key, value); err != nil {
			return err
		}
	}
	for _, path := range l.config.Config.ReadonlyPaths {
		if err := readonlyPath(path); err != nil {
			return err
		}
	}
	for _, path := range l.config.Config.MaskPaths {
		if err := maskPath(path); err != nil {
			return err
		}
	}
	pdeath, err := system.GetParentDeathSignal()
	if err != nil {
		return err
	}
	if l.config.NoNewPrivileges {
		if err := system.Prctl(PR_SET_NO_NEW_PRIVS, 1, 0, 0, 0); err != nil {
			return err
		}
	}
	// Tell our parent that we&#39;re ready to Execv. This must be done before the
	// Seccomp rules have been applied, because we need to be able to read and
	// write to a socket.
	if err := syncParentReady(l.pipe); err != nil {
		return err
	}
	// Without NoNewPrivileges seccomp is a privileged operation, so we need to
	// do this before dropping capabilities; otherwise do it as late as possible
	// just before execve so as few syscalls take place after it as possible.
	if l.config.Config.Seccomp != nil &amp;amp;&amp;amp; !l.config.NoNewPrivileges {
		if err := seccomp.InitSeccomp(l.config.Config.Seccomp); err != nil {
			return err
		}
	}
	if err := finalizeNamespace(l.config); err != nil {
		return err
	}
	// finalizeNamespace can change user/group which clears the parent death
	// signal, so we restore it here.
	if err := pdeath.Restore(); err != nil {
		return err
	}
	// compare the parent from the initial start of the init process and make sure that it did not change.
	// if the parent changes that means it died and we were reparented to something else so we should
	// just kill ourself and not cause problems for someone else.
	if syscall.Getppid() != l.parentPid {
		return syscall.Kill(syscall.Getpid(), syscall.SIGKILL)
	}
	// check for the arg before waiting to make sure it exists and it is returned
	// as a create time error.
	name, err := exec.LookPath(l.config.Args[0])
	if err != nil {
		return err
	}
	// close the pipe to signal that we have completed our init.
	l.pipe.Close()
	// wait for the fifo to be opened on the other side before
	// exec&#39;ing the users process.
	fd, err := syscall.Openat(l.stateDirFD, execFifoFilename, os.O_WRONLY|syscall.O_CLOEXEC, 0)
	if err != nil {
		return newSystemErrorWithCause(err, &amp;quot;openat exec fifo&amp;quot;)
	}
	if _, err := syscall.Write(fd, []byte(&amp;quot;0&amp;quot;)); err != nil {
		return newSystemErrorWithCause(err, &amp;quot;write 0 exec fifo&amp;quot;)
	}
	if l.config.Config.Seccomp != nil &amp;amp;&amp;amp; l.config.NoNewPrivileges {
         //下面这行是第178行
		if err := seccomp.InitSeccomp(l.config.Config.Seccomp); err != nil {
			return newSystemErrorWithCause(err, &amp;quot;init seccomp&amp;quot;)
		}
	}
	// close the statedir fd before exec because the kernel resets dumpable in the wrong order
	// https://github.com/torvalds/linux/blob/v4.9/fs/exec.c#L1290-L1318
	syscall.Close(l.stateDirFD)
	if err := syscall.Exec(name, l.config.Args[0:], os.Environ()); err != nil {
		return newSystemErrorWithCause(err, &amp;quot;exec user process&amp;quot;)
	}
	return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;结论&#34;&gt;&lt;del&gt;结论&lt;/del&gt;&lt;/h2&gt;

&lt;p&gt;&lt;del&gt;到此了问题还没解决。&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;问题的关键是执行&lt;strong&gt;docker create plugin&lt;/strong&gt;之后&lt;strong&gt;.sock&lt;/strong&gt;文件创建到哪里去了？为什么在&lt;strong&gt;config.json&lt;/strong&gt;指定成&lt;code&gt;/run/docker/plugins/sshfs.sock&lt;/code&gt;就可以在指定的目录下创建出.sock文件，说明&lt;strong&gt;创建socket的定义和get socket时寻找的路径不一样&lt;/strong&gt;，创建socket时就是固定在/run/docker/plugins目录下创建，而enable plugin的时候，Get socket的时候还要加上docker plugin的ID，可是按照官网的配置在本地create plugin后并没有在/run/docker/plugins目录下生成插件的socket文件，直到enable插件的时候才会生成以plugin ID命名的目录，但是socket文件没有！☹️&lt;/del&gt;&lt;/p&gt;

&lt;h2 id=&#34;问题解决&#34;&gt;问题解决&lt;/h2&gt;

&lt;p&gt;之所以出现上面的那些问题，是因为create docker plugin的时候有问题，也就是那个二进制文件有问题，我在&lt;strong&gt;Mac&lt;/strong&gt;上build的image，而且还没有用&lt;strong&gt;Dockerfile.dev&lt;/strong&gt;这个专门用来搭建二进制文件编译环境的Dockerfile来创建golang的编译环境，虽然docker plugin是创建成功了，但是当docker plugin enable的时候，这个热紧张文件不能正确的运行，所以就没能生成&lt;strong&gt;sshfs.sock&lt;/strong&gt;文件。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;请在Linux环境下使用&lt;strong&gt;make all&lt;/strong&gt;命令来创建plugin。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Docker 17.03-CE create plugin源码解析</title>
      <link>http://rootsongjc.github.io/blogs/docker-create-plugin/</link>
      <pubDate>Wed, 15 Mar 2017 12:09:26 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/docker-create-plugin/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20160403050.jpg&#34; alt=&#34;故宫博物院&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：故宫 Apr 3,2016）&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;继续上一篇&lt;a href=&#34;http://rootsongjc.github.io/blogs/docker-plugin-develop/&#34;&gt;Docker17.03-CE插件开发的🌰&lt;/a&gt;，今天来看下&lt;strong&gt;docker create plugin&lt;/strong&gt;的源码。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;cli/command/plugin/create.go&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Docker命令行&lt;code&gt;docker plugin create&lt;/code&gt;调用的，使用的是&lt;a href=&#34;http://github.com/spf13/cobra&#34;&gt;cobra&lt;/a&gt;，这个命令行工具开发包很好用，推荐下。&lt;/p&gt;

&lt;p&gt;执行这两个函数&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func newCreateCommand(dockerCli *command.DockerCli) *cobra.Command 
//调用下面的函数，拼装成URL调用RESTful API接口
func runCreate(dockerCli *command.DockerCli, options pluginCreateOptions) error {
  ...
  if err = dockerCli.Client().PluginCreate(ctx, createCtx, createOptions); err != nil {
		return err
	}
  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在&lt;strong&gt;api/server/router/plugin/plugin_routes.go&lt;/strong&gt;中&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func (pr *pluginRouter) createPlugin(ctx context.Context, w http.ResponseWriter, r *http.Request, vars map[string]string) error {
  ...
  if err := pr.backend.CreateFromContext(ctx, r.Body, options); err != nil {
		return err
	}
  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;createPlugin&lt;/strong&gt;这个方法定义在api/server/route/plugin/backen.go的&lt;strong&gt;Backend&lt;/strong&gt;接口中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PluginCreate&lt;/strong&gt;这个方法定义在docker/docker/client/Interface.go的&lt;strong&gt;PluginAPIClient&lt;/strong&gt;接口中。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;docker/client/plugin_create.go&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// PluginCreate creates a plugin
func (cli *Client) PluginCreate(ctx context.Context, createContext io.Reader, createOptions types.PluginCreateOptions) error {
	headers := http.Header(make(map[string][]string))
	headers.Set(&amp;quot;Content-Type&amp;quot;, &amp;quot;application/x-tar&amp;quot;)

	query := url.Values{}
	query.Set(&amp;quot;name&amp;quot;, createOptions.RepoName)

	resp, err := cli.postRaw(ctx, &amp;quot;/plugins/create&amp;quot;, query, createContext, headers)
	if err != nil {
		return err
	}
	ensureReaderClosed(resp)
	return err
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;plugin在后端接收到请求后会执行下面的方法。最终&lt;strong&gt;create plugin&lt;/strong&gt;的实现在plugin/backend_linux.go下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// CreateFromContext creates a plugin from the given pluginDir which contains
// both the rootfs and the config.json and a repoName with optional tag.
func (pm *Manager) CreateFromContext(ctx context.Context, tarCtx io.ReadCloser, options *types.PluginCreateOptions) (err error) {}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至于docker create plugin时docker后台究竟做了什么，就看👆那个文件。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>微服务设计读书笔记</title>
      <link>http://rootsongjc.github.io/talks/microservice-reading-notes/</link>
      <pubDate>Sat, 11 Mar 2017 15:45:27 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/talks/microservice-reading-notes/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20160625036.jpg&#34; alt=&#34;青海湖畔&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(题图：青海湖畔  Jun 25,2016)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;最近在看&lt;strong&gt;《微服务设计（Sam Newman著）》&lt;/strong&gt;这本书，&lt;a href=&#34;http://olz1di9xf.bkt.clouddn.com/docs/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1%E4%B8%AD%E6%96%87%E5%AE%8C%E6%95%B4%E7%89%88-Sam%20Newman-%E4%BA%BA%E6%B0%91%E9%82%AE%E7%94%B5%E5%87%BA%E7%89%88%E7%A4%BE.pdf&#34;&gt;下载本书PDF&lt;/a&gt;(扫描版，高清49.17M)。作者是&lt;strong&gt;ThoughtWorks&lt;/strong&gt;的Sam Newman。这本书中包括很多业界是用案例，比如&lt;strong&gt;Netflix&lt;/strong&gt;和&lt;strong&gt;亚马逊&lt;/strong&gt;。有兴趣的话大家一起看看讨论一下。😄&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1%E4%B9%A6%E7%9A%AE%E7%85%A7.jpg&#34; alt=&#34;微服务设计书皮照片&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;本书读者交流微信群二维码，扫码入群（3月18日前有效）&lt;/strong&gt;，如果二维码失效，请移步&lt;a href=&#34;http://rootsongjc.github.io/about/&#34;&gt;这里&lt;/a&gt;加我微信，拉你入群。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1%E4%BA%A4%E6%B5%81%E7%BE%A4%E5%BE%AE%E4%BF%A1%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg&#34; alt=&#34;二维码&#34; /&gt;&lt;/p&gt;

&lt;p&gt;P.S 这本书比较偏理论，另外还有一本中国人写的书，&lt;strong&gt;《微服务架构与实践，王磊著，电子工业出版社》&lt;/strong&gt;，&lt;a href=&#34;http://olz1di9xf.bkt.clouddn.com/docs/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AE%9E%E8%B7%B5-%E7%8E%8B%E7%A3%8A%E8%91%97-%E7%94%B5%E5%AD%90%E5%B7%A5%E4%B8%9A%E5%87%BA%E7%89%88%E7%A4%BE.pdf&#34;&gt;下载本书的pdf&lt;/a&gt;，文字版，大小28.08M。这个人同样也是&lt;strong&gt;ThoughtWorks&lt;/strong&gt;的，两个人的观点不谋而合，依然是便理论的东西。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cloud Native Go - 基于Go和React的web云服务构建指南&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这本书是我最近在翻译的，将由&lt;strong&gt;电子工业出版社&lt;/strong&gt;出版，本书根据实际案例教你如何构建一个web微服务，是实践为服务架构的很好的参考。&lt;a href=&#34;http://rootsongjc.github.io/talks/cloud-native-go/&#34;&gt;查看本书介绍&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;1-微服务初探&#34;&gt;1.微服务初探&lt;/h2&gt;

&lt;h3 id=&#34;什么是微服务&#34;&gt;什么是微服务？&lt;/h3&gt;

&lt;p&gt;微服务（Microservices）这个词比较新颖，但是其实这种架构设计理念早就有了。&lt;em&gt;微服务是一种分布式架构设计理念，为了推动细粒度服务的使用，这些服务要能协同工作，每个服务都有自己的生命周期。一个为服务就是一个独立的实体，可以独立的部署在PAAS平台上，也可以作为一个独立的进程在主机中运行。服务之间通过API访问，修改一个服务不会影响其它服务。&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;微服务的好处&#34;&gt;微服务的好处&lt;/h3&gt;

&lt;p&gt;微服务的好处有很多，包括:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;帮助你更快的采用新技术&lt;/li&gt;
&lt;li&gt;解决技术异构的问题，因为是用API网络通信，可以使用不同的语言和技术开发不同的服务&lt;/li&gt;
&lt;li&gt;增强系统弹性，服务的边界比较清晰，便于故障处理&lt;/li&gt;
&lt;li&gt;方便扩展，比如使用容器技术，可以很方便的一次性启动很多个微服务&lt;/li&gt;
&lt;li&gt;方便部署，因为微服务之间彼此独立，所以能够独立的部署单个服务而不影响其它服务，如果部署失败的话还可以回滚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;别忘了康为定律，微服务可以很好契合解决组织架构问题&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;可重用，可随意组合&lt;/li&gt;
&lt;li&gt;便于维护，可以随时重写服务，不必担心历史遗留问题&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;与面向服务架构soa的关系&#34;&gt;与面向服务架构SOA的关系&lt;/h3&gt;

&lt;p&gt;可以说微服务架构师SOA的一种，但是目前的大多数SOA做的都不好，在&lt;code&gt;通信协议的选择&lt;/code&gt;、&lt;code&gt;第三方中间件的选择&lt;/code&gt;、&lt;code&gt;服务力度如何划分&lt;/code&gt;方面做的都不够好。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;微服务与SOA的共同点&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;都使用共享库，比如可重用的代码库&lt;/li&gt;
&lt;li&gt;模块化，比如Java中的OSGI(Open Source Gateway Initiative)、Erlang中的模块化&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;2-架构师的职责&#34;&gt;2.架构师的职责&lt;/h2&gt;

&lt;h3 id=&#34;架构师应该关心是什么&#34;&gt;架构师应该关心是什么&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;架构师（Architect）&lt;/strong&gt;在英文中和&lt;strong&gt;建筑师&lt;/strong&gt;是同一个词，他们之间也有很多相同之处，架构师构建的是软件，而建筑师构建的是建筑。&lt;/p&gt;

&lt;p&gt;终于看到了我翻译的*Cloud Native Go*第14章中引用的这本书的原话了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1%E5%BC%95%E7%94%A8%E7%BF%BB%E8%AF%91.jpg&#34; alt=&#34;原话&#34; /&gt;&lt;/p&gt;

&lt;p&gt;软件的需求变更是&lt;strong&gt;来的那么快来的那么直接&lt;/strong&gt;，不像建筑那样可以在设计好后按照设计图纸一步步的去建设。&lt;/p&gt;

&lt;p&gt;架构师应该关心的是什么呢？&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;保证系统适合开发人员在上面工作&lt;/li&gt;
&lt;li&gt;关注服务之间的交互，不需要过于关注各个服务内部发生的事情，比如服务之间互相调用的接口，是使用&lt;code&gt;protocol buffer&lt;/code&gt;呢，还是使用&lt;code&gt;RESTful API&lt;/code&gt;，还是使用&lt;code&gt;Java RMI&lt;/code&gt;，这个才是架构师需要关注的问题，至于服务内部究竟使用什么，那就看开发人员自己了，&lt;strong&gt;架构师更需要关注系统的边界和分区&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;架构师应该与团队在一起，&lt;strong&gt;结对编程&lt;/strong&gt; 🤓🤓 了解普通工作，知道普通的工作是什么样子，做一个&lt;em&gt;代码架构师&lt;/em&gt; 😂&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;架构师应该做什么&#34;&gt;架构师应该做什么&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;提供原则指导实践，比如Heroku的&lt;a href=&#34;http://rootsongjc.github.io/blogs/12-factor-app/&#34;&gt;12因素法则&lt;/a&gt;用来指导SAAS应用架构一样，微服务架构设计也要有一套原则。&lt;/li&gt;
&lt;li&gt;提供要求标准，通过日志功能和监控对服务进行集中式管理，明确接口标准，提供安全性建议。&lt;/li&gt;
&lt;li&gt;代码治理。为开发人员提供范例和服务代码模板。&lt;/li&gt;
&lt;li&gt;解决技术债务。&lt;/li&gt;
&lt;li&gt;集中治理和领导。维持良好的团队关系，当团队跑偏的时候及时纠正。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;3-服务建模&#34;&gt;3.服务建模&lt;/h2&gt;

&lt;p&gt;以&lt;strong&gt;MusicCorp&lt;/strong&gt;这家公司的服务为例子讲解。&lt;/p&gt;

&lt;p&gt;服务建模的两个指导原则：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;高内聚：关键是找出问题的边界，把相关的问题放在同一个服务中。&lt;/li&gt;
&lt;li&gt;松耦合：修改一个服务不需要修改另一个。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用&lt;strong&gt;限定上下文&lt;/strong&gt;（一个由显示边界限定的特定指责）的方法将服务拆分，比如MusicCorp的服务可以拆分为：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;财务部门&lt;/li&gt;
&lt;li&gt;仓库&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;他们都不需要知道各自的具体实现，只要给它们提供特定的输入就会有你想要的产出。&lt;/p&gt;

&lt;p&gt;过早的将一个系统划分成微服务的代价非常高，尤其是在面对新领域时，将一个已有的代码库划分成微服务会比葱头开始建设微服务要简单的多。&lt;/p&gt;

&lt;h2 id=&#34;4-集成&#34;&gt;4.集成&lt;/h2&gt;

&lt;p&gt;使用共享数据库，为用户创建好接口，可以使用RPC（protocol buffer、thrift）或者REST。服务端和客户端消息格式可以用Json或XML。当然每种技术都有各自的适用场景，结合自己的业务选择。&lt;/p&gt;

&lt;p&gt;微服务的协作方式是什么样的呢？基于事件的异步通信，使用消息中间件来实现事件发布和消费者接收机制。比如用Kafka或RabbitMQ。&lt;/p&gt;

&lt;h2 id=&#34;5-分解单块系统&#34;&gt;5.分解单块系统&lt;/h2&gt;

&lt;p&gt;分解巨大无比没人感动的单块系统，首先要做的是理清代码库，找到&lt;strong&gt;接缝&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;分解系统带来的好处：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;加快以后系统开发速度&lt;/li&gt;
&lt;li&gt;划清了团队结构（又是康威定律）&lt;/li&gt;
&lt;li&gt;增加安全审计功能后，保障安全性&lt;/li&gt;
&lt;li&gt;利于开展新技术&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;6-部署&#34;&gt;6. 部署&lt;/h2&gt;

&lt;p&gt;这一块跟传统服务的部署并没有太大的不同，无非是微服务的短平快，加快了CI（持续集成）的速度。如果将微服务打包为docker镜像，使用Jenkins、ansible、puppet等技术来部署微服务可以实现部署自动和效率的显著提高。&lt;/p&gt;

&lt;h2 id=&#34;其它&#34;&gt;其它&lt;/h2&gt;

&lt;p&gt;该书的后面还讲了&lt;strong&gt;测试&lt;/strong&gt;、&lt;strong&gt;监控&lt;/strong&gt;、&lt;strong&gt;安全&lt;/strong&gt;、&lt;strong&gt;康威定律&lt;/strong&gt;、最后还上升到&lt;strong&gt;人本&lt;/strong&gt;，给予广大的软件开发人员强烈的人文关怀，可见提倡架构师要融入团队，最一个&lt;strong&gt;代码架构师&lt;/strong&gt;和&lt;strong&gt;结对编程&lt;/strong&gt;的作者是多么博爱❤️。&lt;/p&gt;

&lt;p&gt;该书的核心部分是&lt;strong&gt;第11章规模化微服务&lt;/strong&gt;，为将在下篇中来探讨一下。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker v.s Kubernetes part2</title>
      <link>http://rootsongjc.github.io/blogs/docker-vs-kubernetes-part2/</link>
      <pubDate>Fri, 10 Mar 2017 22:06:32 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/docker-vs-kubernetes-part2/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20160709044.jpg&#34; alt=&#34;承德兴隆星空&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：河北承德兴隆县雾灵山京郊最佳星空拍摄点 July 9,2016)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;本文是&lt;code&gt;Docker v.s Kubernetes&lt;/code&gt;第二篇，续接上文&lt;a href=&#34;http://rootsongjc.github.io/blogs/docker-vs-kubernetes-part1/&#34;&gt;Docker v.s Kuberntes Part1&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;Kubernetes是典型的&lt;strong&gt;Master/Slave&lt;/strong&gt;架构模式，本文简要的介绍kubenetes的架构和组件构成。&lt;/p&gt;

&lt;h2 id=&#34;kubernetes核心架构&#34;&gt;Kubernetes核心架构&lt;/h2&gt;

&lt;h3 id=&#34;master节点&#34;&gt;master节点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;apiserver：作为kubernetes系统的入口，封装了核心对象的增删改查操作，以RESTFul接口方式提供给外部客户和内部组件调用。它维护的REST对象将持久化到etcd（一个分布式强一致性的key/value存储）。&lt;/li&gt;
&lt;li&gt;scheduler：负责集群的资源调度，为新建的Pod分配机器。这部分工作分出来变成一个组件，意味着可以很方便地替换成其他的调度器。&lt;/li&gt;
&lt;li&gt;controller-manager：负责执行各种控制器，目前有两类：

&lt;ol&gt;
&lt;li&gt;endpoint-controller：定期关联service和Pod(关联信息由endpoint对象维护)，保证service到Pod的映射总是最新的。&lt;/li&gt;
&lt;li&gt;replication-controller：定期关联replicationController和Pod，保证replicationController定义的复制数量与实际运行Pod的数量总是一致的。&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;node节点&#34;&gt;node节点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;kubelet：负责管控docker容器，如启动/停止、监控运行状态等。它会定期从etcd获取分配到本机的Pod，并根据Pod信息启动或停止相应的容器。同时，它也会接收apiserver的HTTP请求，汇报Pod的运行状态。&lt;/li&gt;
&lt;li&gt;proxy：负责为Pod提供代理。它会定期从etcd获取所有的service，并根据service信息创建代理。当某个客户Pod要访问其他Pod时，访问请求会经过本机proxy做转发。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://valleylord.github.io/images/201601-kubernetes-concepts/kubernetes-masterslave.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;kubernetes组件详细介绍&#34;&gt;Kubernetes组件详细介绍&lt;/h2&gt;

&lt;h3 id=&#34;etcd&#34;&gt;etcd&lt;/h3&gt;

&lt;p&gt;虽然不是Kubernetes的组件但是有必要提一下，etcd是一个分布式协同数据库，基于Go语言开发，&lt;code&gt;CoreOS&lt;/code&gt;公司出品，使用&lt;a href=&#34;http://rootsongjc.github.io/blogs/raft/&#34;&gt;raft一致性算法&lt;/a&gt;协同。Kubernetes的主数据库，在安装kubernetes之前就要先安装它，很多开源下项目都用到，老版本的&lt;code&gt;docker swarm&lt;/code&gt;也用到了它。目前主要使用的是&lt;code&gt;2.7.x&lt;/code&gt;版本，&lt;code&gt;3.0+&lt;/code&gt;版本的API变化太大。&lt;/p&gt;

&lt;h3 id=&#34;apiserver&#34;&gt;APIServer&lt;/h3&gt;

&lt;p&gt;APIServer负责对外提供kubernetes API服务，它运行在master节点上。任何对资源的增删改查都要交给APIServer处理后才能提交给etcd。APIServer总体上由两部分组成：HTTP/HTTPS服务和一些功能性插件。这些功能性插件又分为两种：一部分与底层IaaS平台（Cloud Provide）相关；另一部分与资源管理控制（Admission Control）相关。&lt;/p&gt;

&lt;h3 id=&#34;scheduler&#34;&gt;Scheduler&lt;/h3&gt;

&lt;p&gt;Scheduler的作用是&lt;strong&gt;根据特定的调度算法将pod调度到node节点上&lt;/strong&gt;，这一过程也被称为绑定。Scheduler调度器的输入是待调度的pod和可用的工作节点列表，输出则是一个已经绑定了pod的节点，这个节点是通过调度算法在工作节点列表中选择的最优节点。&lt;/p&gt;

&lt;p&gt;工作节点从哪里来？工作节点并不是由Kubernetes创建，它是由IaaS平台创建，或者就是由用户管理的物理机或者虚拟机。但是Kubernetes会创建一个Node对象，用来描述这个工作节点。描述的具体信息由创建Node对象的配置文件给出。一旦用户创建节点的请求被成功处理，Kubernetes又会立即在内部创建一个node对象，再去检查该节点的健康状况。只有那些当前可用的node才会被认为是一个有效的节点并允许pod调度到上面运行。&lt;/p&gt;

&lt;p&gt;工作节点可以通过资源配置文件或者kubectl命令行工具来创建。Kubernetes主要维护工作节点的两个属性：spec和status来描述一个工作节点的期望状态和当前状态。其中，所谓的当前状态信息由3个信息组成：&lt;code&gt;HostIp&lt;/code&gt;、&lt;code&gt;NodePhase&lt;/code&gt;和&lt;code&gt;Node Condition&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;工作节点的动态维护过程依靠&lt;strong&gt;Node Controller&lt;/strong&gt;来完成，它是&lt;code&gt;Kubernetes Controller Manager&lt;/code&gt;下属的一个控制器。它会一直不断的检查Kubernetes已知的每台node节点是否正常工作，如果一个之前已经失败的节点在这个检查循环中被检查为可以工作的，那么Node Controller会把这个节点添加到工作节点中，Node Controller会从工作节点中删除这个节点。&lt;/p&gt;

&lt;h3 id=&#34;controller-manager&#34;&gt;Controller Manager&lt;/h3&gt;

&lt;p&gt;Controller Manager运行在集群的Master节点上，是基于pod API的一个独立服务，它&lt;strong&gt;重点实现service Endpoint（服务端点）的动态更新&lt;/strong&gt;。管理着Kubernetes集群中各种控制节点，包括&lt;strong&gt;replication Controller&lt;/strong&gt;和&lt;strong&gt;node Controller&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;与APIServer相比，APIServer负责接受用户请求并创建对应的资源，而Controller Manager在系统中扮演的角色是在一旁旁默默的管控这些资源，确保他们永远保持在预期的状态&lt;/strong&gt;。它采用各种管理器定时的对pod、节点等资源进行预设的检查，然后判断出于预期的是否一致，若不一致，则通知APIServer采取行动，比如重启、迁移、删除等。&lt;/p&gt;

&lt;h3 id=&#34;kubelet&#34;&gt;kubelet&lt;/h3&gt;

&lt;p&gt;kubelet组件工作在Kubernetes的node上，&lt;strong&gt;负责管理和维护在这台主机上运行着的所有容器&lt;/strong&gt;。 kubelet与cAdvisor交互来抓取docker容器和主机的资源信息。 kubelet垃圾回收机制，包括容器垃圾回收和镜像垃圾回收。 kubelet工作节点状态同步。&lt;/p&gt;

&lt;h3 id=&#34;kube-proxy&#34;&gt;kube-proxy&lt;/h3&gt;

&lt;p&gt;kube-proxy提供两种功能:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;提供算法将客服端流量负载均衡到service对应的一组后端pod。&lt;/li&gt;
&lt;li&gt;使用etcd的watch机制，实现服务发现功能，维护一张从service到endpoint的映射关系，从而保证后端pod的IP变化不会对访问者的访问造成影响。&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Docker v.s Kubernetes part1</title>
      <link>http://rootsongjc.github.io/blogs/docker-vs-kubernetes-part1/</link>
      <pubDate>Fri, 10 Mar 2017 21:09:47 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/docker-vs-kubernetes-part1/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20161016031.jpg&#34; alt=&#34;杭州西湖&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：杭州西湖 Oct 16,2016）&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;前言&#34;&gt;前言&lt;/h3&gt;

&lt;p&gt;这一系列文章是对比kubernetes 和docker两者之间的差异，鉴于我之前从docker1.10.3起开始使用docker，对原生docker的了解比较多，最近又正在看&lt;strong&gt;Kunernetes权威指南（第二版）&lt;/strong&gt;这本书（P.S感谢&lt;u&gt;电子工业出版社&lt;/u&gt;的编辑朋友赠送此书）。这系列文章不是为了比较孰优孰劣，&lt;strong&gt;适合自己的才是最好的&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;此系列文章中所说的&lt;strong&gt;docker&lt;/strong&gt;指的是*17.03-ce*版本。&lt;/p&gt;

&lt;h3 id=&#34;概念性的差别&#34;&gt;概念性的差别&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;了解一样东西首先要高屋建瓴的了解它的概念，kubernetes包括以下几种资源对象：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/abstractions/pod/&#34;&gt;Pod&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Service&lt;/li&gt;
&lt;li&gt;Volume&lt;/li&gt;
&lt;li&gt;Namespace&lt;/li&gt;
&lt;li&gt;ReplicaSet&lt;/li&gt;
&lt;li&gt;Deployment&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/abstractions/controllers/statefulsets/&#34;&gt;StatefulSet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;DaemonSet&lt;/li&gt;
&lt;li&gt;Job&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Docker&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Docker的资源对象相对于kubernetes来说就简单多了，只有以下几个：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Service&lt;/li&gt;
&lt;li&gt;Node&lt;/li&gt;
&lt;li&gt;Stack&lt;/li&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;就这么简单，使用一个*docker-compose.yml*即可以启动一系列服务。当然简单的好处是便于理解和管理，但是在功能方面就没有kubernetes那么强大了。&lt;/p&gt;

&lt;h3 id=&#34;功能性差别&#34;&gt;功能性差别&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Kubernetes 资源限制 CPU 100m千分之一核为单位，绝对值，requests 和limits，超过这个值可能被杀掉，资源限制力度比docker更细。&lt;/li&gt;
&lt;li&gt;Pod中有个最底层的pause 容器，其他业务容器共用他的IP，docker因为没有这层概念，所以没法共用IP，而是使用overlay网络同处于一个网络里来通信。&lt;/li&gt;
&lt;li&gt;Kubernetes在rc中使用环境变量传递配置（1.3版本是这样的，后续版本还没有研究过）&lt;/li&gt;
&lt;li&gt;Kuberentes Label 可以在开始和动态的添加修改，所有的资源对象都有，这一点docker也有，但是资源调度因为没有kubernetes那么层级，所有还是相对比较弱一些。&lt;/li&gt;
&lt;li&gt;Kubernetes对象选择机制继续通过label selector，用于对象调度。&lt;/li&gt;
&lt;li&gt;Kubernetes中有一个比较特别的镜像，叫做&lt;code&gt;google_containers/pause&lt;/code&gt;，这个镜像是用来实现Pod概念的。&lt;/li&gt;
&lt;li&gt;HPA horizontal pod autoscaling 横向移动扩容，也是一种资源对象，根据负载变化情况针对性的调整pod目标副本数。&lt;/li&gt;
&lt;li&gt;Kubernetes中有三个IP，Node,Pod,Cluster IP的关系比较复杂，docker中没有Cluster IP的概念。&lt;/li&gt;
&lt;li&gt;持久化存储，在Kubernetes中有Persistent volume 只能是网络存储，不属于任何node，独立于pod之外，而docker只能使用&lt;code&gt;volume plugin&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;多租户管理，kubernetes中有`Namespace，docker暂时没有多租户管理功能。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总体来说Docker架构更加简单，使用起来也没有那么多的配置，只需要每个结点都安装docker即可，调度和管理功能没kubernetes那么复杂。但是kubernetes本身就是一个通用的数据中心管理工具，不仅可以用来管理docker，*pod*这个概念里就可以运行不仅是docker了。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;以后的文章中将结合docker着重讲Kubernetes，基于1.3版本。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Contiv入坑指南-v2plugin</title>
      <link>http://rootsongjc.github.io/blogs/contiv-v2plugin/</link>
      <pubDate>Fri, 10 Mar 2017 11:51:09 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/contiv-v2plugin/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20161022082.jpg&#34; alt=&#34;上海交通大学&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(题图：上海交通大学 Oct 22,2016)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;继续趟昨天挖的坑。&lt;/p&gt;

&lt;p&gt;昨天的&lt;a href=&#34;https://github.com/contiv/netplugin/issues/776&#34;&gt;issue-776&lt;/a&gt;已经得到@gkvijay的回复，原来是因为没有安装contiv/v2plugin的缘故，所以create contiv network失败，我需要自己build一个&lt;strong&gt;docker plugin&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;查看下这个&lt;a href=&#34;https://github.com/contiv/netplugin/commit/8afd1b7718c8424a876760d18484124e0aad3557&#34;&gt;commit&lt;/a&gt;里面有build &lt;strong&gt;v2plugin&lt;/strong&gt;的脚本更改，所以直接调用以下命令就可以build自己的v2plugin。&lt;/p&gt;

&lt;p&gt;前提你需要先build出&lt;code&gt;netctl&lt;/code&gt;、&lt;code&gt;netmaster&lt;/code&gt;、&lt;code&gt;netplugin&lt;/code&gt;三个二进制文件并保存到&lt;strong&gt;bin&lt;/strong&gt;目录下，如果你没自己build直接下载&lt;strong&gt;release&lt;/strong&gt;里面的文件保存进去也行。&lt;/p&gt;

&lt;h3 id=&#34;编译v2plugin插件&#34;&gt;编译v2plugin插件&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;修改config.json插件配置文件&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Json&#34;&gt;{
    &amp;quot;manifestVersion&amp;quot;: &amp;quot;v0&amp;quot;,
    &amp;quot;description&amp;quot;: &amp;quot;Contiv network plugin for Docker&amp;quot;,
    &amp;quot;documentation&amp;quot;: &amp;quot;https://contiv.github.io&amp;quot;,
    &amp;quot;entrypoint&amp;quot;: [&amp;quot;/startcontiv.sh&amp;quot;],
    &amp;quot;network&amp;quot;: {
           &amp;quot;type&amp;quot;: &amp;quot;host&amp;quot;
    },
    &amp;quot;env&amp;quot;: [
       {
          &amp;quot;Description&amp;quot;: &amp;quot;To enable debug mode, set to &#39;-debug&#39;&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;dbg_flag&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;-debug&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;VLAN uplink interface used by OVS&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;iflist&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;Etcd or Consul cluster store url&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;cluster_store&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;etcd://172.20.0.113:2379&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;Local IP address to be used by netplugin for control communication&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;ctrl_ip&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;none&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;Local VTEP IP address to be used by netplugin&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;vtep_ip&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;none&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;In &#39;master&#39; role, plugin runs netmaster and netplugin&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;plugin_role&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;master&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;Netmaster url to listen http requests on&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;listen_url&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;172.20.0.113:9999&amp;quot;
       },
       {
          &amp;quot;Description&amp;quot;: &amp;quot;Network Driver name for requests to dockerd. Should be same as name:tag of the plugin&amp;quot;,
          &amp;quot;Name&amp;quot;: &amp;quot;plugin_name&amp;quot;,
          &amp;quot;Settable&amp;quot;: [
             &amp;quot;value&amp;quot;
          ],
          &amp;quot;Value&amp;quot;: &amp;quot;contiv/v2plugin:latest&amp;quot;
       }
    ],
    &amp;quot;mounts&amp;quot;: [
       {
          &amp;quot;type&amp;quot;: &amp;quot;bind&amp;quot;,
          &amp;quot;options&amp;quot;: [&amp;quot;rbind&amp;quot;],
          &amp;quot;source&amp;quot;: &amp;quot;/etc/openvswitch&amp;quot;,
          &amp;quot;destination&amp;quot;: &amp;quot;/etc/openvswitch&amp;quot;
       },
       {
          &amp;quot;type&amp;quot;: &amp;quot;bind&amp;quot;,
          &amp;quot;options&amp;quot;: [&amp;quot;rbind&amp;quot;],
          &amp;quot;source&amp;quot;: &amp;quot;/var/log/openvswitch&amp;quot;,
          &amp;quot;destination&amp;quot;: &amp;quot;/var/log/openvswitch&amp;quot;
       },
       {
          &amp;quot;type&amp;quot;: &amp;quot;bind&amp;quot;,
          &amp;quot;options&amp;quot;: [&amp;quot;rbind&amp;quot;],
          &amp;quot;source&amp;quot;: &amp;quot;/var/run&amp;quot;,
          &amp;quot;destination&amp;quot;: &amp;quot;/var/run&amp;quot;
       },
       {
          &amp;quot;type&amp;quot;: &amp;quot;bind&amp;quot;,
          &amp;quot;options&amp;quot;: [&amp;quot;rbind&amp;quot;],
          &amp;quot;source&amp;quot;: &amp;quot;/lib/modules&amp;quot;,
          &amp;quot;destination&amp;quot;: &amp;quot;/lib/modules&amp;quot;
       }
    ],
    &amp;quot;interface&amp;quot; : {
          &amp;quot;types&amp;quot;: [&amp;quot;docker.networkdriver/1.0&amp;quot;, &amp;quot;docker.ipamdriver/1.0&amp;quot;],
          &amp;quot;socket&amp;quot;: &amp;quot;netplugin.sock&amp;quot;
    },
    &amp;quot;Linux&amp;quot;: {
          &amp;quot;Capabilities&amp;quot;: [&amp;quot;CAP_SYS_ADMIN&amp;quot;, &amp;quot;CAP_NET_ADMIN&amp;quot;, &amp;quot;CAP_SYS_MODULE&amp;quot;]
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/docker/docker/blob/master/docs/extend/config.md&#34;&gt;关于&lt;strong&gt;docker plugin v2&lt;/strong&gt;配置文件的说明&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;方法一&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;自动化make&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$make host-pluginfs-create
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;方法二&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;直接调用Makefile里指定的那个shell脚本&lt;code&gt;scripts/v2plugin_rootfs.sh&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;$bash scripts/v2plugin_rootfs
Creating rootfs for v2plugin ,
sed: 1: &amp;quot;install/v2plugin/config ...&amp;quot;: command i expects \ followed by text
Sending build context to Docker daemon 73.94 MB
Step 1/5 : FROM alpine:3.5
 ---&amp;gt; 4a415e366388
Step 2/5 : MAINTAINER Cisco Contiv (http://contiv.github.io/)
 ---&amp;gt; Running in fada1677341b
 ---&amp;gt; f0440792dff6
Removing intermediate container fada1677341b
Step 3/5 : RUN mkdir -p /run/docker/plugins /etc/openvswitch /var/run/contiv/log     &amp;amp;&amp;amp; echo &#39;http://dl-cdn.alpinelinux.org/alpine/v3.4/main&#39; &amp;gt;&amp;gt; /etc/apk/repositories     &amp;amp;&amp;amp; apk update &amp;amp;&amp;amp; apk add openvswitch=2.5.0-r0 iptables
 ---&amp;gt; Running in 2ae2fbee6834
fetch http://dl-cdn.alpinelinux.org/alpine/v3.5/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.5/community/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.4/main/x86_64/APKINDEX.tar.gz
v3.5.2-3-g3649125268 [http://dl-cdn.alpinelinux.org/alpine/v3.5/main]
v3.5.1-71-gc7bb9a04f0 [http://dl-cdn.alpinelinux.org/alpine/v3.5/community]
v3.4.6-81-g1f1f409 [http://dl-cdn.alpinelinux.org/alpine/v3.4/main]
OK: 13194 distinct packages available
(1/6) Installing libmnl (1.0.4-r0)
(2/6) Installing libnftnl-libs (1.0.7-r0)
(3/6) Installing iptables (1.6.0-r0)
(4/6) Installing libcrypto1.0 (1.0.2k-r0)
(5/6) Installing libssl1.0 (1.0.2k-r0)
(6/6) Installing openvswitch (2.5.0-r0)
Executing busybox-1.25.1-r0.trigger
OK: 19 MiB in 17 packages
 ---&amp;gt; b130141ad660
Removing intermediate container 2ae2fbee6834
Step 4/5 : COPY netplugin netmaster netctl startcontiv.sh /
 ---&amp;gt; 2b88b2f8e5e7
Removing intermediate container d7580a394c64
Step 5/5 : ENTRYPOINT /startcontiv.sh
 ---&amp;gt; Running in e6fc5c887cb3
 ---&amp;gt; 1c569e4c633d
Removing intermediate container e6fc5c887cb3
Successfully built 1c569e4c633d
Password:
03d60dc01488362156f98a062d17af7a34e4b17569c2fe4f5d2048d619860314
Untagged: contivrootfs:latest
Deleted: sha256:1c569e4c633d27bd3e79d9d30b2825ce57452d30f90a3452304b932835331b13
Deleted: sha256:2b88b2f8e5e7bae348bf296f6254662c1d444760db5acd1764b9c955b106adad
Deleted: sha256:b60594671dc9312bf7ba73bf17abb9704d2b0d0e802c0d990315c5b4a5ca11fe
Deleted: sha256:b130141ad660d4ee291d9eb9a1e0704c4bc009fc91a73de28e8fd110aa45c481
Deleted: sha256:ab3c02d5a171681ba00d27f2c456cf8b63eeeaf408161dc84d9d89526d0399de
Deleted: sha256:f0440792dff6a89e321cc5d34ecaa21b4cb993f0c4e4df6c2b04eef8878bb471
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;创建镜像这一步需要输入你的docker hub密码。而且alpine下载软件需要翻墙的。打包v2plugin目录需要使用sudo，不然会报一个错。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;整个插件打包压缩后的大小是91M。现在&lt;code&gt;rootfs&lt;/code&gt;和&lt;code&gt;config.json&lt;/code&gt;都已经有了，就可以在你自己的系统上create docker plugin了。&lt;/p&gt;

&lt;h2 id=&#34;启动contiv-plugin&#34;&gt;启动contiv plugin&lt;/h2&gt;

&lt;p&gt;创建docker network plugin并enable。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;$docker plugin create contiv/v2plugin .
contiv/v2plugin
$docker plugin enable contiv/v2plugin
$docker plugin ls
ID                  NAME                     DESCRIPTION                        ENABLED
574d4a4d82a3        contiv/v2plugin:latest   Contiv network plugin for Docker   true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至此*contiv plugin*已经创建好了，enable后执行&lt;code&gt;ip addr&lt;/code&gt;命令可以看到多出一个网络*contivh0*。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;contivh0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UNKNOWN qlen 1000
link/ether 02:02:ac:13:ff:fe brd ff:ff:ff:ff:ff:ff
inet 172.19.255.254/16 scope global contivh0
	valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;且主机多了一个IP地址*172.19.255.254*。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;不需要再主机上安装&lt;code&gt;netctl&lt;/code&gt;、&lt;code&gt;netmaster&lt;/code&gt;、&lt;code&gt;netplugin&lt;/code&gt;这几个二进制文件了，只需要安装&lt;code&gt;docker plugin&lt;/code&gt;即可，这些都已经封装到plugin中了，如果你看下插件的目录结构就知道了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;因为插件安装的问题，目前我测试机上的自定义插件都无法使用，正在troubleshooting中，一旦有进展会及时更新该文档。&lt;/p&gt;

&lt;p&gt;另外正在同步跟开发者沟通中，因为时差问题，下周一才能有结果。😪&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Contiv入坑指南-试用全记录</title>
      <link>http://rootsongjc.github.io/blogs/contiv-tryout/</link>
      <pubDate>Thu, 09 Mar 2017 14:23:04 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/contiv-tryout/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/2017013129.jpg&#34; alt=&#34;黄昏&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(题图：山东荣成滨海风力发电场  Jan 31,2017）&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;关于contiv的介绍请看我的上一篇文章&lt;a href=&#34;http://rootsongjc.github.io/post/contiv_guide/&#34;&gt;Contiv Intro&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;开发环境使用&lt;strong&gt;Vagrant&lt;/strong&gt;搭建，昨天试用了下，真不知道它们是怎么想的，即然是docker插件为啥不直接在docker中开发呢，我有篇文章介绍&lt;a href=&#34;http://rootsongjc.github.io/post/docker-dev-env/&#34;&gt;如何搭建docker开发环境&lt;/a&gt;，可以在docker中开发docker，当然也可以用来开发contiv啊😄，只要下载一个docker镜像&lt;code&gt;dockercore/docker:latest&lt;/code&gt;即可，不过有点大2.31G，使用阿里云的mirror下载倒是也划算，总比你自己部署一个开发环境节省时间。&lt;/p&gt;

&lt;h3 id=&#34;contiv概念解析&#34;&gt;Contiv概念解析&lt;/h3&gt;

&lt;p&gt;Contiv用于给容器创建和分配网路，可以创建策略管理容器的安全、带宽、优先级等，相当于一个SDN。&lt;/p&gt;

&lt;h4 id=&#34;group&#34;&gt;Group&lt;/h4&gt;

&lt;p&gt;按容器或Pod的功能给容器分配策略组，通常是按照容器/Pod的&lt;code&gt;label&lt;/code&gt;来分组，应用组跟contiv的network不是一一对应的，可以很多应用组属于同一个network或IP subnet。&lt;/p&gt;

&lt;h4 id=&#34;polices&#34;&gt;Polices&lt;/h4&gt;

&lt;p&gt;用来限定group的行为，contiv支持两种类型的policy：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Bandwidth 限定应用组的资源使用上限&lt;/li&gt;
&lt;li&gt;Isolation 资源组的访问权限&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Group可以同时应用一个或多个policy，当有容器调度到该group里就会适用该group的policy。&lt;/p&gt;

&lt;h4 id=&#34;network&#34;&gt;Network&lt;/h4&gt;

&lt;p&gt;IPv4或IPv6网络，可以配置subnet和gateway。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Contiv中的网络&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在contiv中可以配置两种类型的网络&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;application network：容器使用的网络&lt;/li&gt;
&lt;li&gt;infrastructure network：host namespace的虚拟网络，比如基础设施监控网络&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;网络封装&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Contiv中有两种类型的网络封装&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Routed：overlay topology和L3-routed BGP topology&lt;/li&gt;
&lt;li&gt;Bridged：layer2 VLAN&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;tenant&#34;&gt;Tenant&lt;/h4&gt;

&lt;p&gt;Tenant提供contiv中的namespace隔离。一个tenant可以有很多个network，每个network都有个subnet。该tenant中的用户可以使用它的任意network和subnet的IP。&lt;/p&gt;

&lt;p&gt;物理网络中的tenant称作&lt;code&gt;虚拟路由转发(VRF)&lt;/code&gt;。Contiv使用VLAN和VXLAN ID来实现外部网络访问，这取决你使用的是layer2、layer3还是Cisco ACI。&lt;/p&gt;

&lt;h3 id=&#34;contiv下载&#34;&gt;Contiv下载&lt;/h3&gt;

&lt;p&gt;Contiv的编译安装比较复杂，我们直接下载github上的&lt;a href=&#34;[1.0.0-beta.3-03-08-2017.18-51-20.UTC](https://github.com/contiv/netplugin/releases/tag/1.0.0-beta.3-03-08-2017.18-51-20.UTC)&#34;&gt;release-1.0.0-beta.3-03-08-2017.18-51-20.UTC&lt;/a&gt;文件解压获得二进制文件安装。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/contiv/install/blob/master/README.md这个官方文档已经过时，不要看了。&#34;&gt;https://github.com/contiv/install/blob/master/README.md这个官方文档已经过时，不要看了。&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;如果试用可以的话，我会后续写contiv开发环境搭建的文章。&lt;/p&gt;

&lt;p&gt;这个release是2017年3月8日发布的，就在我写这篇文章的前一天。有个&lt;strong&gt;最重要的更新&lt;/strong&gt;是&lt;u&gt;支持docker1.13 swarm mode&lt;/u&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/contiv/netplugin/blob/master/install/HowtoSetupContiv.md&#34;&gt;官方安装文档&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;下载解压后会得到如下几个文件：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;contivk8s  k8s专用的&lt;/li&gt;
&lt;li&gt;contrib  文件夹，里面有个&lt;code&gt;netctl&lt;/code&gt;的bash脚本&lt;/li&gt;
&lt;li&gt;netcontiv  这个命令就一个-version选项用来查看contiv的版本😓&lt;/li&gt;
&lt;li&gt;netctl  contiv命令行工具，用来配置网络、策略、服务负载均衡，&lt;a href=&#34;http://contiv.github.io/documents/reference/netctlcli.html&#34;&gt;使用说明&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;netmaster  contiv的主节点服务&lt;/li&gt;
&lt;li&gt;netplugin&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面的安装中用到的只有netctl、netmaster和netplugin这三个二进制文件。&lt;/p&gt;

&lt;p&gt;我们将这三个文件都copy到/usr/bin目录下。&lt;/p&gt;

&lt;p&gt;我们在docker17.03-ce中安装contiv。&lt;/p&gt;

&lt;h3 id=&#34;contiv安装依赖&#34;&gt;Contiv安装依赖&lt;/h3&gt;

&lt;p&gt;Contiv依赖于consul或etcd，我们选择使用etcd，slack里的人说只支持2.3.x版本，可能不支持3.0+版本的吧，还没实际测过，先使用2.3.7。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;contiv master&lt;/code&gt;启动后自动向etcd中注册信息：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/contiv.io/oper
/contiv.io/oper/auto-vlan
/contiv.io/oper/auto-vlan/global
/contiv.io/oper/auto-vxlan
/contiv.io/oper/auto-vxlan/global
/contiv.io/oper/global
/contiv.io/oper/global/global
/contiv.io/oper/ovs-driver
/contiv.io/oper/ovs-driver/sz-pg-oam-docker-test-001.tendcloud.com
/contiv.io/master
/contiv.io/master/config
/contiv.io/master/config/global
/contiv.io/obj
/contiv.io/obj/modeldb
/contiv.io/obj/modeldb/global
/contiv.io/obj/modeldb/global/global
/contiv.io/obj/modeldb/tenant
/contiv.io/obj/modeldb/tenant/default
/contiv.io/lock
/contiv.io/lock/netmaster
/contiv.io/lock/netmaster/leader
/contiv.io/service
/contiv.io/service/netmaster
/contiv.io/service/netmaster/172.20.0.113:9999
/contiv.io/service/netmaster.rpc
/contiv.io/service/netmaster.rpc/172.20.0.113:9001
/contiv.io/state
/contiv.io/state/auto-vlan
/contiv.io/state/auto-vlan/global
/contiv.io/state/auto-vxlan
/contiv.io/state/auto-vxlan/global
/contiv.io/state/global
/contiv.io/state/global/global
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;contiv启动&#34;&gt;Contiv启动&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;启动netmaster&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$nohup netmaster -cluster-mode docker -cluster-store etcd://172.20.0.113:2379 -debug -listen-url 172.20.0.113:9999 -plugin-name netplugin &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为了突出netmaster命令的使用，我把所有可以使用默认值的参数都明确的写出。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;netmaster&lt;/code&gt;监听9999端口。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;查看已有的contiv网络&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$netctl --netmaster http://172.20.0.113:9999 network ls
Tenant  Network  Nw Type  Encap type  Packet tag  Subnet   Gateway  IPv6Subnet  IPv6Gateway
------  -------  -------  ----------  ----------  -------  ------   ----------  -----------
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为了以后执行命令方便，不用来回输入&lt;code&gt;$NETMASTER&lt;/code&gt;地址，可以将其设置为环境变量&lt;/p&gt;

&lt;p&gt;&lt;code&gt;export NETMASTER=&amp;quot;http://172.20.0.113:9999&amp;quot;&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;netplugin需要使用Open vSwitch，所以你需要先安装&lt;strong&gt;Open vSwitch&lt;/strong&gt;。否则你会遇到这个问题&lt;a href=&#34;https://github.com/contiv/netplugin/issues/760&#34;&gt;netplugin issue-760&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;open-vswitch安装&#34;&gt;Open vSwitch安装&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://supercomputing.caltech.edu/blog/index.php/2016/05/03/open-vswitch-installation-on-centos-7-2/&#34;&gt;Open vSwitch installation on CentOS7.2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;参考上面链接里的方法。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#!/bin/bash
yum -y install make gcc openssl-devel autoconf automake rpm-build redhat-rpm-config python-devel openssl-devel kernel-devel kernel-debug-devel libtool wget
mkdir -p ~/rpmbuild/SOURCES
cp openvswitch-2.5.1.tar.gz ~/rpmbuild/SOURCES/
tar xfz openvswitch-2.5.1.tar.gz
sed &#39;s/openvswitch-kmod, //g&#39; openvswitch-2.5.1/rhel/openvswitch.spec &amp;gt; openvswitch-2.5.1/rhel/openvswitch_no_kmod.spec
rpmbuild -bb --nocheck ~/openvswitch-2.5.1/rhel/openvswitch_no_kmod.spec
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;编译好的rpm包在&lt;code&gt;~/rpmbuild/RPMS/x86_64/openvswitch-2.5.1-1.x86_64.rpm&lt;/code&gt;目录下。&lt;/p&gt;

&lt;p&gt;安装好Open vSwitch后就可以启动&lt;strong&gt;netplugin&lt;/strong&gt;。&lt;/p&gt;

&lt;h3 id=&#34;创建contiv网络&#34;&gt;创建contiv网络&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;启动netplugin&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;nohup netplugin -cluster-store etcd://172.20.0.113:2379 &amp;amp;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;创建network&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;netctl --netmaster http://172.20.0.113:9999 network create --subnet=10.1.2.0/24 contiv-net&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;获得以下报错：&lt;/p&gt;

&lt;p&gt;ERRO[0000] Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&lt;/p&gt;

&lt;p&gt;但是执行第二次的时候居然成功了，不过当我查看docker network的时候根本就看不到刚刚创建的contiv-net网络。*这只是一场游戏一场梦。。。*😢&lt;/p&gt;

&lt;p&gt;Creating network default:contiv-net&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$netctl network ls
Tenant   Network     Nw Type  Encap type  Packet tag  Subnet       Gateway  IPv6Subnet  IPv6Gateway
------   -------     -------  ----------  ----------  -------      ------   ----------  -----------
default  contiv-net  data     vxlan       0           10.1.2.0/24  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看刚创建的contiv-net网络。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$netctl network inspect contiv-net
Inspeting network: contiv-net tenant: default
{
  &amp;quot;Config&amp;quot;: {
    &amp;quot;key&amp;quot;: &amp;quot;default:contiv-net&amp;quot;,
    &amp;quot;encap&amp;quot;: &amp;quot;vxlan&amp;quot;,
    &amp;quot;networkName&amp;quot;: &amp;quot;contiv-net&amp;quot;,
    &amp;quot;nwType&amp;quot;: &amp;quot;data&amp;quot;,
    &amp;quot;subnet&amp;quot;: &amp;quot;10.1.2.0/24&amp;quot;,
    &amp;quot;tenantName&amp;quot;: &amp;quot;default&amp;quot;,
    &amp;quot;link-sets&amp;quot;: {},
    &amp;quot;links&amp;quot;: {
      &amp;quot;Tenant&amp;quot;: {
        &amp;quot;type&amp;quot;: &amp;quot;tenant&amp;quot;,
        &amp;quot;key&amp;quot;: &amp;quot;default&amp;quot;
      }
    }
  },
  &amp;quot;Oper&amp;quot;: {
    &amp;quot;availableIPAddresses&amp;quot;: &amp;quot;10.1.2.1-10.1.2.254&amp;quot;,
    &amp;quot;externalPktTag&amp;quot;: 1,
    &amp;quot;pktTag&amp;quot;: 1
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从&lt;strong&gt;netmaster&lt;/strong&gt;日志中可以看到如下报错：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;time=&amp;quot;Mar  9 21:44:14.746627381&amp;quot; level=debug msg=&amp;quot;NwInfra type is default, no ACI&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.750278056&amp;quot; level=info msg=&amp;quot;Creating docker network: {CheckDuplicate:true Driver:netplugin EnableIPv6:false IPAM:0xc4204d8ea0 Internal:false Attachable:true Options:map[tenant:default encap:vxlan pkt-tag:1] Labels:map[]}&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.752034749&amp;quot; level=error msg=&amp;quot;Error creating network contiv-net. Err: Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.752067294&amp;quot; level=error msg=&amp;quot;Error creating network contiv-net.default in docker. Err: Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.752102735&amp;quot; level=error msg=&amp;quot;Error creating network {&amp;amp;{Key:default:contiv-net Encap:vxlan Gateway: Ipv6Gateway: Ipv6Subnet: NetworkName:contiv-net NwType:data PktTag:0 Subnet:10.1.2.0/24 TenantName:default LinkSets:{EndpointGroups:map[] Servicelbs:map[] Services:map[]} Links:{Tenant:{ObjType: ObjKey:}}}}. Err: Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.752129195&amp;quot; level=error msg=&amp;quot;NetworkCreate retruned error for: &amp;amp;{Key:default:contiv-net Encap:vxlan Gateway: Ipv6Gateway: Ipv6Subnet: NetworkName:contiv-net NwType:data PktTag:0 Subnet:10.1.2.0/24 TenantName:default LinkSets:{EndpointGroups:map[] Servicelbs:map[] Services:map[]} Links:{Tenant:{ObjType: ObjKey:}}}. Err: Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.752155973&amp;quot; level=error msg=&amp;quot;CreateNetwork error for: {Key:default:contiv-net Encap:vxlan Gateway: Ipv6Gateway: Ipv6Subnet: NetworkName:contiv-net NwType:data PktTag:0 Subnet:10.1.2.0/24 TenantName:default LinkSets:{EndpointGroups:map[] Servicelbs:map[] Services:map[]} Links:{Tenant:{ObjType: ObjKey:}}}. Err: Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&amp;quot; 
time=&amp;quot;Mar  9 21:44:14.752172138&amp;quot; level=error msg=&amp;quot;Handler for POST /api/v1/networks/default:contiv-net/ returned error: Error response from daemon: legacy plugin netplugin of type NetworkDriver is not supported in swarm mode&amp;quot; 
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;

&lt;p&gt;从日志中看到一个令人悲痛语句的话*legacy plugin netplugin of type NetworkDriver is not supported in swarm mode*，你们昨天不是刚发的版本说已经支持swarm mode吗？&lt;a href=&#34;https://github.com/contiv/netplugin/commit/8afd1b7718c8424a876760d18484124e0aad3557&#34;&gt;&lt;code&gt;commit-8afd1b7&lt;/code&gt;&lt;/a&gt;不是白纸黑字的写着吗？&lt;/p&gt;

&lt;p&gt;我提了个&lt;a href=&#34;https://github.com/contiv/netplugin/issues/776&#34;&gt;issue-776&lt;/a&gt;，看看怎样解决这个问题，另外netplugin命令怎么用，文档上没写啊？&lt;/p&gt;

&lt;p&gt;&lt;code&gt;netplugin -h&lt;/code&gt;可以中有两个选项我不明白，不知道怎么设置，有知道的人请告诉我一声。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  -vlan-if value
    	VLAN uplink interface
  -vtep-ip string
    	My VTEP ip address
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;同时我会继续关注contiv的slack和github &lt;a href=&#34;https://github.com/contiv/netplugin/issues/776&#34;&gt;Issue-776&lt;/a&gt;的进展。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Contiv Intro</title>
      <link>http://rootsongjc.github.io/blogs/contiv-guide/</link>
      <pubDate>Thu, 09 Mar 2017 11:28:34 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/contiv-guide/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/2017021162.jpg&#34; alt=&#34;蓝色港湾&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(题图：北京蓝色港湾夜景 Feb 11,2017 元宵节)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Contiv&lt;/strong&gt;是思科开发的docker网络插件，从2015年就开源了，业界通常拿它和Calico比较。貌似Contiv以前还开发过volume plugin，现在销声匿迹了，只有netplugin仍在活跃开发。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://dockone.io/article/1935&#34;&gt;容器网络插件 Calico 与 Contiv Netplugin深入比较&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;还有篇文章讲解了&lt;a href=&#34;http://blog.dataman-inc.com/shurenyun-docker-133/&#34;&gt;docker网络方案的改进&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;contiv-netplugin-简介&#34;&gt;Contiv Netplugin 简介&lt;/h3&gt;

&lt;p&gt;Contiv Netplugin 是来自思科的解决方案。编程语言为 Go。它基于 OpenvSwitch，以插件化的形式支持容器访问网络，支持 VLAN，Vxlan，多租户，主机访问控制策略等。作为思科整体支持容器基础设施contiv项目的网络部分，最大的亮点在于容器被赋予了 SDN 能力，实现对容器更细粒度，更丰富的访问控制功能。另外，对 Docker CNM 网络模型的支持，并内置了 IPAM 接口，不仅仅提供了一容器一 IP，而且容器的网络信息被记录的容器配置中，伴随着容器的整个生命周期，减低因为状态不同步造成网络信息丢失的风险。有别于 CNI，这种内聚化的设计有利于减少对第三方模块的依赖。随着项目的发展，除了 Docker，还提供了对 Kubernetes 以及 Mesos 的支持，即 CNI 接口。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://dockerone.com/uploads/article/20161221/c737f78ce7c50c84e49648aaf771a6b4.png&#34;&gt;&lt;img src=&#34;http://dockerone.com/uploads/article/20161221/c737f78ce7c50c84e49648aaf771a6b4.png&#34; alt=&#34;9260E9B7-43C0-48B8-B5C7-CF8B952959D2.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Netmaster 后台进程负责记录所有节点状态，保存网络信息，分配 IP 地址&lt;/li&gt;
&lt;li&gt;Netplugin 后台进程作为每个宿主机上的 Agent 与 Docker 及 OVS 通信，处理来自 Docker 的请求，管理 OVS。Docker 方面接口为 remote driver，包括一系列 Docker 定义的 JSON-RPC(POST) 消息。OVS 方面接口为 remote ovsdb，也是 JSON-RPC 消息。以上消息都在 localhost 上处理。&lt;/li&gt;
&lt;li&gt;集群管理依赖 etcd/serf&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;http://dockerone.com/uploads/article/20161221/852b276222482c4740b690eb7f078409.png&#34;&gt;&lt;img src=&#34;http://dockerone.com/uploads/article/20161221/852b276222482c4740b690eb7f078409.png&#34; alt=&#34;580469BC-468C-49C8-B29E-8B88143AFE0A.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;netplugin的优势&#34;&gt;Netplugin的优势&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;较早支持CNM模型。与已有的网络基础设施兼容性较高，改造影响小。基于VLAN的平行扩展与现有网络结构地位对等&lt;/li&gt;
&lt;li&gt;SDN能力，能够对容器的网络访问做更精细的控制&lt;/li&gt;
&lt;li&gt;多租户支持，具备未来向混合云/公有云迁移的潜力&lt;/li&gt;
&lt;li&gt;代码规模不大，逻辑结构清晰，并发好，VLAN在公司内部有开发部署运维实践经验，稳定性经过生产环境验证&lt;/li&gt;
&lt;li&gt;&lt;u&gt;&lt;strong&gt;京东&lt;/strong&gt;基于相同的技术栈（OVS + VLAN）已支持10w+ 容器的运行。&lt;/u&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;next&#34;&gt;Next&lt;/h3&gt;

&lt;p&gt;后续文章会讲解contiv netplugin的环境配置和开发。目前还在1.0-beta版本。&lt;strong&gt;Docker store&lt;/strong&gt;上提供了contiv插件的&lt;a href=&#34;https://store.docker.com/plugins/803eecee-0780-401a-a454-e9523ccf86b3&#34;&gt;下载地址&lt;/a&gt;。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Packer Intro</title>
      <link>http://rootsongjc.github.io/blogs/packer-intro/</link>
      <pubDate>Thu, 09 Mar 2017 10:58:42 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/packer-intro/</guid>
      <description>&lt;p&gt;昨天研究了下&lt;a href=&#34;https://github.com/mitchellh/vagrant&#34;&gt;&lt;strong&gt;Vagrant&lt;/strong&gt;&lt;/a&gt;，感觉它的虚拟机ruby格式定义很麻烦，经人指点还有一个叫做&lt;a href=&#34;https://github.com/mitchellh/packer&#34;&gt;&lt;strong&gt;packer&lt;/strong&gt;&lt;/a&gt;的东西，也是Hashicorp这家公司出品的，今天看了下。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Packer&lt;/strong&gt;是一款开源轻量级的镜像定义工具，可以根据一份定义文件生成多个平台的镜像，支持的平台有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Amazon EC2 (AMI). Both EBS-backed and instance-store AMIs&lt;/li&gt;
&lt;li&gt;Azure&lt;/li&gt;
&lt;li&gt;DigitalOcean&lt;/li&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;li&gt;Google Compute Engine&lt;/li&gt;
&lt;li&gt;OpenStack&lt;/li&gt;
&lt;li&gt;Parallels&lt;/li&gt;
&lt;li&gt;QEMU. Both KVM and Xen images.&lt;/li&gt;
&lt;li&gt;VirtualBox&lt;/li&gt;
&lt;li&gt;VMware&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Packer创造的镜像也能转换成&lt;strong&gt;Vagrant boxes&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;Packer的镜像创建需要一个json格式的定义文件，例如&lt;code&gt;quick-start.json&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;variables&amp;quot;: {
    &amp;quot;access_key&amp;quot;: &amp;quot;{{env `AWS_ACCESS_KEY_ID`}}&amp;quot;,
    &amp;quot;secret_key&amp;quot;: &amp;quot;{{env `AWS_SECRET_ACCESS_KEY`}}&amp;quot;
  },
  &amp;quot;builders&amp;quot;: [{
    &amp;quot;type&amp;quot;: &amp;quot;amazon-ebs&amp;quot;,
    &amp;quot;access_key&amp;quot;: &amp;quot;{{user `access_key`}}&amp;quot;,
    &amp;quot;secret_key&amp;quot;: &amp;quot;{{user `secret_key`}}&amp;quot;,
    &amp;quot;region&amp;quot;: &amp;quot;us-east-1&amp;quot;,
    &amp;quot;source_ami&amp;quot;: &amp;quot;ami-af22d9b9&amp;quot;,
    &amp;quot;instance_type&amp;quot;: &amp;quot;t2.micro&amp;quot;,
    &amp;quot;ssh_username&amp;quot;: &amp;quot;ubuntu&amp;quot;,
    &amp;quot;ami_name&amp;quot;: &amp;quot;packer-example {{timestamp}}&amp;quot;
  }]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用&lt;code&gt;packer build quick-start.json&lt;/code&gt;可以在AWS上build一个AIM镜像。&lt;/p&gt;

&lt;p&gt;Packer的详细文档：&lt;a href=&#34;https://www.packer.io/docs/&#34;&gt;https://www.packer.io/docs/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Vagrant介绍-从使用到放弃完全指南</title>
      <link>http://rootsongjc.github.io/blogs/vagrant-intro/</link>
      <pubDate>Wed, 08 Mar 2017 20:40:08 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/vagrant-intro/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/2017030513.jpg&#34; alt=&#34;光熙家园夜景&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：北京地铁13号线光熙家园夜景 Mar 5,2017）&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;起源&#34;&gt;起源&lt;/h2&gt;

&lt;p&gt;久闻&lt;strong&gt;Vagrant&lt;/strong&gt;大名，之前经常看到有开源项目使用它作为分布式开发的环境配置。&lt;/p&gt;

&lt;p&gt;因为今天在看&lt;a href=&#34;https://github.com/contiv/netplugin&#34;&gt;contiv&lt;/a&gt;正好里面使用vagrant搭建的开发测试环境，所以顺便了解下。它的&lt;a href=&#34;https://github.com/contiv/netplugin/blob/master/Vagrantfile&#34;&gt;Vagrantfile&lt;/a&gt;文件中定义了三台主机。并安装了很多依赖软件，如consul、etcd、docker、go等，整的比较复杂。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;➜  netplugin git:(master) ✗ vagrant status
Current machine states:

netplugin-node1           running (virtualbox)
netplugin-node2           running (virtualbox)
netplugin-node3           running (virtualbox)

This environment represents multiple VMs. The VMs are all listed
above with their current state. For more information about a specific
VM, run `vagrant status NAME`.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Vagrant是&lt;a href=&#34;https://www.hashicorp.com/&#34;&gt;hashicorp&lt;/a&gt;这家公司的产品，这家公司主要做数据中心PAAS和虚拟化，其名下大名鼎鼎的产品有&lt;code&gt;Consul&lt;/code&gt;、&lt;code&gt;Vault&lt;/code&gt;、&lt;code&gt;Nomad&lt;/code&gt;、&lt;code&gt;Terraform&lt;/code&gt;。他们的产品都是基于&lt;strong&gt;Open Source&lt;/strong&gt;的&lt;a href=&#34;https://github.com/hashicorp&#34;&gt;Github地址&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;用途&#34;&gt;用途&lt;/h2&gt;

&lt;p&gt;Vagrant是用来管理虚拟机的，如VirtualBox、VMware、AWS等，主要好处是可以提供一个可配置、可移植和复用的软件环境，可以使用shell、chef、puppet等工具部署。所以vagrant不能单独使用，如果你用它来管理自己的开发环境的话，必须在自己的电脑里安装了虚拟机软件，我使用的是&lt;strong&gt;virtualbox&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;Vagrant提供一个命令行工具&lt;code&gt;vagrant&lt;/code&gt;，通过这个命令行工具可以直接启动一个虚拟机，当然你需要提前定义一个Vagrantfile文件，这有点类似Dockerfile之于docker了。&lt;/p&gt;

&lt;p&gt;跟docker类比这来看vagrant就比较好理解了，vagrant也是用来提供一致性环境的，vagrant本身也提供一个镜像源，使用&lt;code&gt;vagrant init hashicorp/precise64&lt;/code&gt;就可以初始化一个Ubuntu 12.04的镜像。&lt;/p&gt;

&lt;h2 id=&#34;用法&#34;&gt;用法&lt;/h2&gt;

&lt;p&gt;你可以下载安装文件来安装vagrant，也可以使用RubyGem安装，它是用Ruby开发的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Vagrantfile&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Vagrantfile是用来定义vagrant project的，使用ruby语法，不过你不必了解ruby就可以写一个Vagrantfile。&lt;/p&gt;

&lt;p&gt;看个例子，选自&lt;a href=&#34;https://github.com/fenbox/Vagrantfile&#34;&gt;https://github.com/fenbox/Vagrantfile&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Ruby&#34;&gt;# -*- mode: ruby -*-
# vi: set ft=ruby :

# All Vagrant configuration is done below. The &amp;quot;2&amp;quot; in Vagrant.configure
# configures the configuration version (we support older styles for
# backwards compatibility). Please don&#39;t change it unless you know what
# you&#39;re doing.
Vagrant.configure(&amp;quot;2&amp;quot;) do |config|
  # The most common configuration options are documented and commented below.
  # For a complete reference, please see the online documentation at
  # https://docs.vagrantup.com.

  # Every Vagrant development environment requires a box. You can search for
  # boxes at https://atlas.hashicorp.com/search.
  config.vm.box = &amp;quot;ubuntu/trusty64&amp;quot;

  # Disable automatic box update checking. If you disable this, then
  # boxes will only be checked for updates when the user runs
  # `vagrant box outdated`. This is not recommended.
  # config.vm.box_check_update = false

  # Create a forwarded port mapping which allows access to a specific port
  # within the machine from a port on the host machine. In the example below,
  # accessing &amp;quot;localhost:8080&amp;quot; will access port 80 on the guest machine.
  # config.vm.network &amp;quot;forwarded_port&amp;quot;, guest: 80, host: 8080

  # Create a private network, which allows host-only access to the machine
  # using a specific IP.
  config.vm.network &amp;quot;private_network&amp;quot;, ip: &amp;quot;192.168.33.10&amp;quot;

  # Create a public network, which generally matched to bridged network.
  # Bridged networks make the machine appear as another physical device on
  # your network.
  # config.vm.network &amp;quot;public_network&amp;quot;

  # Share an additional folder to the guest VM. The first argument is
  # the path on the host to the actual folder. The second argument is
  # the path on the guest to mount the folder. And the optional third
  # argument is a set of non-required options.
  # config.vm.synced_folder &amp;quot;../data&amp;quot;, &amp;quot;/vagrant_data&amp;quot;

  # Provider-specific configuration so you can fine-tune various
  # backing providers for Vagrant. These expose provider-specific options.
  # Example for VirtualBox:
  #
  # config.vm.provider &amp;quot;virtualbox&amp;quot; do |vb|
  #   # Display the VirtualBox GUI when booting the machine
  #   vb.gui = true
  #
  #   # Customize the amount of memory on the VM:
  #   vb.memory = &amp;quot;1024&amp;quot;
  # end
  #
  # View the documentation for the provider you are using for more
  # information on available options.

  # Define a Vagrant Push strategy for pushing to Atlas. Other push strategies
  # such as FTP and Heroku are also available. See the documentation at
  # https://docs.vagrantup.com/v2/push/atlas.html for more information.
  # config.push.define &amp;quot;atlas&amp;quot; do |push|
  #   push.app = &amp;quot;YOUR_ATLAS_USERNAME/YOUR_APPLICATION_NAME&amp;quot;
  # end

  # Enable provisioning with a shell script. Additional provisioners such as
  # Puppet, Chef, Ansible, Salt, and Docker are also available. Please see the
  # documentation for more information about their specific syntax and use.
  # config.vm.provision &amp;quot;shell&amp;quot;, inline: &amp;lt;&amp;lt;-SHELL
  #   apt-get update
  #   apt-get install -y apache2
  # SHELL
  config.vm.provision :shell, path: &amp;quot;bootstrap.sh&amp;quot;
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Boxes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Vagrant的基础镜像，相当于docker images。可以在这些基础镜像的基础上制作自己的虚拟机镜像。&lt;/p&gt;

&lt;p&gt;添加一个box&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ vagrant box add hashicorp/precise64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在Vagrantfile中指定box&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Ruby&#34;&gt;Vagrant.configure(&amp;quot;2&amp;quot;) do |config|
  config.vm.box = &amp;quot;hashicorp/precise64&amp;quot;
  config.vm.box_version = &amp;quot;1.1.0&amp;quot;
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;使用ssh进入vagrant&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;vagrant up&lt;/code&gt;后就可以用&lt;code&gt;vagrant ssh $name&lt;/code&gt;进入虚拟机内，如果主机上就一个vagrant可以不指定名字。默认进入的用户是vagrant。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;文件同步&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;vagrant up&lt;/code&gt;后在虚拟机中会有一个&lt;code&gt;/vagrant&lt;/code&gt;目录，这跟你定义&lt;code&gt;Vagrantfile&lt;/code&gt;是同一级目录。&lt;/p&gt;

&lt;p&gt;这个目录跟你宿主机上的目录文件是同步的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;软件安装&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在Vagrantfile中定义要安装的软件和操作。&lt;/p&gt;

&lt;p&gt;例如安装apache&lt;/p&gt;

&lt;p&gt;在与Vagrantfile同级的目录下创建一个&lt;code&gt;bootstrap.sh&lt;/code&gt;文件。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#!/usr/bin/env bash

apt-get update
apt-get install -y apache2
if ! [ -L /var/www ]; then
  rm -rf /var/www
  ln -fs /vagrant /var/www
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后在Vagrantfile中使用它。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Ruby&#34;&gt;Vagrant.configure(&amp;quot;2&amp;quot;) do |config|
  config.vm.box = &amp;quot;hashicorp/precise64&amp;quot;
  config.vm.box_version = &amp;quot;1.1.0&amp;quot;
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;网络&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;端口转发&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;Vagrant.configure(&amp;quot;2&amp;quot;) do |config|
  config.vm.box = &amp;quot;hashicorp/precise64&amp;quot;
  config.vm.provision :shell, path: &amp;quot;bootstrap.sh&amp;quot;
  config.vm.network :forwarded_port, guest: 80, host: 4567
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行&lt;code&gt;vagrant reload&lt;/code&gt;或者&lt;code&gt;vagrant up&lt;/code&gt;可以生效。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;分享&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;你自己做的vagrant是可以分享给别人的用的，只要你有一个hashicorp账号，&lt;code&gt;vagrant login&lt;/code&gt;后就可以执行&lt;code&gt;vagrant share&lt;/code&gt;分享，会生成一个URL，其它人也可以访问到你的vagrant里的服务。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;中止&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;vagrant suspend&lt;/li&gt;
&lt;li&gt;Vagrant halt&lt;/li&gt;
&lt;li&gt;Vagrant destroy&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;重构&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;再次执行&lt;code&gt;vagrant up&lt;/code&gt;即可。&lt;/p&gt;

&lt;h2 id=&#34;分布式环境&#34;&gt;分布式环境&lt;/h2&gt;

&lt;p&gt;开发分布式环境下的应用时往往需要多个虚拟机用于测试，这时候才是vagrant显威力的时候。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;定义多个主机&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;Vagrant.configure(&amp;quot;2&amp;quot;) do |config|
  config.vm.provision &amp;quot;shell&amp;quot;, inline: &amp;quot;echo Hello&amp;quot;

  config.vm.define &amp;quot;web&amp;quot; do |web|
    web.vm.box = &amp;quot;apache&amp;quot;
  end

  config.vm.define &amp;quot;db&amp;quot; do |db|
    db.vm.box = &amp;quot;mysql&amp;quot;
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个比较复杂，详见&lt;a href=&#34;https://www.vagrantup.com/docs/multi-machine/&#34;&gt;https://www.vagrantup.com/docs/multi-machine/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;还有一些其它功能，如push、plugins、providers按下不表。&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;总的来说说Vagrant没有Docker好用，但是对于协同开发，用它来定义分布式开发环境还可以，ruby的语法看着有点不习惯，好在也不复杂，如果是团队几个人开发，弄几个虚拟机大家互相拷贝一下也没那么复杂吧？&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>docker技术选型</title>
      <link>http://rootsongjc.github.io/projects/docker-tech-selection/</link>
      <pubDate>Wed, 08 Mar 2017 10:37:01 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/projects/docker-tech-selection/</guid>
      <description>

&lt;h2 id=&#34;回顾历史&#34;&gt;回顾历史&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;多少次我回过头看看走过的路，你还在小村旁。&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;去年基于docker1.11对Hadoop yarn进行了docker化改造，详情请看&lt;a href=&#34;https://rootsongjc.github.io/docker-practice/docs/td_yarn_on_docker.html&#34;&gt;大数据集群虚拟化-Yarn on docker始末&lt;/a&gt;，我将这个事件命名为&lt;a href=&#34;https://github.com/rootsongjc/magpie&#34;&gt;magpie&lt;/a&gt;，因为它就像是喜鹊一样收集着各种各样的资源搭建自己的小窝。&lt;strong&gt;magpie&lt;/strong&gt;还是有很多事情可以做的，大数据集群的虚拟化也不会止步，它仅仅是对其做了初步的探索，对于资源利用率和管理方面的优化还有很长的路要走，&lt;strong&gt;Yarn&lt;/strong&gt;本身就是做为大数据集群的资源管理调度角色出现的，一开始是为调度&lt;strong&gt;MapReduce&lt;/strong&gt;，后来的&lt;code&gt;spark&lt;/code&gt;、&lt;code&gt;hive&lt;/code&gt;、&lt;code&gt;tensrflow&lt;/code&gt;、&lt;code&gt;HAWQ&lt;/code&gt;、&lt;code&gt;slide&lt;/code&gt;等等不一而足陆续出现。但是用它来管理docker似乎还是有点过重，还不如用kubernetes、marathon、nomad、swarm等。&lt;/p&gt;

&lt;p&gt;但是在微服务方面docker1.11的很多弊端或者说缺点就暴露了出来，首先docker1.11原生并不带cluster管理，需要配合·&lt;code&gt;docker swarm&lt;/code&gt;、&lt;code&gt;kubernetes&lt;/code&gt;、&lt;code&gt;marathon&lt;/code&gt;等才能管理docker集群。&lt;u&gt;之前的对于docker的使用方式基本就是按照虚拟机的方式使用的，固定IP有悖于微服务的原则。&lt;/u&gt;&lt;/p&gt;

&lt;p&gt;我们基于docker1.11和&lt;a href=&#34;github.com/talkingdata/shrike&#34;&gt;shrike&lt;/a&gt;二层网络模式，还有&lt;a href=&#34;https://github.com/shipyard/shipyard&#34;&gt;shipyard&lt;/a&gt;来做集群管理，shipyard只是一个简单的docker集群管理的WebUI，基本都是调用docker API，唯一做了一点docker原生没有的功能就是&lt;strong&gt;scale&lt;/strong&gt;容器，而且只支持到docker1.11，早已停止开发。我抛弃了&lt;strong&gt;shipyard&lt;/strong&gt;，它的页面功能基本可有可无，我自己开发的&lt;a href=&#34;https://github.com/rootsongjc/magpie&#34;&gt;magpie&lt;/a&gt;一样可以管理&lt;code&gt;yarn on docker&lt;/code&gt;集群。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Docker Swarm有如下几个缺点&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;对于大规模集群的管理效率太低，当管理上百个node的时候经常出现有节点状态不同步的问题，比如主机重启后容器已经&lt;strong&gt;Exited&lt;/strong&gt;了，但是master让然认为是&lt;strong&gt;Running&lt;/strong&gt;状态，必须重启所有master节点才行。&lt;/li&gt;
&lt;li&gt;没有中心化Node管理功能，必须登录到每台node上手动启停&lt;code&gt;swarm-agent&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;集群管理功能实在&lt;strong&gt;太太太&lt;/strong&gt;简陋，查看所有node状态只能用&lt;code&gt;docker info&lt;/code&gt;而且那个格式就不提了，shipyard里有处理这个格式的代码，我copy到了magpie里，彻底抛弃shipyard了。&lt;/li&gt;
&lt;li&gt;Docker swarm的集群管理概念缺失，因为docker一开始设计的时候就不是用来管理集群的，所以出现了swarm，但是只能使用&lt;strong&gt;docker-compose&lt;/strong&gt;来编排服务，但是无法在swarm集群中使用我们自定义的&lt;strong&gt;mynet&lt;/strong&gt;网络，&lt;a href=&#34;https://github.com/docker/compose/issues/4233&#34;&gt;compose issue-4233&lt;/a&gt;，&lt;strong&gt;compose&lt;/strong&gt;也已经被docker官方废弃（最近一年docker发展的太快了，原来用python写的compose已经被用go重构为&lt;strong&gt;libcompose&lt;/strong&gt;直接集成到swarm mode里了），而且docker1.11里也没有像kubernetes那样&lt;code&gt;service&lt;/code&gt;的单位，在docker1.11所有的管理都是基于docker容器的。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Docker Swarm的问题也是shipyard的问题，谁让shipyard直接调用docker的API呢。当然，在后续版本的docker里以上问题都已经不是问题，docker已经越来越像kubernetes，不论是在设计理念上还是在功能上，甚至还发行了企业版，以后每个月发布一个版本。&lt;/p&gt;

&lt;h2 id=&#34;技术选型&#34;&gt;技术选型&lt;/h2&gt;

&lt;p&gt;主要对比&lt;code&gt;Docker1.11&lt;/code&gt;和&lt;code&gt;Docker17.03-ce&lt;/code&gt;版本。&lt;/p&gt;

&lt;p&gt;首先有一点需要了解的是，docker1.12+带来的&lt;a href=&#34;https://rootsongjc.github.io/docker-practice/docs/swarm_mode.html&#34;&gt;swarm mode&lt;/a&gt;，你可以使用一个命令直接启动一个复杂的&lt;strong&gt;stack&lt;/strong&gt;，其中包括了服务编排和所有的服务配置，这是一个&lt;a href=&#34;https://rootsongjc.github.io/docker-practice/docs/create_swarm_app.html&#34;&gt;投票应用的例子&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;下表对比了docker1.11和docker17.03-ce&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;版本&lt;/th&gt;
&lt;th&gt;docker1.11&lt;/th&gt;
&lt;th&gt;docker17.03-ce&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;基本单位&lt;/td&gt;
&lt;td&gt;docker容器&lt;/td&gt;
&lt;td&gt;docker容器、service、stack&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;服务编排&lt;/td&gt;
&lt;td&gt;compose，不支持docker swarm的mynet网络&lt;/td&gt;
&lt;td&gt;改造后的compose，支持stack中完整的服务编排&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;网络模型&lt;/td&gt;
&lt;td&gt;Host、bridge、overlay、mynet&lt;/td&gt;
&lt;td&gt;默认支持跨主机的overlay网络，创建单个容器时也可以attach到已有的overla网络中&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;插件&lt;/td&gt;
&lt;td&gt;没有插件管理命令，但是可以手动创建和管理&lt;/td&gt;
&lt;td&gt;有插件管理命令，可以手动创建和从docker hub中下载，上传插件到自己的私有镜像仓库&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;升级&lt;/td&gt;
&lt;td&gt;不支持平滑升级，重启docker原来的容器也会停掉&lt;/td&gt;
&lt;td&gt;可以停止docker engine但不影响已启动的容器&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;弹性伸缩&lt;/td&gt;
&lt;td&gt;不支持&lt;/td&gt;
&lt;td&gt;service内置功能&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;服务发现&lt;/td&gt;
&lt;td&gt;监听docker event增删DNS&lt;/td&gt;
&lt;td&gt;内置服务发现，根据DNS负载均衡&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;节点管理&lt;/td&gt;
&lt;td&gt;手动启停&lt;/td&gt;
&lt;td&gt;中心化管理node节点&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;服务升级&lt;/td&gt;
&lt;td&gt;手动升级&lt;/td&gt;
&lt;td&gt;service内置功能&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;负载均衡&lt;/td&gt;
&lt;td&gt;本身不支持&lt;/td&gt;
&lt;td&gt;Swarm mode内部DNS轮寻&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;基于以上对比，使用docker17.03-ce不仅可以兼容以前的mynet网络模式，只需要重构以前的shrike为&lt;strong&gt;docker plugin&lt;/strong&gt;，在创建service的时候指定为mynet即可。也可以同时使用docker mode的overlay网络，而且还可以安装其它docker plugin首先更高级网络和volume功能。&lt;/p&gt;

&lt;p&gt;Docker17.03-ce借鉴了很多kubernetes的设计理念，docker发力企业级市场，相信新版的才符合微服务的方向，既能兼容以前的&lt;strong&gt;虚拟机式&lt;/strong&gt;的使用模式，也能兼容&lt;strong&gt;微服务&lt;/strong&gt;架构。&lt;/p&gt;

&lt;h2 id=&#34;下一步&#34;&gt;下一步&lt;/h2&gt;

&lt;p&gt;之前考虑过使用docker1.11 + compose + shipyard + eureka + nginx等做微服务架构，但是考虑到最新版docker的重大升级，从长远的眼光来看，不能一直限定于之前的那一套，我更倾向于新版本。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;调研Docker17.03-ce的新特性，尤其是服务治理方面&lt;/li&gt;
&lt;li&gt;结合具体业务试用&lt;/li&gt;
&lt;li&gt;重构shrike为docker plugin&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Don&amp;rsquo;t speak, I&amp;rsquo;ll try to save us from ourselves&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;If were going down, we&amp;rsquo;re going down in flames&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>docker源码编译和开发环境搭建</title>
      <link>http://rootsongjc.github.io/blogs/docker-dev-env/</link>
      <pubDate>Mon, 06 Mar 2017 17:03:19 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/docker-dev-env/</guid>
      <description>

&lt;p&gt;看了下网上其他人写的docker开发环境搭建，要么是在ubuntu下搭建，要么就是使用官方说明的build docker-dev镜像的方式一步步搭建的，甚是繁琐，docker hub上有一个docker官方推出的&lt;strong&gt;dockercore/docker&lt;/strong&gt;镜像，其实这就是官网上所说的docker-dev镜像，不过以前的那个deprecated了，使用目前这个镜像搭建docker开发环境是最快捷的了。&lt;/p&gt;

&lt;p&gt;想要修改docker源码和做docker定制开发的同学可以参考下。&lt;/p&gt;

&lt;p&gt;官方指导文档：&lt;a href=&#34;https://docs.docker.com/opensource/code/&#34;&gt;https://docs.docker.com/opensource/code/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;设置docker开发环境：&lt;a href=&#34;https://docs.docker.com/opensource/project/set-up-dev-env/&#34;&gt;https://docs.docker.com/opensource/project/set-up-dev-env/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;docker的编译实质上是在docker容器中运行docker。&lt;/p&gt;

&lt;p&gt;因此在本地编译docker的前提是需要安装了docker，还需要用git把代码pull下来。&lt;/p&gt;

&lt;h3 id=&#34;创建分支&#34;&gt;创建分支&lt;/h3&gt;

&lt;p&gt;为了方便以后给docker提交更改，我们从docker官方fork一个分支。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;git clone https://github.com/rootsongjc/docker.git
git config --local user.name &amp;quot;Jimmy Song&amp;quot;
git config --local user.email &amp;quot;rootsongjc@gmail.com&amp;quot;
git remote add upstream https://github.com/docker/docker.git
git config --local -l
git remote -v
git checkout -b dry-run-test
touch TEST.md
vim TEST.md
git status
git add TEST.md
git commit -am &amp;quot;Making a dry run test.&amp;quot;
git push --set-upstream origin dry-run-test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后就可以在&lt;code&gt;dry-run-test&lt;/code&gt;这个分支下工作了。&lt;/p&gt;

&lt;h3 id=&#34;配置docker开发环境&#34;&gt;配置docker开发环境&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/opensource/project/set-up-dev-env/&#34;&gt;官网&lt;/a&gt;上说需要先清空自己电脑上已有的容器和镜像。&lt;/p&gt;

&lt;p&gt;docker开发环境本质上是创建一个docker镜像，镜像里包含了docker的所有开发运行环境，本地代码通过挂载的方式放到容器中运行，下面这条命令会自动创建这样一个镜像。&lt;/p&gt;

&lt;p&gt;在&lt;code&gt;dry-run-test&lt;/code&gt;分支下执行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;make BIND_DIR=. shell
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该命令会自动编译一个docker镜像，From debian:jessie。这一步会上网下载很多依赖包，速度比较慢。如果翻不了墙的话肯定都会失败。因为需要下载的软件和安装包都是在国外服务器上，不翻墙根本就下载不下来，为了不用这么麻烦，推荐直接使用docker官方的dockercore/docker镜像，也不用以前的docker-dev镜像，那个造就废弃了。这个镜像大小有2.31G。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker pull dockercore/docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用方法见这里：&lt;a href=&#34;https://hub.docker.com/r/dockercore/docker/&#34;&gt;https://hub.docker.com/r/dockercore/docker/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;然后就可以进入到容器里&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;docker run --rm -i --privileged -e BUILDFLAGS -e KEEPBUNDLE -e DOCKER_BUILD_GOGC -e DOCKER_BUILD_PKGS -e DOCKER_CLIENTONLY -e DOCKER_DEBUG -e DOCKER_EXPERIMENTAL -e DOCKER_GITCOMMIT -e DOCKER_GRAPHDRIVER=devicemapper -e DOCKER_INCREMENTAL_BINARY -e DOCKER_REMAP_ROOT -e DOCKER_STORAGE_OPTS -e DOCKER_USERLANDPROXY -e TESTDIRS -e TESTFLAGS -e TIMEOUT -v &amp;quot;/Users/jimmy/Workspace/github/rootsongjc/docker/bundles:/go/src/github.com/docker/docker/bundles&amp;quot; -t &amp;quot;dockercore/docker:latest&amp;quot; bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;按照官网的说明make会报错&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@f2753f78bb6d:/go/src/github.com/docker/docker# ./hack/make.sh binary                          

error: .git directory missing and DOCKER_GITCOMMIT not specified
  Please either build with the .git directory accessible, or specify the
  exact (--short) commit hash you are building using DOCKER_GITCOMMIT for
  future accountability in diagnosing build issues.  Thanks!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这是一个&lt;a href=&#34;https://github.com/docker/docker/issues/27581&#34;&gt;issue-27581&lt;/a&gt;，解决方式就是在make的时候手动指定&lt;code&gt;DOCKER_GITCOMMIT&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@f2753f78bb6d:/go/src/github.com/docker/docker# DOCKER_GITCOMMIT=3385658 ./hack/make.sh binary

---&amp;gt; Making bundle: binary (in bundles/17.04.0-dev/binary)
Building: bundles/17.04.0-dev/binary-client/docker-17.04.0-dev
Created binary: bundles/17.04.0-dev/binary-client/docker-17.04.0-dev
Building: bundles/17.04.0-dev/binary-daemon/dockerd-17.04.0-dev
Created binary: bundles/17.04.0-dev/binary-daemon/dockerd-17.04.0-dev
Copying nested executables into bundles/17.04.0-dev/binary-daemon
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;bundles目录下会生成如下文件结构&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;.
├── 17.04.0-dev
│   ├── binary-client
│   │   ├── docker -&amp;gt; docker-17.04.0-dev
│   │   ├── docker-17.04.0-dev
│   │   ├── docker-17.04.0-dev.md5
│   │   └── docker-17.04.0-dev.sha256
│   └── binary-daemon
│       ├── docker-containerd
│       ├── docker-containerd-ctr
│       ├── docker-containerd-ctr.md5
│       ├── docker-containerd-ctr.sha256
│       ├── docker-containerd-shim
│       ├── docker-containerd-shim.md5
│       ├── docker-containerd-shim.sha256
│       ├── docker-containerd.md5
│       ├── docker-containerd.sha256
│       ├── docker-init
│       ├── docker-init.md5
│       ├── docker-init.sha256
│       ├── docker-proxy
│       ├── docker-proxy.md5
│       ├── docker-proxy.sha256
│       ├── docker-runc
│       ├── docker-runc.md5
│       ├── docker-runc.sha256
│       ├── dockerd -&amp;gt; dockerd-17.04.0-dev
│       ├── dockerd-17.04.0-dev
│       ├── dockerd-17.04.0-dev.md5
│       └── dockerd-17.04.0-dev.sha256
└── latest -&amp;gt; 17.04.0-dev

4 directories, 26 files
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在可以将docker-daemon和docker-client目录下的docker可以执行文件复制到容器的/usr/bin/目录下了。&lt;/p&gt;

&lt;p&gt;启动docker deamon&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;docker daemon -D&amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;检查下docker是否可用&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@f2753f78bb6d:/go/src/github.com/docker/docker/bundles/17.04.0-dev# docker version
DEBU[0048] Calling GET /_ping                           
DEBU[0048] Calling GET /v1.27/version                   
Client:
 Version:      17.04.0-dev
 API version:  1.27
 Go version:   go1.7.5
 Git commit:   3385658
 Built:        Mon Mar  6 08:39:06 2017
 OS/Arch:      linux/amd64

Server:
 Version:      17.04.0-dev
 API version:  1.27 (minimum version 1.12)
 Go version:   go1.7.5
 Git commit:   3385658
 Built:        Mon Mar  6 08:39:06 2017
 OS/Arch:      linux/amd64
 Experimental: false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;到此docker源码编译和开发环境都已经搭建好了。&lt;/p&gt;

&lt;p&gt;如果想要修改docker源码，只要在你的IDE、容器里或者你本机上修改docker代码后，再执行上面的hack/make.sh binary命令就可以生成新的docker二进制文件，再替换原来的/usr/bin/目录下的docker二进制文件即可。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cloud Native Go - 基于Go和React的web云服务构建指南</title>
      <link>http://rootsongjc.github.io/talks/cloud-native-go/</link>
      <pubDate>Fri, 03 Mar 2017 17:29:54 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/talks/cloud-native-go/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/20160326003.jpg&#34; alt=&#34;北京植物园桃花&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(题图：北京植物园桃花 Mar 26,2016)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;最近在翻译Kevin Hoffman和Dan Nemeth的书《Cloud Native Go - 基于Go和React的web云服务构建指南》。目前已经完成图书的粗译，格式调整和排版，正在调整校对，预计本月将完成。本书将由&lt;strong&gt;电子工业出版社&lt;/strong&gt;出版。&lt;/p&gt;

&lt;p&gt;下面先罗列下目录，以飨读者。&lt;/p&gt;

&lt;h2 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h2&gt;

&lt;p&gt;Cloud Native Go. 1
构建基于Go和React的云原生Web应用&amp;hellip; 1
云服务构建完全指南&amp;hellip; 1
目录&amp;hellip; 4
前言&amp;hellip; 8
关于作者&amp;hellip; 9
致谢&amp;hellip; 9&lt;/p&gt;

&lt;h3 id=&#34;第1章-云之道-10&#34;&gt;第1章        云之道&amp;hellip; 10&lt;/h3&gt;

&lt;p&gt;云的优势&amp;hellip; 10
崇尚简洁&amp;hellip; 11
测试优先，测试一切&amp;hellip; 11
尽早发布, 频繁发布&amp;hellip; 12
自动化一切&amp;hellip; 13
建立服务生态系统&amp;hellip; 13
为什么使用GO?. 14
总结&amp;hellip; 15&lt;/p&gt;

&lt;h3 id=&#34;第2章-开始-16&#34;&gt;第2章        开始… 16&lt;/h3&gt;

&lt;p&gt;正确的工具&amp;hellip; 16
配置Git 16
建立Go. 18
配置您的Go工作区&amp;hellip; 18
检查环境&amp;hellip; 19
总结&amp;hellip; 19&lt;/p&gt;

&lt;h3 id=&#34;第3章-go入门-20&#34;&gt;第3章        Go入门&amp;hellip; 20&lt;/h3&gt;

&lt;p&gt;建立Hello Cloud. 20
使用基本函数&amp;hellip; 21
使用结构体&amp;hellip; 23
介绍Go接口&amp;hellip; 24
向结构体添加方法&amp;hellip; 24
Go中的接口动态类型检查&amp;hellip; 25
使用第三方包&amp;hellip; 27
创建自己的包&amp;hellip; 28
导出函数和数据&amp;hellip; 28
创建包&amp;hellip; 28
总结&amp;hellip; 30&lt;/p&gt;

&lt;h3 id=&#34;第4章-持续交付-31&#34;&gt;第4章        持续交付&amp;hellip; 31&lt;/h3&gt;

&lt;p&gt;Docker介绍&amp;hellip; 31
为什么要使用Docker？&amp;hellip; 31
安装Docker 32
运行Docker镜像&amp;hellip; 33
与Wercker的持续集成&amp;hellip; 33
持续集成最佳实践&amp;hellip; 34
为什么使用Wercker？&amp;hellip; 34
安装Wercker CLI 36
创建Wercker配置文件&amp;hellip; 36
使用Wercker进行构建&amp;hellip; 40
部署到DockerHub. 41
读者练习：创建完整的开发管道&amp;hellip; 42
高级挑战：集成第三方库&amp;hellip; 42
总结&amp;hellip; 43&lt;/p&gt;

&lt;h3 id=&#34;第5章-在go中构建微服务-44&#34;&gt;第5章        在Go中构建微服务&amp;hellip; 44&lt;/h3&gt;

&lt;p&gt;设计API First的服务&amp;hellip; 44
通过Apiary测试和发布文档&amp;hellip; 46
架设微服务&amp;hellip; 46
构建Test First的服务&amp;hellip; 48
创建第一个失败测试&amp;hellip; 49
测试Location Header 51
壮丽的蒙太奇 - 迭代测试&amp;hellip; 52
在云中部署和运行&amp;hellip; 53
总结&amp;hellip; 55&lt;/p&gt;

&lt;h3 id=&#34;第6章-运用后端服务-56&#34;&gt;第6章        运用后端服务&amp;hellip; 56&lt;/h3&gt;

&lt;p&gt;设计服务系统&amp;hellip; 56
测试优先构建依赖服务&amp;hellip; 57
构建Fulfillment服务&amp;hellip; 57
构建Catalog服务&amp;hellip; 60
在服务之间共享结构化数据&amp;hellip; 64
使用服务捆绑去外部化地址与元数据&amp;hellip; 65
服务发现&amp;hellip; 67
读者练习&amp;hellip; 69
总结&amp;hellip; 70&lt;/p&gt;

&lt;h3 id=&#34;第7章-构建数据服务-71&#34;&gt;第7章        构建数据服务&amp;hellip; 71&lt;/h3&gt;

&lt;p&gt;构建MongoDB存储库&amp;hellip; 71
集成测试一个Mongo-Backed服务&amp;hellip; 76
在云中运行&amp;hellip; 80
总结&amp;hellip; 81&lt;/p&gt;

&lt;h3 id=&#34;第8章-事件源和cqrs-83&#34;&gt;第8章        事件源和CQRS.. 83&lt;/h3&gt;

&lt;p&gt;现实源自事件&amp;hellip; 83
最终还是一致的&amp;hellip; 85
介绍命令查询责任分离&amp;hellip; 86
事件源案例&amp;hellip; 87
代码示例：管理无人机军队&amp;hellip; 88
构建命令处理程序服务&amp;hellip; 88
构建事件处理器&amp;hellip; 92
构建查询处理程序服务&amp;hellip; 95
总结&amp;hellip; 96&lt;/p&gt;

&lt;h3 id=&#34;第9章-使用go构建web应用程序-97&#34;&gt;第9章 使用Go构建web应用程序&amp;hellip; 97&lt;/h3&gt;

&lt;p&gt;处理静态文件和资产&amp;hellip; 97
支持javascript客户端&amp;hellip; 98
使用服务端模板&amp;hellip; 100
处理表单&amp;hellip; 102
使用Cookie和会话状态&amp;hellip; 102
使用Wercker构建和部署&amp;hellip; 104
总结&amp;hellip; 105&lt;/p&gt;

&lt;h3 id=&#34;第10章-云安全-106&#34;&gt;第10章 云安全&amp;hellip; 106&lt;/h3&gt;

&lt;p&gt;保护一个web应用程序&amp;hellip; 106
保护微服务&amp;hellip; 111
隐私和数据安全&amp;hellip; 113
阅读练习&amp;hellip; 114
总结&amp;hellip; 115&lt;/p&gt;

&lt;h3 id=&#34;第11章-使用websockets-116&#34;&gt;第11章 使用WebSockets. 116&lt;/h3&gt;

&lt;p&gt;解析WebSockets. 116
WebSockets和云的诞生&amp;hellip; 117
使用消息传递提供程序构建WebSocket应用程序&amp;hellip; 119
总结&amp;hellip; 122&lt;/p&gt;

&lt;h3 id=&#34;第12章-使用react构建web视图-123&#34;&gt;第12章 使用React构建web视图… 123&lt;/h3&gt;

&lt;p&gt;JavaScript State of the Union JavaScript  . 123
为什么选择React？&amp;hellip; 123
React应用程序的解剖&amp;hellip; 125
构建一个简单的React应用程序&amp;hellip; 127
测试React应用程序&amp;hellip; 132
进一步阅读&amp;hellip; 132
总结 . 133&lt;/p&gt;

&lt;h3 id=&#34;第13章-使用flux构建高可扩展性ui-134&#34;&gt;第13章      使用Flux构建高可扩展性UI 134&lt;/h3&gt;

&lt;p&gt;Flux介绍&amp;hellip; 134
创建Flux应用程序&amp;hellip; 136
总结&amp;hellip; 141&lt;/p&gt;

&lt;h3 id=&#34;第14章-创建完整应用world-of-fluxcraft-143&#34;&gt;第14章      创建完整应用World of FluxCraft 143&lt;/h3&gt;

&lt;p&gt;World of FluxCraft介绍&amp;hellip; 143
架构概览&amp;hellip; 145
Flux GUI 146
命令处理&amp;hellip; 148
事件处理&amp;hellip; 149
维持现实服务的状态&amp;hellip; 149
地图管理&amp;hellip; 150
自动验收测试&amp;hellip; 150
总结&amp;hellip; 151&lt;/p&gt;

&lt;h3 id=&#34;第15章-结论-152&#34;&gt;第15章     结论&amp;hellip; 152&lt;/h3&gt;

&lt;p&gt;我们学到了什么？&amp;hellip; 152
下一步&amp;hellip; 153&lt;/p&gt;

&lt;h3 id=&#34;a云应用的故障排查-154&#34;&gt;A云应用的故障排查… 154&lt;/h3&gt;

&lt;p&gt;使用日志流&amp;hellip; 154
健康和性能监控&amp;hellip; 154
在云中调试应用程序&amp;hellip; 155&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>《云计算技术架构与实践》读后感</title>
      <link>http://rootsongjc.github.io/blogs/cloud-computing-architecture-practice/</link>
      <pubDate>Wed, 01 Mar 2017 18:29:36 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/blogs/cloud-computing-architecture-practice/</guid>
      <description>&lt;p&gt;最近友人推荐了一本书，是华为的工程师写的《云计算架构与实践第二版》，正好在网上找到了这本书的pdf，分享给大家，&lt;a href=&#34;http://olz1di9xf.bkt.clouddn.com/docs/%E4%BA%91%E8%AE%A1%E7%AE%97%E6%9E%B6%E6%9E%84%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E8%B7%B5%E7%AC%AC2%E7%89%88.pdf&#34;&gt;点这里下载&lt;/a&gt;，书是文字版的，大小13.04MB，除了章节顺序有点问题外没有其他什么问题。&lt;/p&gt;

&lt;p&gt;后续我将会陆续分享这本书的读后感。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>