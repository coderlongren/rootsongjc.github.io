<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Jimmy Song&#39;s Blog</title>
    <link>http://rootsongjc.github.io/projects/index.xml</link>
    <description>Recent content in Projects on Jimmy Song&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Apr 2017 14:00:04 +0800</lastBuildDate>
    <atom:link href="http://rootsongjc.github.io/projects/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Kubernetes1.6集群部署完全指南 ——二进制文件部署开启TLS基于CentOS7发布</title>
      <link>http://rootsongjc.github.io/projects/kubernetes-installation-document/</link>
      <pubDate>Thu, 13 Apr 2017 14:00:04 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/projects/kubernetes-installation-document/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/2016081309.jpg&#34; alt=&#34;首都机场&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;（题图：清晨@首都机场 Aug 13,2016）&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;这可能是目前为止最详细的kubernetes安装文档了。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;经过几天的安装、调试、整理，今天该文档终于发布了。&lt;/p&gt;

&lt;p&gt;你可以在这里看到文档和配置文件&lt;a href=&#34;https://github.com/rootsongjc/follow-me-install-kubernetes-cluster&#34;&gt;和我一步步部署 kubernetes1.6 集群&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;或者直接下载&lt;a href=&#34;http://olz1di9xf.bkt.clouddn.com/Kubernetes1.6%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97%E2%80%94%E2%80%94%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6%E9%83%A8%E7%BD%B2%E5%BC%80%E5%90%AFTLS%E5%9F%BA%E4%BA%8ECentOS7.pdf&#34;&gt;pdf&lt;/a&gt;版本（2.92M）。&lt;/p&gt;

&lt;p&gt;Kubernetes的安装繁琐，步骤复杂，该文档能够帮助跳过很多坑，节约不少时间，我在本地环境上已经安装完成，有问题欢迎在&lt;a href=&#34;https://github.com/opsnull/follow-me-install-kubernetes-cluster&#34;&gt;GitHub&lt;/a&gt;上提issue。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>容器技术在大数据场景下的应用——Yarn on Docker</title>
      <link>http://rootsongjc.github.io/projects/yarn-on-docker/</link>
      <pubDate>Tue, 04 Apr 2017 00:19:04 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/projects/yarn-on-docker/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;作者：&lt;a href=&#34;rootsongjc.github.io/about/&#34;&gt;宋净超&lt;/a&gt; TalkingData云计算及大数据工程师&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;我已就该话题已在2016年上海Qcon上发表过演讲，&lt;a href=&#34;http://www.infoq.com/cn/presentations/yarn-on-docker-container-technology-in-big-data-scenarios&#34;&gt;点此观看&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;另外InfoQ网站上的文字版&lt;a href=&#34;http://www.infoq.com/cn/articles/YarnOnDocker-forDCCluster&#34;&gt;数据中心的Yarn on Docker集群方案&lt;/a&gt;，即本文。&lt;/p&gt;

&lt;p&gt;项目代码开源在Github上：&lt;a href=&#34;github.com/rootsongjc/magpie&#34;&gt;Magpie&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;当前数据中心存在的问题&#34;&gt;当前数据中心存在的问题&lt;/h2&gt;

&lt;p&gt;数据中心中的应用一般独立部署，为了保证环境隔离与方便管理，保证应用最大资源  数据中心中普遍存在如下问题：&lt;/p&gt;

&lt;p&gt;1.主机资源利用率低&lt;/p&gt;

&lt;p&gt;2.部署和扩展复杂&lt;/p&gt;

&lt;p&gt;3.资源隔离无法动态调整&lt;/p&gt;

&lt;p&gt;4.无法快速响应业务&lt;/p&gt;

&lt;p&gt;为何使用Yarnon Docker&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;彻底隔离队列 &lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;•  为了合理利用Hadoopyarn的资源，队列间会互相抢占计算资源，造成重要任务阻塞&lt;/p&gt;

&lt;p&gt;•  根据部门申请的机器数量划分Yarn集群方便财务管理&lt;/p&gt;

&lt;p&gt;•  更细粒度的资源分配 &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;统一的资源分配&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;•  每个NodeManager和容器都可以限定CPU、内存资源&lt;/p&gt;

&lt;p&gt;•  Yarn资源划分精确到CPU核数和内存大小 &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;弹性伸缩性服务&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;•  每个容器中运行一个NodeManager，增减yarn资源只需增减容器个数&lt;/p&gt;

&lt;p&gt;•  可以指定每个NodeManager拥有的计算资源多少，按需申请资源 &lt;/p&gt;

&lt;h2 id=&#34;给我们带来什么好处&#34;&gt;给我们带来什么好处？ &lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Swarm统一集群资源调度&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt; •  统一资源&lt;/p&gt;

&lt;p&gt;•  增加Docker虚拟化层，降低运维成本&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;增加Hadoop集群资源利用率&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;•  Fordatacenter：避免了静态资源隔离&lt;/p&gt;

&lt;p&gt;•  Forcluster：加强集群内部资源隔离&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;h2 id=&#34;系统架构&#34;&gt;系统架构&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/img/yarn-on-docker/td_yarn_arch.jpg&#34; alt=&#34;td_yarn_arch&#34; /&gt;&lt;/p&gt;

&lt;p&gt;  比如数据中心中运行的Hadoop集群，我们将HDFS依然运行在物理机上，即DataNode依然部署在实体机器上，将Yarn计算层运行在Docker容器中，整个系统使用二层资源调度，Spark、Flinek、MapReduce等应用运行在Yarn上。&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;    Swarm调度最底层的主机硬件资源，CPU和内存封装为Docker容器，容器中运行NodeManager，提供给Yarn集群，一个Swarm集群中可以运行多个Yarn集群，形成圈地式的Yarn计算集群。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/img/yarn-on-docker/td_yarn_arch2.jpg&#34; alt=&#34;td_yarn_arch2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;具体流程&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;1.swarm node向swarm master注册主机资源并加入到swarmcluster中&lt;/p&gt;

&lt;p&gt;2.swarm master向cluster申请资源请求启动容器&lt;/p&gt;

&lt;p&gt;3.swarm根据调度策略选择在某个node上启动dockercontainer&lt;/p&gt;

&lt;p&gt;4.swarm node的docker deamon根据容器启动参数启动相应资源大小的NodeManager&lt;/p&gt;

&lt;p&gt;5.NodeManager自动向YARN的ResourceManager注册资源一个NodeManager资源添加完成。&lt;/p&gt;

&lt;p&gt;  &lt;/p&gt;

&lt;p&gt;Swarm为数据中心做容器即主机资源调度，每个swarmnode的节点结构如图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/img/yarn-on-docker/td_yarn_arch3.jpg&#34; alt=&#34;td_yarn_arch3&#34; /&gt;&lt;/p&gt;

&lt;p&gt;一个Swarmnode就是一台物理机，每台主机上可以起多个同类型的dockercontainer，每个container的资源都有限制包括CPU、内存NodeManager容器只需要考虑本身进程占用的资源和需要给主机预留资源。假如主机是24核64G，我们可以分给一个容器5核12G，NodeManager占用4核10G的资源提供给Yarn。&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;KubernetesVS Swarm&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;   关于容器集群管理系统的选型，用Kubernetes还是Swarm？我们结合自己的经验和业务需求，对比如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/img/yarn-on-docker/td_yarn_compare.jpg&#34; alt=&#34;td_yarn_compare&#34; /&gt;&lt;/p&gt;

&lt;p&gt;基于以上四点，我们最终选择了Swarm，它基本满足我们的需求，掌握和开发时常较短。&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;h2 id=&#34;镜像制作与发布&#34;&gt;镜像制作与发布&lt;/h2&gt;

&lt;p&gt;镜像制作和发布流程如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/img/yarn-on-docker/td_yarn_ci.jpg&#34; alt=&#34;td_yarn_ci&#34; /&gt;&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;    用户从客户端提交代码到Gitlab中，需要包含Dockerfile文件，通过集成了docker插件的Jenkins的自动编译发布机制，自动build镜像后push到docker镜像仓库中，同一个项目每提交一次代码都会重新build一次镜像，生成不同的tag来标识镜像，Swarm集群使用该镜像仓库就可以直接拉取镜像。&lt;/p&gt;

&lt;p&gt;Dockerfile的编写技巧&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/img/yarn-on-docker/td_yarn_dockerfile.jpg&#34; alt=&#34;td_yarn_dockerfile&#34; /&gt;&lt;/p&gt;

&lt;p&gt; Dockerfile相当于docker镜像的编译打包流程说明，其中也不乏一些技巧。&lt;/p&gt;

&lt;p&gt;     &lt;/p&gt;

&lt;p&gt;    很多应用需要配置文件，如果想为每次启动容器的时候使用不同的配置参数，可以通过传递环境变量的方式来修改配置文件，前提是需要写一个bash脚本，脚本中来处理配置文件，再将这个脚本作为entrypoint入口，每当容器启动时就会执行这个脚本从而替换配置文件中的参数，也可以通过CMD传递参数给该脚本。&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;启动容器的时候通过传递环境变量的方式修改配置文件：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;docker run -d 
--net=mynet 
-e NAMESERVICE=nameservice 
-e ACTIVE_NAMENODE_ID=namenode29 \
-e STANDBY_NAMENODE_ID=namenode63 \
-e HA_ZOOKEEPER_QUORUM=zk1:2181,zk2:2181,zk3:2181 \
-e YARN_ZK_DIR=rmstore \
-e YARN_CLUSTER_ID=yarnRM \
-e YARN_RM1_IP=rm1 \
-e YARN_RM2_IP=rm2 \
-e CPU_CORE_NUM=5
-e NODEMANAGER_MEMORY_MB=12288 \
-e YARN_JOBHISTORY_IP=jobhistory \
-e ACTIVE_NAMENODE_IP=active-namenode \
-e STANDBY_NAMENODE_IP=standby-namenode \
-e HA=yes \
docker-registry/library/hadoop-yarn:v0.1 resourcemanager
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最后传递resourcemanager或者nodemanager参数指定启动相应的服务。&lt;/p&gt;

&lt;p&gt;集群管理&lt;/p&gt;

&lt;p&gt;我开发的命令行工具&lt;a href=&#34;https://github.com/rootsongjc/magpie&#34;&gt;magpie&lt;/a&gt;，也可以通过其他开源可视化页面来管理集群，比如shipyard。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/img/yarn-on-docker/td_yarn_shipyard.jpg&#34; alt=&#34;td_yarn_shipyard&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;自定义网络&#34;&gt;自定义网络&lt;/h2&gt;

&lt;p&gt; Docker容器跨主机互访一直是一个问题，Docker官方为了避免网络上带来的诸多麻烦，故将跨主机网络开了比较大的口子，而由用户自己去实现。我们开发并开源了Shrike这个docker网络插件，大家可以在这里下载到：&lt;a href=&#34;https://github.com/rootsongjc/docker-ipam-plugin&#34;&gt;https://github.com/rootsongjc/docker-ipam-plugin&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;    目前Docker跨主机的网络实现方案也有很多种, 主要包括端口映射，ovs,fannel等。但是这些方案都无法满足我们的需求，端口映射服务内的内网IP会映射成外网的IP，这样会给开发带来困惑，因为他们往往在跨网络交互时是不需要内网IP的，而ovs与fannel则是在基础网络协议上又包装了一层自定义协议，这样当网络流量大时，却又无端的增加了网络负载，最后我们采取了自主研发扁平化网络插件，也就是说让所有的容器统统在大二层上互通。架构如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/img/yarn-on-docker/td_yarn_network.jpg&#34; alt=&#34;td_yarn_network&#34; /&gt;&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;我们首先需要创建一个br0自定义网桥，这个网桥并不是通过系统命令手动建立的原始Linux网桥，而是通过Docker的cerate network命令来建立的自定义网桥，这样避免了一个很重要的问题就是我们可以通过设置DefaultGatewayIPv4参数来设置容器的默认路由，这个解决了原始Linux自建网桥不能解决的问题. 用Docker创建网络时我们可以通过设置subnet参数来设置子网IP范围，默认我们可以把整个网段给这个子网，后面可以用ipamdriver（地址管理插件）来进行控制。还有一个参数gateway是用来设置br0自定义网桥地址的，其实也就是你这台宿主机的地址。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Shell&#34;&gt;docker network create 
--opt=com.docker.network.bridge.enable_icc=true
--opt=com.docker.network.bridge.enable_ip_masquerade=false
--opt=com.docker.network.bridge.host_binding_ipv4=0.0.0.0
--opt=com.docker.network.bridge.name=br0
--opt=com.docker.network.driver.mtu=1500
--ipam-driver=talkingdata
--subnet=容器IP的子网范围
--gateway=br0网桥使用的IP,也就是宿主机的地址
--aux-address=DefaultGatewayIPv4=容器使用的网关地址
mynet
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/img/yarn-on-docker/td_yarn_ipam.jpg&#34; alt=&#34;td_yarn_ipam&#34; /&gt;&lt;/p&gt;

&lt;p&gt;IPAM驱动是专门管理Docker 容器IP的, Docker 每次启停与删除容器都会调用这个驱动提供的IP管理接口，然后IP接口会对存储IP地址的Etcd有一个增删改查的操作。此插件运行时会起一个UnixSocket, 然后会在docker/run/plugins目录下生成一个.sock文件，Dockerdaemon之后会和这个sock 文件进行沟通去调用我们之前实现好的几个接口进行IP管理，以此来达到IP管理的目的，防止IP冲突。&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;    通过Docker命令去创建一个自定义的网络起名为“mynet”，同时会产生一个网桥br0，之后通过更改网络配置文件（在/etc/sysconfig/network-scripts/下ifcfg-br0、ifcfg-默认网络接口名）将默认网络接口桥接到br0上，重启网络后，桥接网络就会生效。Docker默认在每次启动容器时都会将容器内的默认网卡桥接到br0上，而且宿主机的物理网卡也同样桥接到了br0上了。其实桥接的原理就好像是一台交换机，Docker 容器和宿主机物理网络接口都是服务器，通过vethpair这个网络设备像一根网线插到交换机上。至此，所有的容器网络已经在同一个网络上可以通信了，每一个Docker容器就好比是一台独立的虚拟机，拥有和宿主机同一网段的IP，可以实现跨主机访问了。&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;h2 id=&#34;性能瓶颈与优化&#34;&gt;性能瓶颈与优化&lt;/h2&gt;

&lt;p&gt;    大家可能会担心自定义网络的性能问题，为此我们用iperf进行了网络性能测试。我们对比了不同主机容器间的网速，同一主机上的不同容器和不同主机间的网速，结果如下表：&lt;/p&gt;

&lt;p&gt; &lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/img/yarn-on-docker/td_yarn_iperf.jpg&#34; alt=&#34;td_yarn_iperf&#34; /&gt;&lt;/p&gt;

&lt;p&gt; 从表中我们可以看到，在这一组测试中，容器间的网速与容器是在想通主机还是在不同主机上的差别不大，说明我们的网络插件性能还是很优异的。&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;h2 id=&#34;hadoop配置优化&#34;&gt;Hadoop配置优化 &lt;/h2&gt;

&lt;p&gt;    因为使用docker将原来一台机器一个nodemanager给细化为了多个，会造成nodemanager个数的成倍增加，因此hadoop的一些配置需要相应优化。&lt;/p&gt;

&lt;p&gt;•  yarn.nodemanager.localizer.fetch.thread-count 随着容器数量增加，需要相应调整该参数&lt;/p&gt;

&lt;p&gt;•  yarn.resourcemanager.amliveliness-monitor.interval-ms默认1秒，改为10秒，否则时间太短可能导致有些节点无法注册&lt;/p&gt;

&lt;p&gt;•  yarn.resourcemanager.resource-tracker.client.thread-count默认50，改为100，随着容器数量增加，需要相应调整该参数&lt;/p&gt;

&lt;p&gt;•  yarn.nodemanager.pmem-check-enabled默认true，改为false，不检查任务正在使用的物理内存量&lt;/p&gt;

&lt;p&gt;•  容器中hadoop ulimit值修改，默认4096，改成655350&lt;/p&gt;

&lt;p&gt;集群监控&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;如果使用shipyard管理集群会有一个单独的监控页面，可以看到一定时间段内的CPU、内存、IO、网络使用状况。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/img/yarn-on-docker/td_yarn_monitor.jpg&#34; alt=&#34;td_yarn_monitor&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;关于未来&#34;&gt;关于未来&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://olz1di9xf.bkt.clouddn.com/img/yarn-on-docker/td_yarn_os.jpg&#34; alt=&#34;td_yarn_os&#34; /&gt; &lt;/p&gt;

&lt;p&gt;    我们未来规划做的是DC／OS，基于Docker的应用自动打包编译分发系统，让开发人员可以很便捷的申请资源，上下线服务，管理应用。要达到这个目标还有很多事情要做：&lt;/p&gt;

&lt;p&gt;•  Service Control Panel：统一的根据服务来管理的web页面&lt;/p&gt;

&lt;p&gt;•  Loadbalance：容器根据机器负载情况自动迁移&lt;/p&gt;

&lt;p&gt;•  Scheduler：swarm调度策略优化&lt;/p&gt;

&lt;p&gt;•  服务配置文件：提供镜像启动参数的配置文件，所有启动参数可通过文件配置&lt;/p&gt;

&lt;p&gt;•  监控：服务级别的监控&lt;/p&gt;

&lt;h2 id=&#34;后记&#34;&gt;后记&lt;/h2&gt;

&lt;p&gt;这篇文章写好的时候是2016年10月，距离现在我添加&lt;strong&gt;前言&lt;/strong&gt;和&lt;strong&gt;后记&lt;/strong&gt;的已经快半年时间了，这段时间内业界也发生了很多变化，比如docker推出CE和SE版本，Google的kubernetes发布了1.6版本，人工智能依然大热，在可预见的未来，可以说&lt;u&gt;Kubernetes一定会远远超越Docker成为容器编排领域的王者&lt;/u&gt;，这是毋庸置疑的，对于docker 17.03-CE我也研究过了一段时间，其disgusting的plugin让我对于docker的编排已经失去信心。&lt;/p&gt;

&lt;p&gt;其实容器在大数据场景下的应用并不是很多，毕竟Hadoop那套笨重的东西放在容器下运行，上生产环境? Are you kidding me?如果说做原型验证、研发测试那还可以。这样就大大限制了容器技术在大数据场景下的应用场景。使用容器的编排调度来实现大数据集群的资源优化有点舍本逐末，&lt;u&gt;如果真的要优化集群资源利用率的话，应该让不同的应用混跑，而不应该让集群之间资源隔离，比如Web应用跟大数据应用混布。&lt;/u&gt;目前的这种&lt;strong&gt;Yarn on Docker&lt;/strong&gt;方案实质上是将原来的整体Hadoop Yarn集群划分成多个不同的Yarn，将存储和计算分离了。其实这跟&lt;strong&gt;Nutanix&lt;/strong&gt;的超融合架构有点像，Nutanix是由前Google的工程师创立的，解决虚拟化计算环境下的存储问题，也是将存储和计算分离，共享存储，计算根据需要调度。事实上Yahoo已经有解决Hadoop集群的资源细粒度分配和调度问题的方案，这应该是从Yarn的scheduler层来处理。&lt;/p&gt;

&lt;p&gt;Swarm已死，Swarmkit将继续发展，Docker的Swarm Mode还会在艰难中前行，目前看到的趋势仍然是模仿Kubernentes为主，没有自己鲜明的特色（除了部署管理方便意外，谁让它就集成在了docker里呢，就像当年windows集成IE打败Netscape，不过这不会再此上演了），Kubernentes又是一个通用的资源调度框架，它的最小资源划分是&lt;strong&gt;Pod&lt;/strong&gt;而不是docker，它还可以运行rkt、containerd。&lt;/p&gt;

&lt;p&gt;上周起我开始将注意力转移到kubernentes，以后请关注我的&lt;a href=&#34;http://rootsongjc.github.io/tags/kubernetes/&#34;&gt;Kuberentes实践&lt;/a&gt;相关文章。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Go语言中的并发编程总结</title>
      <link>http://rootsongjc.github.io/projects/golang-concurrency-summary/</link>
      <pubDate>Fri, 24 Mar 2017 08:36:29 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/projects/golang-concurrency-summary/</guid>
      <description>

&lt;h1 id=&#34;go语言并发编程总结&#34;&gt;Go语言并发编程总结&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Golang :不要通过共享内存来通信，而应该通过通信来共享内存。这句风靡在Go社区的话,说的就是 goroutine中的 channel。他在go并发编程中充当着类型安全的管道作用。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;1-通过golang中的-goroutine-与sync-mutex进行并发同步&#34;&gt;1、通过golang中的 goroutine 与sync.Mutex进行并发同步&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;import( 

    &amp;quot;fmt&amp;quot;

    &amp;quot;sync&amp;quot;

    &amp;quot;runtime&amp;quot;

)

var count int =0;

func counter(lock * sync.Mutex){

      lock.Lock()

      count++

      fmt.Println(count)

      lock.Unlock()

}

func main(){

   lock:=&amp;amp;sync.Mutex{}

   for i:=0;i&amp;lt;10;i++{

      //传递指针是为了防止 函数内的锁和 调用锁不一致

      go counter(lock)  

     }

   for{

      lock.Lock()

      c:=count

      lock.Unlock()

      ///把时间片给别的goroutine  未来某个时刻运行该routine

      runtime.Gosched()

      if c&amp;gt;=10{

        fmt.Println(&amp;quot;goroutine end&amp;quot;)

        break

        }

   }    

}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;2-goroutine之间通过-channel进行通信&#34;&gt;2、goroutine之间通过 channel进行通信&lt;/h2&gt;

&lt;p&gt;channel是和类型相关的 可以理解为  是一种类型安全的管道。&lt;/p&gt;

&lt;p&gt;简单的channel 使用&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;
package main  

import &amp;quot;fmt&amp;quot;

func Count(ch chan int) {

    ch &amp;lt;- 1  

    fmt.Println(&amp;quot;Counting&amp;quot;)

}

func main() {

    chs := make([]chan int, 10)

for i := 0; i &amp;lt; 10; i++ {

        chs[i] = make(chan int)

  go Count(chs[i])

  fmt.Println(&amp;quot;Count&amp;quot;,i)

    }

for i, ch := range chs {

  &amp;lt;-ch

  fmt.Println(&amp;quot;Counting&amp;quot;,i)

    }  

} 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;3-go语言中的select是语言级内置-非堵塞&#34;&gt;3、Go语言中的select是语言级内置  非堵塞&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;select {

case &amp;lt;-chan1: // 如果chan1成功读到数据，则进行该case处理语句  

case chan2 &amp;lt;- 1: // 如果成功向chan2写入数据，则进行该case处理语句  

default: // 如果上面都没有成功，则进入default处理流程  

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看出，select不像switch，后面并不带判断条件，而是直接去查看case语句。每个&lt;/p&gt;

&lt;p&gt;case语句都必须是一个面向channel的操作。比如上面的例子中，第一个case试图从chan1读取&lt;/p&gt;

&lt;p&gt;一个数据并直接忽略读到的数据，而第二个case则是试图向chan2中写入一个整型数1，如果这&lt;/p&gt;

&lt;p&gt;两者都没有成功，则到达default语句。&lt;/p&gt;

&lt;h2 id=&#34;4-channel-的带缓冲读取写入&#34;&gt;4、channel 的带缓冲读取写入&lt;/h2&gt;

&lt;p&gt;之前我们示范创建的都是不带缓冲的channel，这种做法对于传递单个数据的场景可以接受，&lt;/p&gt;

&lt;p&gt;但对于需要持续传输大量数据的场景就有些不合适了。接下来我们介绍如何给channel带上缓冲，&lt;/p&gt;

&lt;p&gt;从而达到消息队列的效果。&lt;/p&gt;

&lt;p&gt;要创建一个带缓冲的channel，其实也非常容易：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Go&#34;&gt;c := make(chan int, 1024)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在调用make()时将缓冲区大小作为第二个参数传入即可，比如上面这个例子就创建了一个大小&lt;/p&gt;

&lt;p&gt;为1024的int类型channel，即使没有读取方，写入方也可以一直往channel里写入，在缓冲区被&lt;/p&gt;

&lt;p&gt;填完之前都不会阻塞。&lt;/p&gt;

&lt;p&gt;从带缓冲的channel中读取数据可以使用与常规非缓冲channel完全一致的方法，但我们也可&lt;/p&gt;

&lt;p&gt;以使用range关键来实现更为简便的循环读取：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;for i := range c {

    fmt.Println(&amp;quot;Received:&amp;quot;, i)

} 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;5-用goroutine模拟生产消费者&#34;&gt;5、用goroutine模拟生产消费者&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import &amp;quot;fmt&amp;quot;

import &amp;quot;time&amp;quot;

func Producer (queue chan&amp;lt;- int){

        for i:= 0; i &amp;lt; 10; i++ {

                queue &amp;lt;- i  

                }

}

func Consumer( queue &amp;lt;-chan int){

        for i :=0; i &amp;lt; 10; i++{

                v := &amp;lt;- queue

                fmt.Println(&amp;quot;receive:&amp;quot;, v)

        }

}

func main(){

        queue := make(chan int, 1)

        go Producer(queue)

        go Consumer(queue)

        time.Sleep(1e9) //让Producer与Consumer完成

}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;6-通过make-创建通道&#34;&gt;6、 通过make 创建通道&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;make(c1 chan int)   创建的是 同步channel ...读写完全对应

make(c1 chan int ,10) 闯进带缓冲的通道 上来可以写10次
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;7-随机向通道中写入0或者1&#34;&gt;7、随机向通道中写入0或者1&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import &amp;quot;fmt&amp;quot;

import &amp;quot;time&amp;quot;

func main(){

       ch := make(chan int, 1)

 for {

   ///不停向channel中写入 0 或者1

  select {

   case ch &amp;lt;- 0:

   case ch &amp;lt;- 1:

  }

    //从通道中取出数据

    i := &amp;lt;-ch

    fmt.Println(&amp;quot;Value received:&amp;quot;,i)

    time.Sleep(1e8)

    }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;8-带缓冲的channel&#34;&gt;8、带缓冲的channel&lt;/h2&gt;

&lt;p&gt;之前创建的都是不带缓冲的channel，这种做法对于传递单个数据的场景可以接受，&lt;/p&gt;

&lt;p&gt;但对于需要持续传输大量数据的场景就有些不合适了。接下来我们介绍如何给channel带上缓冲，&lt;/p&gt;

&lt;p&gt;从而达到消息队列的效果。&lt;/p&gt;

&lt;p&gt;要创建一个带缓冲的channel，其实也非常容易：&lt;/p&gt;

&lt;p&gt;c := make(chan int, 1024)&lt;/p&gt;

&lt;p&gt;在调用make()时将缓冲区大小作为第二个参数传入即可，比如上面这个例子就创建了一个大小&lt;/p&gt;

&lt;p&gt;为1024的int类型channel，即使没有读取方，写入方也可以一直往channel里写入，在缓冲区被&lt;/p&gt;

&lt;p&gt;填完之前都不会阻塞。&lt;/p&gt;

&lt;p&gt;从带缓冲的channel中读取数据可以使用与常规非缓冲channel完全一致的方法，但我们也可&lt;/p&gt;

&lt;p&gt;以使用range关键来实现更为简便的循环读取：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;for i := range c {

    fmt.Println(&amp;quot;Received:&amp;quot;, i)

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;下面是测试代码&lt;/strong&gt;&amp;lsquo;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import &amp;quot;fmt&amp;quot;

import &amp;quot;time&amp;quot;

func A(c chan int){

 for i:=0;i&amp;lt;10;i++{

        c&amp;lt;- i

    }

}

func B(c chan int){

 for val:=range c {

      fmt.Println(&amp;quot;Value:&amp;quot;,val)  

    }

}

func main(){

    chs:=make(chan int,10)

    //只要有通道操作一定要放到goroutine中否则 会堵塞当前的主线程 并且导致程序退出

    //对于同步通道 或者带缓冲的通道 一定要封装成函数 使用 goroutine 包装

    go A(chs)

    go B(chs)

    time.Sleep(1e9)

}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;9-关于创建多个goroutine具体到go语言会创建多少个线程&#34;&gt;9、关于创建多个goroutine具体到go语言会创建多少个线程&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;import &amp;quot;os&amp;quot;

func main() {

    for i:=0; i&amp;lt;20; i++ {

        go func() {

            for {

                b:=make([]byte, 10)

                os.Stdin.Read(b) // will block

            }

        }()

    }

    select{}

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;会产生21个线程：&lt;/p&gt;

&lt;p&gt;runtime scheduler(src/pkg/runtime/proc.c)会维护一个线程池，当某个goroutine被block后，scheduler会创建一个新线程给其他ready的goroutine&lt;/p&gt;

&lt;p&gt;GOMAXPROCS控制的是未被阻塞的所有goroutine被multiplex到多少个线程上运行&lt;/p&gt;

&lt;h2 id=&#34;10-在channel中也是可以传递channel的-go语言的channel和map-slice等一样都是原生类型&#34;&gt;10、在channel中也是可以传递channel的,Go语言的channel和map、slice等一样都是原生类型&lt;/h2&gt;

&lt;p&gt;需要注意的是，在Go语言中channel本身也是一个原生类型，与map之类的类型地位一样，因&lt;/p&gt;

&lt;p&gt;此channel本身在定义后也可以通过channel来传递。&lt;/p&gt;

&lt;p&gt;我们可以使用这个特性来实现*nix上非常常见的管道（pipe）特性。管道也是使用非常广泛&lt;/p&gt;

&lt;p&gt;的一种设计模式，比如在处理数据时，我们可以采用管道设计，这样可以比较容易以插件的方式&lt;/p&gt;

&lt;p&gt;增加数据的处理流程。&lt;/p&gt;

&lt;p&gt;下面我们利用channel可被传递的特性来实现我们的管道。 为了简化表达， 我们假设在管道中&lt;/p&gt;

&lt;p&gt;传递的数据只是一个整型数，在实际的应用场景中这通常会是一个数据块。&lt;/p&gt;

&lt;p&gt;首先限定基本的数据结构：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type PipeData struct {

    value int

    handler func(int) int

    next chan int

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我们写一个常规的处理函数。我们只要定义一系列PipeData的数据结构并一起传递给&lt;/p&gt;

&lt;p&gt;这个函数，就可以达到流式处理数据的目的：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func handle(queue chan *PipeData) {

for data := range queue {

        data.next &amp;lt;- data.handler(data.value)

    }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;11-我们默认创建的是双向通道-单向通道没有意义-但是我们却可以通过强制转换-将双向通道-转换成为单向通道&#34;&gt;11、我们默认创建的是双向通道,单向通道没有意义,但是我们却可以通过强制转换 将双向通道 转换成为单向通道 。&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var ch1 chan int  // ch1是一个正常的channel，不是单向的  

var ch2 chan&amp;lt;- float64// ch2是单向channel，只用于写float64数据

var ch3 &amp;lt;-chan int // ch3是单向channel，只用于读取int数据 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;channel是一个原生类型，因此不仅 支持被传递，还支持类型转换。只有在介绍了单向channel的概念后，读者才会明白类型转换对于&lt;/p&gt;

&lt;p&gt;channel的意义：就是在单向channel和双向channel之间进行转换。&lt;/p&gt;

&lt;p&gt;示例如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;ch4 := make(chan int)

ch5 := &amp;lt;-chan int(ch4) // ch5就是一个单向的读取channel

ch6 := chan&amp;lt;- int(ch4) // ch6 是一个单向的写入channel
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;基于ch4，我们通过类型转换初始化了两个单向channel：单向读的ch5和单向写的ch6。&lt;/p&gt;

&lt;p&gt;从设计的角度考虑，所有的代码应该都遵循“最小权限原则” ，&lt;/p&gt;

&lt;p&gt;从而避免没必要地使用泛滥问题， 进而导致程序失控。 写过C++程序的读者肯定就会联想起const 指针的用法。非const指针具备const指针的所有功能，将一个指针设定为const就是明确告诉&lt;/p&gt;

&lt;p&gt;函数实现者不要试图对该指针进行修改。单向channel也是起到这样的一种契约作用。&lt;/p&gt;

&lt;p&gt;下面我们来看一下单向channel的用法：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func Parse(ch &amp;lt;-chan int) {

for value := range ch {

        fmt.Println(&amp;quot;Parsing value&amp;quot;, value)  

    }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;除非这个函数的实现者无耻地使用了类型转换，否则这个函数就不会因为各种原因而对ch 进行写，避免在ch中出现非期望的数据，从而很好地实践最小权限原则。&lt;/p&gt;

&lt;h2 id=&#34;12-只读只写单向-channel-代码例子-遵循权限最小化的原则&#34;&gt;12、只读只写单向 channel 代码例子，遵循权限最小化的原则&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import &amp;quot;fmt&amp;quot;

import &amp;quot;time&amp;quot;

//接受一个参数 是只允许读取通道  除非直接强制转换 要么你只能从channel中读取数据

func sCh(ch &amp;lt;-chan int){

   for val:= range ch {

     fmt.Println(val)

   }

}

func main(){

    //创建一个带100缓冲的通道 可以直接写入 而不会导致 主线程堵塞

    dch:=make(chan int,100)

    for i:=0;i&amp;lt;100;i++{

      dch&amp;lt;- i  

    }

    //传递进去 只读通道

    go sCh(dch)

    time.Sleep(1e9)

}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;13-channel的关闭-以及判断channel的关闭&#34;&gt;13、channel的关闭,以及判断channel的关闭&lt;/h2&gt;

&lt;p&gt;关闭channel非常简单，直接使用Go语言内置的close()函数即可：&lt;/p&gt;

&lt;p&gt;close(ch)&lt;/p&gt;

&lt;p&gt;在介绍了如何关闭channel之后，我们就多了一个问题：如何判断一个channel是否已经被关&lt;/p&gt;

&lt;p&gt;闭？我们可以在读取的时候使用多重返回值的方式：&lt;/p&gt;

&lt;p&gt;x, ok := &amp;lt;-ch&lt;/p&gt;

&lt;p&gt;这个用法与map中的按键获取value的过程比较类似，只需要看第二个bool返回值即可，如&lt;/p&gt;

&lt;p&gt;果返回值是false则表示ch已经被关闭。&lt;/p&gt;

&lt;h2 id=&#34;14-go的多核并行化编程&#34;&gt;14、Go的多核并行化编程&lt;/h2&gt;

&lt;p&gt;高性能并发编程 必须设置GOMAXPROCS 为最大核数目,这个值由runtime.NumCPU()获取&lt;/p&gt;

&lt;p&gt;在执行一些昂贵的计算任务时， 我们希望能够尽量利用现代服务器普遍具备的多核特性来尽&lt;/p&gt;

&lt;p&gt;量将任务并行化，从而达到降低总计算时间的目的。此时我们需要了解CPU核心的数量，并针对&lt;/p&gt;

&lt;p&gt;性地分解计算任务到多个goroutine中去并行运行。&lt;/p&gt;

&lt;p&gt;下面我们来模拟一个完全可以并行的计算任务：计算N个整型数的总和。我们可以将所有整&lt;/p&gt;

&lt;p&gt;型数分成M份，M即CPU的个数。让每个CPU开始计算分给它的那份计算任务，最后将每个CPU&lt;/p&gt;

&lt;p&gt;的计算结果再做一次累加，这样就可以得到所有N个整型数的总和：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Vector []float64

// 分配给每个CPU的计算任务

func (v Vector) DoSome(i, n int, u Vector, c chan int) {

for ; i &amp;lt; n; i++ {

         v[i] += u.Op(v[i])

     }

     c &amp;lt;- 1       

// 发信号告诉任务管理者我已经计算完成了

}

const NCPU = 16     

// 假设总共有16核   

func (v Vector) DoAll(u Vector) {   

    c := make(chan int, NCPU)  // 用于接收每个CPU的任务完成信号   

for i := 0; i &amp;lt; NCPU; i++ {   

go v.DoSome(i*len(v)/NCPU, (i+1)*len(v)/NCPU, u, c)

    } 

// 等待所有CPU的任务完成

for i := 0; i &amp;lt; NCPU; i++ {   

&amp;lt;-c    // 获取到一个数据，表示一个CPU计算完成了

    }

// 到这里表示所有计算已经结束

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这两个函数看起来设计非常合理。DoAll()会根据CPU核心的数目对任务进行分割，然后开&lt;/p&gt;

&lt;p&gt;辟多个goroutine来并行执行这些计算任务。&lt;/p&gt;

&lt;p&gt;是否可以将总的计算时间降到接近原来的1/N呢？答案是不一定。如果掐秒表（正常点的话，&lt;/p&gt;

&lt;p&gt;应该用7.8节中介绍的Benchmark方法） ，会发现总的执行时间没有明显缩短。再去观察CPU运行&lt;/p&gt;

&lt;p&gt;状态， 你会发现尽管我们有16个CPU核心， 但在计算过程中其实只有一个CPU核心处于繁忙状态，&lt;/p&gt;

&lt;p&gt;这是会让很多Go语言初学者迷惑的问题。&lt;/p&gt;

&lt;p&gt;官方的答案是，这是当前版本的Go编译器还不能很智能地去发现和利用多核的优势。虽然&lt;/p&gt;

&lt;p&gt;我们确实创建了多个goroutine，并且从运行状态看这些goroutine也都在并行运行，但实际上所有&lt;/p&gt;

&lt;p&gt;这些goroutine都运行在同一个CPU核心上， 在一个goroutine得到时间片执行的时候， 其他goroutine&lt;/p&gt;

&lt;p&gt;都会处于等待状态。从这一点可以看出，虽然goroutine简化了我们写并行代码的过程，但实际上&lt;/p&gt;

&lt;p&gt;整体运行效率并不真正高于单线程程序。&lt;/p&gt;

&lt;p&gt;在Go语言升级到默认支持多CPU的某个版本之前，我们可以先通过设置环境变量&lt;/p&gt;

&lt;p&gt;GOMAXPROCS的值来控制使用多少个CPU核心。具体操作方法是通过直接设置环境变量&lt;/p&gt;

&lt;p&gt;GOMAXPROCS的值，或者在代码中启动goroutine之前先调用以下这个语句以设置使用16个CPU&lt;/p&gt;

&lt;p&gt;核心：&lt;/p&gt;

&lt;p&gt;runtime.GOMAXPROCS(16)&lt;/p&gt;

&lt;p&gt;到底应该设置多少个CPU核心呢，其实runtime包中还提供了另外一个函数NumCPU()来获&lt;/p&gt;

&lt;p&gt;取核心数。可以看到，Go语言其实已经感知到所有的环境信息，下一版本中完全可以利用这些&lt;/p&gt;

&lt;p&gt;信息将goroutine调度到所有CPU核心上，从而最大化地利用服务器的多核计算能力。抛弃&lt;/p&gt;

&lt;p&gt;GOMAXPROCS只是个时间问题。&lt;/p&gt;

&lt;h2 id=&#34;15-主动出让时间片给其他-goroutine-在未来的某一时刻再来执行当前goroutine&#34;&gt;15、主动出让时间片给其他 goroutine 在未来的某一时刻再来执行当前goroutine&lt;/h2&gt;

&lt;p&gt;我们可以在每个goroutine中控制何时主动出让时间片给其他goroutine，这可以使用runtime&lt;/p&gt;

&lt;p&gt;包中的Gosched()函数实现。&lt;/p&gt;

&lt;p&gt;实际上，如果要比较精细地控制goroutine的行为，就必须比较深入地了解Go语言开发包中&lt;/p&gt;

&lt;p&gt;runtime包所提供的具体功能。&lt;/p&gt;

&lt;h2 id=&#34;16-go中的同步&#34;&gt;16、Go中的同步&lt;/h2&gt;

&lt;p&gt;倡导用通信来共享数据，而不是通过共享数据来进行通信，但考虑&lt;/p&gt;

&lt;p&gt;到即使成功地用channel来作为通信手段，还是避免不了多个goroutine之间共享数据的问题，Go&lt;/p&gt;

&lt;p&gt;语言的设计者虽然对channel有极高的期望，但也提供了妥善的资源锁方案。&lt;/p&gt;

&lt;h2 id=&#34;17-go中的同步锁&#34;&gt;17、Go中的同步锁&lt;/h2&gt;

&lt;p&gt;倡导用通信来共享数据，而不是通过共享数据来进行通信，但考虑&lt;/p&gt;

&lt;p&gt;到即使成功地用channel来作为通信手段，还是避免不了多个goroutine之间共享数据的问题，Go&lt;/p&gt;

&lt;p&gt;语言的设计者虽然对channel有极高的期望，但也提供了妥善的资源锁方案。&lt;/p&gt;

&lt;p&gt;对于这两种锁类型， 任何一个Lock()或RLock()均需要保证对应有Unlock()或RUnlock()&lt;/p&gt;

&lt;p&gt;调用与之对应，否则可能导致等待该锁的所有goroutine处于饥饿状态，甚至可能导致死锁。锁的&lt;/p&gt;

&lt;p&gt;典型使用模式如下：&lt;/p&gt;

&lt;p&gt;var l sync.Mutex&lt;/p&gt;

&lt;p&gt;func foo() {&lt;/p&gt;

&lt;p&gt;l.Lock()&lt;/p&gt;

&lt;p&gt;//延迟调用 在函数退出 并且局部资源被释放的时候 调用&lt;/p&gt;

&lt;p&gt;defer l.Unlock()&lt;/p&gt;

&lt;p&gt;//&amp;hellip;&lt;/p&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;这里我们再一次见证了Go语言defer关键字带来的优雅&lt;/p&gt;

&lt;h2 id=&#34;18-全局唯一操作-sync-once-do-sync-atomic原子操作子包&#34;&gt;18、全局唯一操作 sync.Once.Do()     sync.atomic原子操作子包&lt;/h2&gt;

&lt;p&gt;对于从全局的角度只需要运行一次的代码，比如全局初始化操作，Go语言提供了一个Once&lt;/p&gt;

&lt;p&gt;类型来保证全局的唯一性操作，具体代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var a string

var once sync.Once  

func setup() {

a = &amp;quot;hello, world&amp;quot;

}  

func doprint() {

once.Do(setup)

print(a)  

}  

func twoprint() {

go doprint()

go doprint()  

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果这段代码没有引入Once， setup()将会被每一个goroutine先调用一次， 这至少对于这个&lt;/p&gt;

&lt;p&gt;例子是多余的。在现实中，我们也经常会遇到这样的情况。Go语言标准库为我们引入了Once类&lt;/p&gt;

&lt;p&gt;型以解决这个问题。once的Do()方法可以保证在全局范围内只调用指定的函数一次（这里指&lt;/p&gt;

&lt;p&gt;setup()函数） ，而且所有其他goroutine在调用到此语句时，将会先被阻塞，直至全局唯一的&lt;/p&gt;

&lt;p&gt;once.Do()调用结束后才继续。&lt;/p&gt;

&lt;p&gt;这个机制比较轻巧地解决了使用其他语言时开发者不得不自行设计和实现这种Once效果的&lt;/p&gt;

&lt;p&gt;难题，也是Go语言为并发性编程做了尽量多考虑的一种体现。&lt;/p&gt;

&lt;p&gt;如果没有once.Do()，我们很可能只能添加一个全局的bool变量，在函数setup()的最后&lt;/p&gt;

&lt;p&gt;一行将该bool变量设置为true。在对setup()的所有调用之前，需要先判断该bool变量是否已&lt;/p&gt;

&lt;p&gt;经被设置为true，如果该值仍然是false，则调用一次setup()，否则应跳过该语句。实现代码&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var done bool = false

func setup() {

a = &amp;quot;hello, world&amp;quot; 

done = true

}     

func doprint() { 

if !done {

        setup()

    }   

print(a)  

}  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这段代码初看起来比较合理， 但是细看还是会有问题， 因为setup()并不是一个原子性操作，&lt;/p&gt;

&lt;p&gt;这种写法可能导致setup()函数被多次调用，从而无法达到全局只执行一次的目标。这个问题的&lt;/p&gt;

&lt;p&gt;复杂性也更加体现了Once类型的价值。&lt;/p&gt;

&lt;p&gt;为了更好地控制并行中的原子性操作，sync包中还包含一个atomic子包，它提供了对于一&lt;/p&gt;

&lt;p&gt;些基础数据类型的原子操作函数，比如下面这个函数：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;func CompareAndSwapUint64(val *uint64, old, new uint64) (swapped bool)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;就提供了比较和交换两个uint64类型数据的操作。这让开发者无需再为这样的操作专门添加Lock操作。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://lib.csdn.net/article/53/36140?knId=1441&#34;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker技术选型</title>
      <link>http://rootsongjc.github.io/projects/docker-tech-selection/</link>
      <pubDate>Wed, 08 Mar 2017 10:37:01 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/projects/docker-tech-selection/</guid>
      <description>

&lt;h2 id=&#34;回顾历史&#34;&gt;回顾历史&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;多少次我回过头看看走过的路，你还在小村旁。&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;去年基于docker1.11对Hadoop yarn进行了docker化改造，详情请看&lt;a href=&#34;https://rootsongjc.github.io/docker-practice/docs/td_yarn_on_docker.html&#34;&gt;大数据集群虚拟化-Yarn on docker始末&lt;/a&gt;，我将这个事件命名为&lt;a href=&#34;https://github.com/rootsongjc/magpie&#34;&gt;magpie&lt;/a&gt;，因为它就像是喜鹊一样收集着各种各样的资源搭建自己的小窝。&lt;strong&gt;magpie&lt;/strong&gt;还是有很多事情可以做的，大数据集群的虚拟化也不会止步，它仅仅是对其做了初步的探索，对于资源利用率和管理方面的优化还有很长的路要走，&lt;strong&gt;Yarn&lt;/strong&gt;本身就是做为大数据集群的资源管理调度角色出现的，一开始是为调度&lt;strong&gt;MapReduce&lt;/strong&gt;，后来的&lt;code&gt;spark&lt;/code&gt;、&lt;code&gt;hive&lt;/code&gt;、&lt;code&gt;tensrflow&lt;/code&gt;、&lt;code&gt;HAWQ&lt;/code&gt;、&lt;code&gt;slide&lt;/code&gt;等等不一而足陆续出现。但是用它来管理docker似乎还是有点过重，还不如用kubernetes、marathon、nomad、swarm等。&lt;/p&gt;

&lt;p&gt;但是在微服务方面docker1.11的很多弊端或者说缺点就暴露了出来，首先docker1.11原生并不带cluster管理，需要配合·&lt;code&gt;docker swarm&lt;/code&gt;、&lt;code&gt;kubernetes&lt;/code&gt;、&lt;code&gt;marathon&lt;/code&gt;等才能管理docker集群。&lt;u&gt;之前的对于docker的使用方式基本就是按照虚拟机的方式使用的，固定IP有悖于微服务的原则。&lt;/u&gt;&lt;/p&gt;

&lt;p&gt;我们基于docker1.11和&lt;a href=&#34;github.com/talkingdata/shrike&#34;&gt;shrike&lt;/a&gt;二层网络模式，还有&lt;a href=&#34;https://github.com/shipyard/shipyard&#34;&gt;shipyard&lt;/a&gt;来做集群管理，shipyard只是一个简单的docker集群管理的WebUI，基本都是调用docker API，唯一做了一点docker原生没有的功能就是&lt;strong&gt;scale&lt;/strong&gt;容器，而且只支持到docker1.11，早已停止开发。我抛弃了&lt;strong&gt;shipyard&lt;/strong&gt;，它的页面功能基本可有可无，我自己开发的&lt;a href=&#34;https://github.com/rootsongjc/magpie&#34;&gt;magpie&lt;/a&gt;一样可以管理&lt;code&gt;yarn on docker&lt;/code&gt;集群。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Docker Swarm有如下几个缺点&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;对于大规模集群的管理效率太低，当管理上百个node的时候经常出现有节点状态不同步的问题，比如主机重启后容器已经&lt;strong&gt;Exited&lt;/strong&gt;了，但是master让然认为是&lt;strong&gt;Running&lt;/strong&gt;状态，必须重启所有master节点才行。&lt;/li&gt;
&lt;li&gt;没有中心化Node管理功能，必须登录到每台node上手动启停&lt;code&gt;swarm-agent&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;集群管理功能实在&lt;strong&gt;太太太&lt;/strong&gt;简陋，查看所有node状态只能用&lt;code&gt;docker info&lt;/code&gt;而且那个格式就不提了，shipyard里有处理这个格式的代码，我copy到了magpie里，彻底抛弃shipyard了。&lt;/li&gt;
&lt;li&gt;Docker swarm的集群管理概念缺失，因为docker一开始设计的时候就不是用来管理集群的，所以出现了swarm，但是只能使用&lt;strong&gt;docker-compose&lt;/strong&gt;来编排服务，但是无法在swarm集群中使用我们自定义的&lt;strong&gt;mynet&lt;/strong&gt;网络，&lt;a href=&#34;https://github.com/docker/compose/issues/4233&#34;&gt;compose issue-4233&lt;/a&gt;，&lt;strong&gt;compose&lt;/strong&gt;也已经被docker官方废弃（最近一年docker发展的太快了，原来用python写的compose已经被用go重构为&lt;strong&gt;libcompose&lt;/strong&gt;直接集成到swarm mode里了），而且docker1.11里也没有像kubernetes那样&lt;code&gt;service&lt;/code&gt;的单位，在docker1.11所有的管理都是基于docker容器的。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Docker Swarm的问题也是shipyard的问题，谁让shipyard直接调用docker的API呢。当然，在后续版本的docker里以上问题都已经不是问题，docker已经越来越像kubernetes，不论是在设计理念上还是在功能上，甚至还发行了企业版，以后每个月发布一个版本。&lt;/p&gt;

&lt;h2 id=&#34;技术选型&#34;&gt;技术选型&lt;/h2&gt;

&lt;p&gt;主要对比&lt;code&gt;Docker1.11&lt;/code&gt;和&lt;code&gt;Docker17.03-ce&lt;/code&gt;版本。&lt;/p&gt;

&lt;p&gt;首先有一点需要了解的是，docker1.12+带来的&lt;a href=&#34;https://rootsongjc.github.io/docker-practice/docs/swarm_mode.html&#34;&gt;swarm mode&lt;/a&gt;，你可以使用一个命令直接启动一个复杂的&lt;strong&gt;stack&lt;/strong&gt;，其中包括了服务编排和所有的服务配置，这是一个&lt;a href=&#34;https://rootsongjc.github.io/docker-practice/docs/create_swarm_app.html&#34;&gt;投票应用的例子&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;下表对比了docker1.11和docker17.03-ce&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;版本&lt;/th&gt;
&lt;th&gt;docker1.11&lt;/th&gt;
&lt;th&gt;docker17.03-ce&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;基本单位&lt;/td&gt;
&lt;td&gt;docker容器&lt;/td&gt;
&lt;td&gt;docker容器、service、stack&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;服务编排&lt;/td&gt;
&lt;td&gt;compose，不支持docker swarm的mynet网络&lt;/td&gt;
&lt;td&gt;改造后的compose，支持stack中完整的服务编排&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;网络模型&lt;/td&gt;
&lt;td&gt;Host、bridge、overlay、mynet&lt;/td&gt;
&lt;td&gt;默认支持跨主机的overlay网络，创建单个容器时也可以attach到已有的overla网络中&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;插件&lt;/td&gt;
&lt;td&gt;没有插件管理命令，但是可以手动创建和管理&lt;/td&gt;
&lt;td&gt;有插件管理命令，可以手动创建和从docker hub中下载，上传插件到自己的私有镜像仓库&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;升级&lt;/td&gt;
&lt;td&gt;不支持平滑升级，重启docker原来的容器也会停掉&lt;/td&gt;
&lt;td&gt;可以停止docker engine但不影响已启动的容器&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;弹性伸缩&lt;/td&gt;
&lt;td&gt;不支持&lt;/td&gt;
&lt;td&gt;service内置功能&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;服务发现&lt;/td&gt;
&lt;td&gt;监听docker event增删DNS&lt;/td&gt;
&lt;td&gt;内置服务发现，根据DNS负载均衡&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;节点管理&lt;/td&gt;
&lt;td&gt;手动启停&lt;/td&gt;
&lt;td&gt;中心化管理node节点&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;服务升级&lt;/td&gt;
&lt;td&gt;手动升级&lt;/td&gt;
&lt;td&gt;service内置功能&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;负载均衡&lt;/td&gt;
&lt;td&gt;本身不支持&lt;/td&gt;
&lt;td&gt;Swarm mode内部DNS轮寻&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;基于以上对比，使用docker17.03-ce不仅可以兼容以前的mynet网络模式，只需要重构以前的shrike为&lt;strong&gt;docker plugin&lt;/strong&gt;，在创建service的时候指定为mynet即可。也可以同时使用docker mode的overlay网络，而且还可以安装其它docker plugin首先更高级网络和volume功能。&lt;/p&gt;

&lt;p&gt;Docker17.03-ce借鉴了很多kubernetes的设计理念，docker发力企业级市场，相信新版的才符合微服务的方向，既能兼容以前的&lt;strong&gt;虚拟机式&lt;/strong&gt;的使用模式，也能兼容&lt;strong&gt;微服务&lt;/strong&gt;架构。&lt;/p&gt;

&lt;h2 id=&#34;下一步&#34;&gt;下一步&lt;/h2&gt;

&lt;p&gt;之前考虑过使用docker1.11 + compose + shipyard + eureka + nginx等做微服务架构，但是考虑到最新版docker的重大升级，从长远的眼光来看，不能一直限定于之前的那一套，我更倾向于新版本。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;调研Docker17.03-ce的新特性，尤其是服务治理方面&lt;/li&gt;
&lt;li&gt;结合具体业务试用&lt;/li&gt;
&lt;li&gt;重构shrike为docker plugin&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Don&amp;rsquo;t speak, I&amp;rsquo;ll try to save us from ourselves&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;If were going down, we&amp;rsquo;re going down in flames&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>My github pages</title>
      <link>http://rootsongjc.github.io/projects/my-github-pages/</link>
      <pubDate>Wed, 22 Feb 2017 16:56:04 +0800</pubDate>
      
      <guid>http://rootsongjc.github.io/projects/my-github-pages/</guid>
      <description>

&lt;h1 id=&#34;my-open-source-project&#34;&gt;My Open Source Project&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://github.com/rootsongjc/magpie&#34;&gt;Magpie&lt;/a&gt; - Magpie is a command line tool for deploying and managing Yarn on Docker cluster.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://github.com/rootsongjc/docker-ipam-plugin&#34;&gt;Docker IPAM plugin&lt;/a&gt; - Docker network plugin to make a L2 flat network.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rootsongjc.github.io/docker-practice/&#34;&gt;Docker practice&lt;/a&gt; - Docker in practice&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rootsongjc.github.io/go-practice/&#34;&gt;Go practice&lt;/a&gt; - Go in practice&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rootsongjc.github.io/linux-practice&#34;&gt;Linux practice&lt;/a&gt; - Linux in practice :)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rootsongjc.github.com/team-management&#34;&gt;Team management&lt;/a&gt; - About team management&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>